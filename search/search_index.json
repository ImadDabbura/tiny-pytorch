{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tiny-PyTorch \ud83e\udde0","text":""},{"location":"#unravel-the-magic-of-modern-deep-learning-by-building-a-pytorch-like-framework-from-the-ground-up","title":"Unravel the magic of modern deep learning by building a PyTorch-like framework from the ground up.","text":"<p>Tiny-PyTorch is an educational deep learning framework built entirely in Python. It demystifies the core machinery of libraries like PyTorch by providing a clean, focused, and from-scratch implementation of the essential components.</p>"},{"location":"#philosophy-understanding-by-building","title":"Philosophy: Understanding by Building","text":"<p>The best way to truly understand how complex systems work is to build them yourself. Tiny-PyTorch is born from this philosophy. While production frameworks like PyTorch and TensorFlow provide powerful, high-level abstractions, their internal complexity can be a barrier to learning.</p> <p>This project strips away those abstractions, allowing you to:</p> <ul> <li>See the Core Logic: Grasp the fundamental algorithms and data structures that power deep learning, from the <code>Tensor</code> object to the backpropagation process.</li> <li>Connect Theory to Code: Bridge the gap between the mathematical concepts of deep learning and their concrete implementation.</li> <li>Become a Better Practitioner: Use high-level frameworks more effectively by understanding their internal mechanics, performance trade-offs, and potential pitfalls.</li> </ul>"},{"location":"#core-features","title":"\u2728 Core Features","text":"<ul> <li>Dynamic Computation Graph: Tensors track their history, allowing for flexible model architectures.</li> <li>Reverse-Mode Automatic Differentiation: An efficient gradient calculation engine (<code>autograd</code>) built from scratch.</li> <li>Extensible <code>nn.Module</code> System: A familiar API for building complex neural network layers and models.</li> <li>Standard Optimizers: Implementations of <code>SGD</code> and <code>Adam</code> to handle parameter updates.</li> <li>Hardware Acceleration: A pluggable backend system supporting <code>NumPy</code>, custom <code>CPU</code> (C++), and <code>CUDA</code> (GPU) operations.</li> <li>Data Loading Utilities: <code>Dataset</code> and <code>DataLoader</code> classes for efficient data pipelines.</li> </ul>"},{"location":"#project-architecture","title":"\ud83c\udfd7\ufe0f Project Architecture","text":"<p>The framework is built in a bottom-up fashion, where each layer of abstraction relies on the one below it. This mirrors the logical structure of major deep learning libraries.</p> <pre><code>graph TD\n    subgraph \"High-Level API\"\n        C[nn.Module] --&gt; D[Optimizers]\n        B[Tensors &amp; Autograd] --&gt; C\n    end\n    subgraph \"Low-Level Engine\"\n        A[NDArray] --&gt; B\n        subgraph \"Backends\"\n            direction LR\n            np[NumPy]\n            cpu[CPU]\n            gpu[CUDA]\n        end\n        Backend --&gt; A\n    end\n\n    style C fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#ccf,stroke:#333,stroke-width:2px\n    style A fill:#cfc,stroke:#333,stroke-width:2px</code></pre> <ol> <li>Backends (NumPy, CPU, CUDA): Perform the actual mathematical computations on flat arrays of data.</li> <li>NDArray: A generic, strided N-dimensional array class that provides a unified interface over different backends.</li> <li>Tensor &amp; Autograd: The heart of the framework. A <code>Tensor</code> wraps an <code>NDArray</code> and builds a dynamic computation graph. The <code>autograd</code> engine traverses this graph to perform reverse-mode automatic differentiation.</li> <li>High-Level API (<code>nn</code>, <code>optimizer</code>): Provides the familiar modules, layers, and optimization algorithms for building and training neural networks.</li> </ol>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<p>To install Tiny-PyTorch, you have two main options:</p>"},{"location":"#install-from-pypi-using-pip","title":"Install from PyPI (using pip)","text":"<p>You can install the latest stable version directly from PyPI using pip:</p> <pre><code>pip install tiny-pytorch\n</code></pre>"},{"location":"#install-from-source-github-repository","title":"Install from Source (GitHub Repository)","text":"<p>To get the very latest development version or if you plan to contribute, you can install from the GitHub repository:</p> <ol> <li>Clone the repository: <pre><code>git clone https://github.com/your-username/tiny-pytorch.git\n</code></pre></li> <li>Navigate to the project directory: <pre><code>cd tiny-pytorch\n</code></pre></li> <li>Install in editable mode: This allows you to make changes to the source code and have them reflected without reinstalling.     <pre><code>pip install -e .\n</code></pre></li> </ol> <p>Here's a simple example of defining a model and running a forward/backward pass.</p> <pre><code>import tiny_pytorch as tp\nimport tiny_pytorch.nn as nn\n\n\n# 1. Define a simple model\nclass SimpleNet(nn.Module):\n    def __init__(self, in_features, out_features):\n        self.fc1 = nn.Linear(in_features, 64)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(64, out_features)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        return self.fc2(x)\n\n\n# 2. Initialize model, optimizer, and loss function\nmodel = SimpleNet(in_features=10, out_features=1)\noptimizer = tp.optim.Adam(model.parameters(), lr=0.001)\nloss_fn = nn.MSELoss()\n\n# 3. Create dummy data\nx_train = tp.randn(32, 10, requires_grad=True)\ny_true = tp.randn(32, 1)\n\n# 4. Perform a single training step\noptimizer.zero_grad()  # Reset gradients\ny_pred = model(x_train)  # Forward pass\nloss = loss_fn(y_pred, y_true)  # Compute loss\nloss.backward()  # Backward pass (autograd)\noptimizer.step()  # Update weights\n\nprint(f\"Loss: {loss.item():.4f}\")\n</code></pre>"},{"location":"#roadmap","title":"\ud83d\uddfa\ufe0f Roadmap","text":"<p>The project is developed in two main phases. Our current progress is tracked below.</p> <ul> <li>Phase I: Core Framework (NumPy Backend)</li> <li>[x] <code>Tensor</code>: The main multi-dimensional array with autograd support.</li> <li>[x] <code>Op</code>: The base class for all tensor operations.</li> <li>[x] <code>Automatic Differentiation</code>: Reverse-mode autograd engine.</li> <li>[x] <code>init</code>: Parameter initialization functions (<code>kaiming</code>, <code>xavier</code>, etc.).</li> <li>[x] <code>nn</code>: Core neural network layers (<code>Linear</code>, <code>ReLU</code>, <code>BatchNorm</code>, <code>Conv2d</code>).</li> <li>[x] <code>optimizer</code>: <code>SGD</code> and <code>Adam</code> optimizers.</li> <li>[x] <code>data</code>: <code>Dataset</code> and <code>DataLoader</code> for data handling.</li> <li>Phase II: Hardware Acceleration &amp; Advanced Models</li> <li>[x] <code>NDArray</code>: Generic, strided N-dimensional array.</li> <li>[x] NumPy Backend</li> <li>[x] CPU Backend (C++)</li> <li>[x] CUDA Backend (GPU)</li> <li>[x] Advanced CNN operations (e.g., <code>padding</code>, <code>dilation</code>).</li> <li>[x] ResNet implementation.</li> <li>[x] RNN and LSTM layers.</li> <li>[x] A simple Language Model.</li> </ul>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<p>The official documentation, including detailed API references and tutorials, is hosted at: https://imaddabbura.github.io/tiny-pytorch/</p>"},{"location":"#limitations","title":"\u26a0\ufe0f Limitations","text":"<p>As an educational project, Tiny-PyTorch has some intentional simplifications:</p> <ul> <li>Explicit Broadcasting: Broadcasting for element-wise operations must be done manually if tensor shapes do not match.</li> <li>Single Data Type: <code>NDArray</code> only supports the <code>float32</code> <code>dtype</code>.</li> <li>Contiguous Memory: Operations on the underlying 1D array require a call to <code>compact()</code> to ensure the data is in a contiguous memory block.</li> <li>Limited Reductions: Reduction operations (e.g., <code>sum</code>, <code>max</code>) can only be performed on a single axis or all axes at once.</li> </ul>"},{"location":"#license","title":"License","text":"<p>Tiny-PyTorch is licensed under the Apache License 2.0. See the LICENSE file for details.</p>"},{"location":"backend_numpy/","title":"Backend Numpy","text":"<p>NumPy backend implementation for tiny-pytorch.</p> <p>This module provides a NumPy-based backend for tiny-pytorch, implementing device abstractions and tensor operations using NumPy arrays. It serves as a simple, pure Python backend that's useful for development, testing, and educational purposes.</p> <p>The module provides a complete device abstraction layer that wraps NumPy functionality, making it easy to create and manipulate tensors using standard NumPy operations. This backend is particularly useful when you want to avoid external dependencies or need a simple, portable implementation.</p> Key Features <ul> <li>Pure Python implementation using NumPy</li> <li>Device abstraction for tensor operations</li> <li>Standard tensor creation methods (zeros, ones, randn, rand)</li> <li>One-hot encoding support</li> <li>Uniform interface with other backends</li> <li>No external dependencies beyond NumPy</li> </ul> <p>Classes:</p> <ul> <li> <code>Device</code>           \u2013            <p>Base class for device abstractions. Defines the interface that all device implementations must follow. Devices represent where tensor data is stored and provide methods for creating tensors on that device.</p> </li> <li> <code>CPUDevice</code>           \u2013            <p>CPU device implementation using NumPy arrays. Represents data that sits in CPU memory, using NumPy as the underlying computational engine. Provides methods for creating tensors with different initializations and distributions.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>cpu</code>             \u2013              <p>Returns a CPU device instance using NumPy backend.</p> </li> <li> <code>default_device</code>             \u2013              <p>Returns the default device (CPU with NumPy backend).</p> </li> <li> <code>all_devices</code>             \u2013              <p>Returns a list of all available devices (only CPU for this backend).</p> </li> </ul> Notes <p>This backend implementation is designed to be simple and portable, making it ideal for development, testing, and educational purposes. It provides the same interface as other backends (CPU, CUDA) but uses NumPy arrays as the underlying storage and computation engine.</p> <p>The backend automatically handles data type conversions and provides consistent behavior across different platforms. All tensor operations are performed using NumPy's optimized C implementations, ensuring good performance for most use cases.</p> <p>This backend is particularly useful when: - You need a simple, portable implementation - You want to avoid external dependencies - You're developing or testing code - You're in an educational environment</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tiny_pytorch as tp\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a CPU device using NumPy backend\n&gt;&gt;&gt; device = tp.backend_numpy.cpu()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create tensors on the device\n&gt;&gt;&gt; x = device.zeros((3, 4), dtype=\"float32\")\n&gt;&gt;&gt; y = device.ones((3, 4), dtype=\"float32\")\n&gt;&gt;&gt; z = device.randn(3, 4)  # Random normal distribution\n&gt;&gt;&gt; w = device.rand(3, 4)   # Random uniform distribution\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create one-hot encoded tensor\n&gt;&gt;&gt; one_hot = device.one_hot(10, 5, dtype=\"float32\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use the default device\n&gt;&gt;&gt; default_dev = tp.backend_numpy.default_device()\n&gt;&gt;&gt; tensor = default_dev.full((2, 2), 3.14, dtype=\"float32\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check available devices\n&gt;&gt;&gt; devices = tp.backend_numpy.all_devices()\n&gt;&gt;&gt; print(f\"Available devices: {devices}\")\n</code></pre>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice","title":"<code>CPUDevice</code>","text":"<p>               Bases: <code>Device</code></p> <p>Represents data that sits in CPU, using NumPy as backend.</p> <p>This device implementation uses NumPy arrays for all tensor operations. It provides methods for creating tensors with different initializations and distributions.</p> <p>Methods:</p> <ul> <li> <code>zeros</code>             \u2013              <p>Create a tensor filled with zeros.</p> </li> <li> <code>ones</code>             \u2013              <p>Create a tensor filled with ones.</p> </li> <li> <code>randn</code>             \u2013              <p>Create a tensor with random values from standard normal distribution.</p> </li> <li> <code>rand</code>             \u2013              <p>Create a tensor with random values from uniform distribution.</p> </li> <li> <code>one_hot</code>             \u2013              <p>Create a one-hot encoded tensor.</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Check if this device equals another device.</p>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.__hash__","title":"<code>__hash__()</code>","text":"<p>Hash of the device.</p>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of the device.</p>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.full","title":"<code>full(shape, fill_value, dtype='float32')</code>","text":"<p>Create a tensor filled with a constant value.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>int or Sequence[int]</code>)           \u2013            <p>The shape of the tensor to create.</p> </li> <li> <code>fill_value</code>               (<code>float</code>)           \u2013            <p>The value to fill the tensor with.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>The data type of the tensor. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A tensor filled with the specified value.</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.one_hot","title":"<code>one_hot(n, i, dtype='float32')</code>","text":"<p>Create a one-hot encoded tensor.</p> <p>Parameters:</p> <ul> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>Number of columns (classes).</p> </li> <li> <code>i</code>               (<code>int or list[int]</code>)           \u2013            <p>Number of one-hot vectors (rows) or indices to encode.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>The data type of the tensor. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A one-hot encoded tensor.</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.ones","title":"<code>ones(shape, dtype='float32')</code>","text":"<p>Create a tensor filled with ones.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>int or Sequence[int]</code>)           \u2013            <p>The shape of the tensor to create.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>The data type of the tensor. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A tensor filled with ones.</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.rand","title":"<code>rand(*shape)</code>","text":"<p>Create a tensor with random values from uniform distribution.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>The shape of the tensor to create.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A tensor with random values from U[0, 1).</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.randn","title":"<code>randn(*shape)</code>","text":"<p>Create a tensor with random values from standard normal distribution.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>The shape of the tensor to create.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A tensor with random values from N(0, 1).</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.CPUDevice.zeros","title":"<code>zeros(shape, dtype='float32')</code>","text":"<p>Create a tensor filled with zeros.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>int or Sequence[int]</code>)           \u2013            <p>The shape of the tensor to create.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>The data type of the tensor. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A tensor filled with zeros.</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.Device","title":"<code>Device</code>","text":"<p>Base class for device abstractions.</p> <p>This class defines the interface that all device implementations must follow. Devices represent where tensor data is stored and provide methods for creating tensors on that device.</p>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.all_devices","title":"<code>all_devices()</code>","text":"<p>Returns a list of all available devices.</p> <p>Returns:</p> <ul> <li> <code>list[CPUDevice]</code>           \u2013            <p>A list containing the CPU device.</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.cpu","title":"<code>cpu()</code>","text":"<p>Returns a CPU device instance.</p> <p>Returns:</p> <ul> <li> <code>CPUDevice</code>           \u2013            <p>A CPU device instance.</p> </li> </ul>"},{"location":"backend_numpy/#tiny_pytorch.backend_numpy.default_device","title":"<code>default_device()</code>","text":"<p>Returns the default device (CPU).</p> <p>Returns:</p> <ul> <li> <code>CPUDevice</code>           \u2013            <p>The default CPU device.</p> </li> </ul>"},{"location":"data/","title":"Data","text":"<p>Data loading and processing utilities.</p> <p>This module provides comprehensive utilities for loading, processing, and transforming data in the tiny-pytorch framework. It includes dataset abstractions, data loading functionality, and transform operations similar to PyTorch's data utilities, designed to work seamlessly with the Tensor system.</p> <p>The module provides base classes for datasets and transforms, as well as concrete implementations for specific data types and transformations commonly used in machine learning workflows.</p> Key Features <ul> <li>Dataset abstractions for various data types</li> <li>Efficient data loading with batching and shuffling</li> <li>Data augmentation and transformation pipelines</li> <li>Multiprocessing support for parallel data loading</li> <li>Memory-efficient data handling</li> <li>Integration with Tensor operations</li> </ul> <p>Classes:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>Base class that provides common dataset functionality. Defines the interface for accessing data samples and applying transforms.</p> </li> <li> <code>NDArrayDataset : Dataset</code>           \u2013            <p>Dataset implementation for numpy arrays and tensors. Supports multiple arrays that will be returned as tuples when indexed.</p> </li> <li> <code>Sampler</code>           \u2013            <p>Base class for sampling strategies from datasets. Provides functionality for sequential and random sampling.</p> </li> <li> <code>BatchSampler</code>           \u2013            <p>Wraps a sampler to yield batches of indices. Handles batch creation with optional dropping of incomplete batches.</p> </li> <li> <code>DataLoader</code>           \u2013            <p>Iterates over a dataset in batches with optional multiprocessing. Provides efficient data loading with support for shuffling and transforms.</p> </li> <li> <code>Transform</code>           \u2013            <p>Base class for all data transformations. Defines the interface for data augmentation and preprocessing operations.</p> </li> <li> <code>RandomFlipHorizontal : Transform</code>           \u2013            <p>Randomly flips data horizontally with given probability. Commonly used for image data augmentation.</p> </li> <li> <code>RandomCrop : Transform</code>           \u2013            <p>Randomly crops data to specified size. Useful for image data augmentation and regularization.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>collate</code>             \u2013              <p>Collate function for combining multiple samples into a batch. Default collation function used by DataLoader.</p> </li> </ul> Notes <p>The data loading system is designed to be efficient and flexible. Datasets can be easily extended by inheriting from the base Dataset class and implementing the required methods. Transforms can be chained together to create complex data augmentation pipelines.</p> <p>The DataLoader class provides efficient batch loading with support for multiprocessing, which can significantly speed up data loading for large datasets. The system automatically handles device placement and tensor conversion for seamless integration with the neural network modules.</p> <p>All transforms are designed to work with both individual samples and batches, making them suitable for use in data augmentation pipelines.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tiny_pytorch as tp\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a simple dataset\n&gt;&gt;&gt; X = np.random.randn(1000, 784)  # Features\n&gt;&gt;&gt; y = np.random.randint(0, 10, 1000)  # Labels\n&gt;&gt;&gt; dataset = tp.data.NDArrayDataset(X, y)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a data loader with transforms\n&gt;&gt;&gt; transforms = [\n...     tp.data.RandomFlipHorizontal(p=0.5),\n...     tp.data.RandomCrop(padding=3)\n... ]\n&gt;&gt;&gt; dataloader = tp.data.DataLoader(\n...     dataset, batch_size=32, shuffle=True, n_workers=2\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Iterate over batches\n&gt;&gt;&gt; for batch_x, batch_y in dataloader:\n...     # batch_x and batch_y are Tensor objects\n...     print(f\"Batch shape: {batch_x.shape}\")\n...     break\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom dataset example\n&gt;&gt;&gt; class CustomDataset(tp.data.Dataset):\n...     def __init__(self, data, transforms=None):\n...         super().__init__(transforms)\n...         self.data = data\n...\n...     def __getitem__(self, index):\n...         sample = self.data[index]\n...         return self.apply_transforms(sample)\n...\n...     def __len__(self):\n...         return len(self.data)\n</code></pre>"},{"location":"data/#tiny_pytorch.data.BatchSampler","title":"<code>BatchSampler</code>","text":"<p>Wraps a sampler to yield batches of indices.</p> <p>A BatchSampler takes a sampler that yields individual indices and wraps it to yield batches of indices instead. This is useful for mini-batch training where we want to process multiple samples at once.</p> Notes <p>The batch size determines how many indices are yielded in each batch. If drop_last is True, the last batch will be dropped if it's smaller than the batch size.</p> <p>The sampler can be any iterable that yields indices, but is typically an instance of Sampler.</p> See Also <p>Sampler : Base class for sampling individual indices</p>"},{"location":"data/#tiny_pytorch.data.BatchSampler.__init__","title":"<code>__init__(sampler, batch_size, drop_last=False)</code>","text":"<p>Parameters:</p> <ul> <li> <code>sampler</code>               (<code>Sampler or Iterable[int]</code>)           \u2013            <p>Sampler instance or iterable that yields indices.</p> </li> <li> <code>batch_size</code>               (<code>int</code>)           \u2013            <p>Number of indices to include in each batch.</p> </li> <li> <code>drop_last</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, drop the last batch if it's smaller than batch_size. Default is False.</p> </li> </ul>"},{"location":"data/#tiny_pytorch.data.DataLoader","title":"<code>DataLoader</code>","text":"<p>Iterator over a dataset that supports batching and parallel data loading.</p> <p>DataLoader combines a dataset and a sampler, and provides an iterable over the given dataset. It supports automatic batching, parallel data loading, and customizable data loading order.</p> Notes <p>The DataLoader provides an efficient way to load data in batches for training and evaluation. It handles the complexities of:</p> <ul> <li>Batching individual data points into batches</li> <li>Shuffling the data if requested</li> <li>Parallel data loading using multiple worker processes</li> <li>Custom collation of data samples into batches</li> </ul>"},{"location":"data/#tiny_pytorch.data.DataLoader.__init__","title":"<code>__init__(dataset, batch_size=1, n_workers=1, shuffle=False, drop_last=False, collate_fn=collate)</code>","text":"<p>Parameters:</p> <ul> <li> <code>dataset</code>               (<code>Dataset</code>)           \u2013            <p>Dataset from which to load the data.</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>How many samples per batch to load. Default: 1.</p> </li> <li> <code>n_workers</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>How many subprocesses to use for data loading. Default: 1.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to shuffle the data at every epoch. Default: False.</p> </li> <li> <code>drop_last</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to drop the last incomplete batch if dataset size is not divisible by batch_size. Default: False.</p> </li> <li> <code>collate_fn</code>               (<code>callable</code>, default:                   <code>collate</code> )           \u2013            <p>Merges a list of samples to form a mini-batch. Default: collate.</p> </li> </ul>"},{"location":"data/#tiny_pytorch.data.Dataset","title":"<code>Dataset</code>","text":"<p>Base class for all datasets.</p> <p>This class defines the basic interface and functionality that all dataset implementations should follow. It provides common methods like getitem for accessing data samples and apply_transforms for data augmentation.</p> Notes <p>All datasets should inherit from this base class and implement the getitem method according to their specific data loading requirements.</p>"},{"location":"data/#tiny_pytorch.data.Dataset.__init__","title":"<code>__init__(transforms=None)</code>","text":"<p>Parameters:</p> <ul> <li> <code>transforms</code>               (<code>list or None</code>, default:                   <code>None</code> )           \u2013            <p>List of transform functions to be applied to data samples. Each transform should be a callable that takes a sample and returns the transformed sample. Default is None.</p> </li> </ul> Notes <p>The transforms will be applied sequentially in the order they appear in the list when apply_transforms() is called on a sample.</p>"},{"location":"data/#tiny_pytorch.data.NDArrayDataset","title":"<code>NDArrayDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Dataset for working with NDArrays.</p> <p>A dataset class that wraps NDArrays for use in machine learning tasks. Supports multiple arrays that will be returned as tuples when indexed. Commonly used for features and labels in supervised learning.</p> Notes <p>All arrays must have the same first dimension (length). Arrays will be returned in the same order they were passed to init.</p>"},{"location":"data/#tiny_pytorch.data.NDArrayDataset.__init__","title":"<code>__init__(*arrays)</code>","text":"<p>Parameters:</p> <ul> <li> <code>*arrays</code>               (<code>array_like</code>, default:                   <code>()</code> )           \u2013            <p>One or more arrays to include in the dataset. All arrays must have the same first dimension (length).</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no arrays are provided or if arrays have different lengths.</p> </li> </ul> Notes <p>Arrays will be returned in the same order they were passed when indexing the dataset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; X = np.random.randn(100, 10)  # 100 samples, 10 features\n&gt;&gt;&gt; y = np.random.randint(0, 2, 100)  # Binary labels\n&gt;&gt;&gt; dataset = NDArrayDataset(X, y)\n&gt;&gt;&gt; x, y = dataset[0]  # Get first sample and label\n</code></pre>"},{"location":"data/#tiny_pytorch.data.RandomCrop","title":"<code>RandomCrop</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Transform that randomly crops images after zero padding.</p> <p>This transform first applies zero padding around the image borders, then randomly crops the padded image back to its original size. This creates slight translations of the image content, which helps models become more robust to object position variations.</p> Notes <p>The padding size determines the maximum possible shift in any direction. For example, with padding=3, the image content can be shifted by up to 3 pixels in any direction.</p> <p>The cropped region maintains the original image dimensions, effectively creating a translated version of the original image with zero padding filling in any gaps.</p> See Also <p>RandomFlipHorizontal : Transform that randomly flips images horizontally</p>"},{"location":"data/#tiny_pytorch.data.RandomCrop.__call__","title":"<code>__call__(img)</code>","text":"<p>Parameters:</p> <ul> <li> <code>img</code>               (<code>ndarray</code>)           \u2013            <p>H x W x C array representing an image</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>H x W x C array of randomly cropped image after padding</p> </li> </ul>"},{"location":"data/#tiny_pytorch.data.RandomCrop.__init__","title":"<code>__init__(padding=3)</code>","text":"<p>Parameters:</p> <ul> <li> <code>padding</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Number of pixels to pad around image borders. Default is 3.</p> </li> </ul>"},{"location":"data/#tiny_pytorch.data.RandomFlipHorizontal","title":"<code>RandomFlipHorizontal</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Transform that randomly flips images (specified as H x W x C NDArray) horizontally.</p> <p>This transform applies horizontal flipping to images with a specified probability. Horizontal flipping is a common data augmentation technique that helps models become invariant to the horizontal orientation of objects in images.</p> Notes <p>The flip is applied with probability p (default 0.5). When applied, the image is flipped along its horizontal axis, meaning the left side becomes the right side and vice versa.</p> See Also <p>RandomCrop : Transform that randomly crops images</p>"},{"location":"data/#tiny_pytorch.data.RandomFlipHorizontal.__call__","title":"<code>__call__(img)</code>","text":"<p>Parameters:</p> <ul> <li> <code>img</code>               (<code>ndarray</code>)           \u2013            <p>H x W x C array representing an image</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>H x W x C array of flipped or original image</p> </li> </ul>"},{"location":"data/#tiny_pytorch.data.RandomFlipHorizontal.__init__","title":"<code>__init__(p=0.5)</code>","text":"<p>Parameters:</p> <ul> <li> <code>p</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>Probability of flipping the image horizontally. Default is 0.5.</p> </li> </ul>"},{"location":"data/#tiny_pytorch.data.Sampler","title":"<code>Sampler</code>","text":"<p>Base class for sampling elements from a dataset.</p> <p>A Sampler provides an iterable over indices of a dataset, defining the order in which elements are visited. This base class supports sequential or shuffled sampling.</p> Notes <p>Samplers are used by DataLoader to determine the order and grouping of samples during iteration.</p> <p>The shuffle parameter determines whether indices are returned in sequential or randomized order.</p> See Also <p>BatchSampler : Wraps a sampler to yield batches of indices DataLoader : Uses samplers to iterate over dataset elements</p>"},{"location":"data/#tiny_pytorch.data.Sampler.__init__","title":"<code>__init__(ds, shuffle=False)</code>","text":"<p>Parameters:</p> <ul> <li> <code>ds</code>               (<code>Dataset</code>)           \u2013            <p>Dataset to sample from.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, samples are returned in random order. Default is False.</p> </li> </ul>"},{"location":"data/#tiny_pytorch.data.Transform","title":"<code>Transform</code>","text":"<p>Base class for all transforms.</p> <p>This class defines the interface for transformations that can be applied to data. Each transform should implement the call method to specify how the data should be transformed.</p> Notes <p>Transforms are commonly used in computer vision tasks to augment training data and improve model generalization. They can include operations like flipping, rotating, cropping, or normalizing images.</p> See Also <p>RandomFlipHorizontal : Transform that randomly flips images horizontally RandomCrop : Transform that randomly crops images</p>"},{"location":"init/","title":"Initialization","text":"<p>This module provides functions for initializing tensors with different types of values. It includes functions for generating tensors filled with ones, zeros, random numbers, binary random numbers, and one-hot encoded tensors. It also provides functions for initializing weights using Xavier/Glorot uniform and Kaiming/He uniform and normal distributions.</p> <p>Functions:</p> <ul> <li> <code>ones</code>             \u2013              <p>Generate a tensor filled with ones.</p> </li> <li> <code>zeros</code>             \u2013              <p>Generate a tensor filled with zeros.</p> </li> <li> <code>rand</code>             \u2013              <p>Generate a tensor filled with random numbers from a uniform distribution.</p> </li> <li> <code>randb</code>             \u2013              <p>Generate a binary random tensor.</p> </li> <li> <code>one_hot</code>             \u2013              <p>Generate a one-hot encoded tensor.</p> </li> <li> <code>zeros_like</code>             \u2013              <p>Generate a tensor of zeros with the same shape and dtype as the input tensor.</p> </li> <li> <code>ones_like</code>             \u2013              <p>Generate a tensor of ones with the same shape and dtype as the input tensor.</p> </li> <li> <code>xavier_uniform</code>             \u2013              <p>Initialize weights using Xavier/Glorot uniform initialization.</p> </li> <li> <code>xavier_normal</code>             \u2013              <p>Initialize weights using Xavier/Glorot normal initialization.</p> </li> <li> <code>kaiming_uniform</code>             \u2013              <p>Initialize weights using Kaiming/He uniform initialization.</p> </li> <li> <code>kaiming_normal</code>             \u2013              <p>Initialize weights using Kaiming/He normal initialization.</p> </li> </ul>"},{"location":"init/#tiny_pytorch.init.constant","title":"<code>constant(*shape, c=1.0, device=None, dtype='float32', requires_grad=False)</code>","text":"<p>Generate a tensor filled with a constant value.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>Shape of the output tensor.</p> </li> <li> <code>c</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Constant value to fill the tensor with. Default is 1.0.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor of specified shape filled with constant value c.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; constant(2, 3, c=5)  # 2x3 tensor filled with 5\n&gt;&gt;&gt; constant(4, c=3.14)  # 4-element tensor filled with pi\n&gt;&gt;&gt; constant(2, 2, device=gpu(), c=2.0)  # 2x2 tensor on GPU filled with 2\n</code></pre>"},{"location":"init/#tiny_pytorch.init.kaiming_normal","title":"<code>kaiming_normal(fan_in, fan_out, nonlinearity='relu', **kwargs)</code>","text":"<p>Initialize weights using Kaiming/He normal initialization.</p> <p>Parameters:</p> <ul> <li> <code>fan_in</code>               (<code>int</code>)           \u2013            <p>Number of input features.</p> </li> <li> <code>fan_out</code>               (<code>int</code>)           \u2013            <p>Number of output features.</p> </li> <li> <code>nonlinearity</code>               (<code>str</code>, default:                   <code>'relu'</code> )           \u2013            <p>The non-linear function (or activation function) used in the model. Default is \"relu\".</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional arguments passed to randn().</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor initialized with values from normal distribution N(0, std^2) where std = sqrt(2 / fan_in).</p> </li> </ul> Notes <p>This initialization is designed to work with the rectified linear unit (ReLU) activation function. It sets the weights to be zero-mean and have a standard deviation of sqrt(2 / fan_in).</p> References <p>He, K., Zhang, X., Ren, S., &amp; Sun, J. (2015). Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. In ICCV.</p>"},{"location":"init/#tiny_pytorch.init.kaiming_uniform","title":"<code>kaiming_uniform(fan_in, fan_out, nonlinearity='relu', **kwargs)</code>","text":"<p>Initialize weights using Kaiming/He uniform initialization.</p> <p>Parameters:</p> <ul> <li> <code>fan_in</code>               (<code>int</code>)           \u2013            <p>Number of input features.</p> </li> <li> <code>fan_out</code>               (<code>int</code>)           \u2013            <p>Number of output features.</p> </li> <li> <code>nonlinearity</code>               (<code>str</code>, default:                   <code>'relu'</code> )           \u2013            <p>The non-linear function (or activation function) used in the model. Default is \"relu\".</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional arguments passed to rand().</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor initialized with values from uniform distribution U(-bound, bound) where bound = sqrt(6 / fan_in).</p> </li> </ul> Notes <p>This initialization is designed to work with the rectified linear unit (ReLU) activation function. It sets the weights to be zero-mean and have a standard deviation of sqrt(2 / fan_in).</p> References <p>He, K., Zhang, X., Ren, S., &amp; Sun, J. (2015). Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. In ICCV.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; kaiming_uniform(10, 5)  # 10x5 tensor with Kaiming initialization\n&gt;&gt;&gt; kaiming_uniform(20, 10, nonlinearity=\"tanh\")  # Initialize for tanh\n&gt;&gt;&gt; kaiming_uniform(5, 5, device=gpu())  # Initialize on GPU\n</code></pre>"},{"location":"init/#tiny_pytorch.init.one_hot","title":"<code>one_hot(k, n, device=None, dtype='float32', requires_grad=False)</code>","text":"<p>Generate a one-hot encoded tensor.</p> <p>Parameters:</p> <ul> <li> <code>k</code>               (<code>int</code>)           \u2013            <p>Number of classes (width of one-hot encoding).</p> </li> <li> <code>n</code>               (<code>int or Iterable[int]</code>)           \u2013            <p>Number of samples (rows) or shape of output tensor.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>One-hot encoded tensor with shape (n, k) if n is int, or (*n, k) if n is Iterable.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; one_hot(3, 2)  # 2x3 tensor with one-hot rows\n&gt;&gt;&gt; one_hot(4, [2,3])  # 2x3x4 tensor with one-hot encodings\n&gt;&gt;&gt; one_hot(2, 5, device=gpu())  # 5x2 one-hot tensor on GPU\n</code></pre>"},{"location":"init/#tiny_pytorch.init.ones","title":"<code>ones(*shape, device=None, dtype='float32', requires_grad=False)</code>","text":"<p>Generate a tensor filled with ones.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>Shape of the output tensor.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor of specified shape filled with ones.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ones(2, 3)  # 2x3 tensor filled with ones\n&gt;&gt;&gt; ones(4, device=gpu())  # 4-element tensor of ones on GPU\n&gt;&gt;&gt; ones(2, 2, dtype=\"float64\")  # 2x2 tensor of ones with float64 dtype\n</code></pre>"},{"location":"init/#tiny_pytorch.init.ones_like","title":"<code>ones_like(array, *, device=None, requires_grad=False)</code>","text":"<p>Return a tensor of ones with the same shape and dtype as the input tensor.</p> <p>Parameters:</p> <ul> <li> <code>array</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor whose shape and dtype will be used.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. If None, uses the device of the input tensor.</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor of ones with the same shape and dtype as the input tensor.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; ones_like(x)\nTensor([[1, 1], [1, 1]])\n</code></pre>"},{"location":"init/#tiny_pytorch.init.rand","title":"<code>rand(*shape, low=0.0, high=1.0, device=None, dtype='float32', requires_grad=False)</code>","text":"<p>Generate a tensor filled with random numbers from uniform distribution.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>Shape of the output tensor.</p> </li> <li> <code>low</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Lower bound of the uniform distribution. Default is 0.0.</p> </li> <li> <code>high</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Upper bound of the uniform distribution. Default is 1.0.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor of specified shape filled with random values from U(low, high).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rand(2, 3)  # 2x3 tensor with values in [0,1]\n&gt;&gt;&gt; rand(4, low=-1, high=1)  # 4-element tensor with values in [-1,1]\n&gt;&gt;&gt; rand(2, 2, device=gpu(), dtype=\"float64\")  # 2x2 tensor on GPU\n</code></pre>"},{"location":"init/#tiny_pytorch.init.randb","title":"<code>randb(*shape, p=0.5, device=None, dtype='bool', requires_grad=False)</code>","text":"<p>Generate a binary random tensor.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>Shape of the output tensor.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>Probability of generating 1. Default is 0.5.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'bool'</code> )           \u2013            <p>Data type of the tensor. Default is \"bool\".</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Binary tensor of specified shape where each element is 1 with probability p and 0 with probability (1-p).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; randb(2, 3)  # 2x3 binary tensor with p=0.5\n&gt;&gt;&gt; randb(4, p=0.8)  # 4-element tensor, 80% chance of 1s\n&gt;&gt;&gt; randb(2, 2, device=gpu())  # 2x2 binary tensor on GPU\n</code></pre>"},{"location":"init/#tiny_pytorch.init.randn","title":"<code>randn(*shape, mean=0.0, std=1.0, device=None, dtype='float32', requires_grad=False)</code>","text":"<p>Generate a tensor filled with random numbers from normal distribution.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>Shape of the output tensor.</p> </li> <li> <code>mean</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Mean of the normal distribution. Default is 0.0.</p> </li> <li> <code>std</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Standard deviation of the normal distribution. Default is 1.0.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor of specified shape filled with random values from N(mean, std^2).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; randn(2, 3)  # 2x3 tensor from standard normal\n&gt;&gt;&gt; randn(4, mean=5, std=0.1)  # 4-element tensor with mean 5, std 0.1\n&gt;&gt;&gt; randn(2, 2, device=gpu(), dtype=\"float64\")  # 2x2 tensor on GPU\n</code></pre>"},{"location":"init/#tiny_pytorch.init.xavier_normal","title":"<code>xavier_normal(fan_in, fan_out, gain=1.0, **kwargs)</code>","text":"<p>Initialize weights using Xavier/Glorot normal initialization.</p> <p>Parameters:</p> <ul> <li> <code>fan_in</code>               (<code>int</code>)           \u2013            <p>Number of input features.</p> </li> <li> <code>fan_out</code>               (<code>int</code>)           \u2013            <p>Number of output features.</p> </li> <li> <code>gain</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Scaling factor for the standard deviation of the normal distribution. Default is 1.0.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional arguments passed to randn().</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor initialized with values from normal distribution N(mean, std^2) where mean = 0 and std = gain * sqrt(2/(fan_in + fan_out)).</p> </li> </ul> Notes <p>This initialization helps maintain variance of activations and gradients across layers in deep networks. The gain parameter can be adjusted for different activation functions.</p> References <p>Glorot, X. &amp; Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. In AISTATS.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; xavier_normal(10, 5)  # 10x5 tensor with Xavier initialization\n&gt;&gt;&gt; xavier_normal(20, 10, gain=2.0)  # Scaled initialization\n&gt;&gt;&gt; xavier_normal(5, 5, device=gpu())  # Initialize on GPU\n</code></pre>"},{"location":"init/#tiny_pytorch.init.xavier_uniform","title":"<code>xavier_uniform(fan_in, fan_out, gain=1.0, **kwargs)</code>","text":"<p>Initialize weights using Xavier/Glorot uniform initialization.</p> <p>Parameters:</p> <ul> <li> <code>fan_in</code>               (<code>int</code>)           \u2013            <p>Number of input features.</p> </li> <li> <code>fan_out</code>               (<code>int</code>)           \u2013            <p>Number of output features.</p> </li> <li> <code>gain</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Scaling factor for the bounds of the uniform distribution. Default is 1.0.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional arguments passed to rand().</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor initialized with values from uniform distribution U(-a, a) where a = gain * sqrt(6/(fan_in + fan_out)).</p> </li> </ul> Notes <p>This initialization helps maintain variance of activations and gradients across layers in deep networks. The gain parameter can be adjusted for different activation functions.</p> References <p>Glorot, X. &amp; Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. In AISTATS.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; xavier_uniform(10, 5)  # 10x5 tensor with Xavier initialization\n&gt;&gt;&gt; xavier_uniform(20, 10, gain=2.0)  # Scaled initialization\n&gt;&gt;&gt; xavier_uniform(5, 5, device=gpu())  # Initialize on GPU\n</code></pre>"},{"location":"init/#tiny_pytorch.init.zeros","title":"<code>zeros(*shape, device=None, dtype='float32', requires_grad=False)</code>","text":"<p>Generate a tensor filled with zeros.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>Shape of the output tensor.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor of specified shape filled with zeros.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zeros(2, 3)  # 2x3 tensor filled with zeros\n&gt;&gt;&gt; zeros(4, device=gpu())  # 4-element tensor of zeros on GPU\n&gt;&gt;&gt; zeros(2, 2, dtype=\"float64\")  # 2x2 tensor of zeros with float64 dtype\n</code></pre>"},{"location":"init/#tiny_pytorch.init.zeros_like","title":"<code>zeros_like(array, *, device=None, requires_grad=False)</code>","text":"<p>Return a tensor of zeros with the same shape and dtype as the input tensor.</p> <p>Parameters:</p> <ul> <li> <code>array</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor whose shape and dtype will be used.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. If None, uses the device of the input tensor.</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, tensor will track gradients. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor of zeros with the same shape and dtype as the input tensor.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; zeros_like(x)\nTensor([[0, 0], [0, 0]])\n</code></pre>"},{"location":"ndarray/","title":"NDArray","text":"<p>NDArray implementation with multiple backend support.</p> <p>This module provides the core NDArray class that supports multiple backends including NumPy, CPU, and CUDA. The NDArray class is a Python wrapper for handling operations on n-dimensional arrays with strided memory layout, enabling efficient memory usage and fast operations.</p> <p>The module implements a flexible array system that can work with different computational backends while maintaining a consistent interface. It supports advanced features like broadcasting, strided memory access, and device abstraction for cross-platform compatibility.</p> Key Features <ul> <li>Strided memory layout for efficient array operations</li> <li>Multiple backend support (NumPy, CPU, CUDA)</li> <li>Broadcasting and reshaping without memory copying</li> <li>Element-wise and scalar operations</li> <li>Matrix operations and reductions</li> <li>Device abstraction for cross-platform compatibility</li> <li>Memory-efficient views and slicing operations</li> <li>Automatic memory management and optimization</li> </ul> <p>Classes:</p> <ul> <li> <code>BackendDevice</code>           \u2013            <p>Device abstraction that wraps backend implementation modules. Provides a unified interface for different computational backends.</p> </li> <li> <code>NDArray</code>           \u2013            <p>Multi-dimensional array with strided memory layout. Supports efficient operations on n-dimensional data with automatic memory optimization and device management.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>cpu_numpy</code>             \u2013              <p>Create a NumPy-based CPU device.</p> </li> <li> <code>cpu</code>             \u2013              <p>Create a native CPU device.</p> </li> <li> <code>cuda</code>             \u2013              <p>Create a CUDA device for GPU computation.</p> </li> <li> <code>default_device</code>             \u2013              <p>Get the default computational device.</p> </li> <li> <code>array</code>             \u2013              <p>Create an NDArray from array-like input.</p> </li> <li> <code>empty</code>             \u2013              <p>Create an uninitialized NDArray with given shape.</p> </li> <li> <code>full</code>             \u2013              <p>Create an NDArray filled with a constant value.</p> </li> <li> <code>broadcast_to</code>             \u2013              <p>Broadcast an array to a new shape without copying memory.</p> </li> <li> <code>reshape</code>             \u2013              <p>Reshape an array without copying memory.</p> </li> <li> <code>maximum</code>             \u2013              <p>Element-wise maximum of two arrays.</p> </li> <li> <code>log</code>             \u2013              <p>Natural logarithm of array elements.</p> </li> <li> <code>exp</code>             \u2013              <p>Exponential of array elements.</p> </li> <li> <code>tanh</code>             \u2013              <p>Hyperbolic tangent of array elements.</p> </li> <li> <code>summation</code>             \u2013              <p>Sum of array elements over specified axes.</p> </li> <li> <code>negative</code>             \u2013              <p>Element-wise negation of array.</p> </li> <li> <code>flip</code>             \u2013              <p>Reverse the order of elements along specified axes.</p> </li> </ul> Notes <p>The NDArray system is designed for efficiency and flexibility. It uses strided memory layout to enable operations like transposing and reshaping without copying data. The backend device system allows seamless switching between different computational platforms while maintaining consistent behavior.</p> <p>All operations are optimized for the current backend and automatically handle memory management, device transfers, and computational optimization.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tiny_pytorch as tp\n&gt;&gt;&gt; # Create arrays on different devices\n&gt;&gt;&gt; x = tp.array([1, 2, 3], device=tp.cpu())\n&gt;&gt;&gt; y = tp.array([4, 5, 6], device=tp.cuda())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Perform operations\n&gt;&gt;&gt; z = x + y  # Element-wise addition\n&gt;&gt;&gt; w = x @ y  # Matrix multiplication\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Shape manipulation\n&gt;&gt;&gt; reshaped = x.reshape((3, 1))\n&gt;&gt;&gt; broadcasted = x.broadcast_to((2, 3))\n</code></pre>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice","title":"<code>BackendDevice</code>","text":"<p>Backend device that wraps the implementation module for each device.</p> <p>This class provides a unified interface for different backend implementations (numpy, CPU, CUDA) by forwarding operations to the appropriate module.</p> <p>Attributes:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Name of the device (e.g., \"cpu\", \"cuda\", \"cpu_numpy\").</p> </li> <li> <code>module</code>               (<code>object</code>)           \u2013            <p>The backend implementation module that handles actual operations.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Check if two devices are equal.</p> <p>Two devices are equal if they have the same name.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>object</code>)           \u2013            <p>Device to compare with.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>True if devices have the same name.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.__getattr__","title":"<code>__getattr__(name)</code>","text":"<p>Forward attribute access to the implementation module.</p> <p>All attempts to get attribute from device will be forwarded to the module that implements the device's operations. i.e. device.op will become self.module.op</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Name of the attribute to access.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>object</code>           \u2013            <p>Attribute from the implementation module.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.__init__","title":"<code>__init__(name, module=None)</code>","text":"<p>Initialize a new BackendDevice.</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Name of the device.</p> </li> <li> <code>module</code>               (<code>object</code>, default:                   <code>None</code> )           \u2013            <p>Module that implements the device's operations.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of the device.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>String representation showing the device name.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.empty","title":"<code>empty(shape, dtype='float32')</code>","text":"<p>Create an empty array.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>Shape of the array.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the array. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Empty array with the specified shape.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.enabled","title":"<code>enabled()</code>","text":"<p>Check if the device is enabled.</p> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>True if the device has an implementation module.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.full","title":"<code>full(shape, fill_value, dtype='float32')</code>","text":"<p>Create an array filled with a constant value.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>Shape of the array.</p> </li> <li> <code>fill_value</code>               (<code>float</code>)           \u2013            <p>Value to fill the array with.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the array. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Array filled with the specified value.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.one_hot","title":"<code>one_hot(n, i, dtype='float32')</code>","text":"<p>Create a one-hot encoded array.</p> <p>Parameters:</p> <ul> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>Number of classes.</p> </li> <li> <code>i</code>               (<code>int or array - like</code>)           \u2013            <p>Indices to encode.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the array. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>One-hot encoded array.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.rand","title":"<code>rand(*shape, dtype='float32')</code>","text":"<p>Generate random numbers from uniform distribution.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>Shape of the output array.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the array. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Array with random values from U[0, 1).</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.BackendDevice.randn","title":"<code>randn(*shape, dtype='float32')</code>","text":"<p>Generate random numbers from standard normal distribution.</p> <p>Parameters:</p> <ul> <li> <code>*shape</code>               (<code>int</code>, default:                   <code>()</code> )           \u2013            <p>Shape of the output array.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the array. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Array with random values from N(0, 1).</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray","title":"<code>NDArray</code>","text":"<p>A generic ND array class that may contain multiple different backends.</p> <p>NDArray is basically a Python wrapper for handling operations on n-dimensional arrays. The underlying array is just a flat 1D array and the backend device will handle all the ops on the 1D array. Strides, shape, and offset allows us to map n-dimensional (logical) array to the 1D flat array that are physically allocated in memory.</p> <p>The high level ops such as broadcasting and transposing are all done in Python without touching the underlying array. The other <code>raw</code> ops such as addition and matrix-multiplication will be implemented in C/C++ that would call highly optimized Kernels for such ops such as CUDA Kernels.</p> <p>To make the backend code simpler, we will only operate on compact arrays so we need to call <code>compact()</code> before any ops AND we support only float32 data type.</p> <p>Attributes:</p> <ul> <li> <code>device</code>               (<code>BackendDevice</code>)           \u2013            <p>Device that handles the operations.</p> </li> <li> <code>shape</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>Shape of the array.</p> </li> <li> <code>strides</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>Strides for accessing elements in the underlying 1D array.</p> </li> <li> <code>size</code>               (<code>int</code>)           \u2013            <p>Total number of elements in the array.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>Number of dimensions in the array.</p> </li> <li> <code>dtype</code>               (<code>str</code>)           \u2013            <p>Data type of the array (currently only \"float32\" is supported).</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.flat","title":"<code>flat</code>  <code>property</code>","text":"<p>Return a 1-D view (flattened) of the array.</p> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>A 1-dimensional view of the array with the same data.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; a = NDArray([[1, 2], [3, 4]])\n&gt;&gt;&gt; a.flat\nNDArray([1, 2, 3, 4], device=cpu_numpy())\n</code></pre>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.__getitem__","title":"<code>__getitem__(idxs)</code>","text":"<p>Parameters:</p> <ul> <li> <code>idxs</code>           \u2013            <p>Indices to the subset of the n-dimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>NDArray corresponding to the selected subset of elements.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AssertionError</code>             \u2013            <p>If a slice has negative step, or if number of slices is not equal to the number of dimensions.</p> </li> <li> <code>TypeError</code>             \u2013            <p>If an index is not an int or slice.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.__init__","title":"<code>__init__(other, device=None)</code>","text":"<p>Create NDArray by copying another NDArray/Numpy array OR use Numpy as a bridge for all other types of iterables.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>NDArray or ndarray or array_like</code>)           \u2013            <p>Source data to create the NDArray from.</p> </li> <li> <code>device</code>               (<code>BackendDevice</code>, default:                   <code>None</code> )           \u2013            <p>Device to place the array on. If None, uses default device.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Matrix multiplication of two arrays.  This requires that both arrays be 2D (i.e., we don't handle batch matrix multiplication), and that the sizes match up properly for matrix multiplication.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.__setitem__","title":"<code>__setitem__(idxs, other)</code>","text":"<p>Set the values of a view into an array, using the same semantics as getitem().</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.as_strided","title":"<code>as_strided(shape, strides)</code>","text":"<p>Create a strided view of the underlying memory without copying anything.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.broadcast_to","title":"<code>broadcast_to(new_shape)</code>","text":"<p>Broadcast an array to a new shape.  <code>new_shape</code>'s elements must be the same as the original shape, except for dimensions in the self where the size = 1 (which can then be broadcast to any size). This will not copy memory, and just achieves broadcasting by manipulating the strides.</p> <p>Parameters:</p> <ul> <li> <code>new_shape</code>           \u2013            <p>Shape to broadcast to.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>          \u2013            <p>New NDArray object with the new broadcast shape; should point to the same memory as the original array.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AssertionError</code>             \u2013            <p>If new_shape[i] != shape[i] for all i where shape[i] != 1</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.compact","title":"<code>compact()</code>","text":"<p>Convert NDArray to be compact if it is not already compact.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.compact_strides","title":"<code>compact_strides(shape)</code>  <code>staticmethod</code>","text":"<p>Utility function to compute compact strides.</p> <p>N-dimensional arrays are represented (with row-major order) contiguously from the inner most dimension to the outer most dimension. Examples:   1. 4 x 3 array will be represented physically in memory with first   row (3 elements) then the second and so on -&gt; strides = (3, 1)   2. 4 x 3 x 2 array will be represented with inner most dimension   first until its done (2 in this case), then next outer dimension   (3 rows of 2), finally outer most dimension which has 4 (3 x 2)   arrays -&gt; strides = (6, 2, 1)</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.ewise_or_scalar","title":"<code>ewise_or_scalar(other, ewise_func, scalar_func)</code>","text":"<p>Run either an element-wise or scalar version of a function, depending on whether \"other\" is an NDArray or scalar.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.fill","title":"<code>fill(value)</code>","text":"<p>Fill in-place with a constant value.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.flip","title":"<code>flip(axes=None)</code>","text":"<p>Reverse (flip) the order of elements in the array along the specified axes.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple[int, ...] or None</code>, default:                   <code>None</code> )           \u2013            <p>Axes along which to flip the array. Each axis index must be valid for the array's dimensions. If None, flip over all axes (reverse the array in every dimension).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>A view of the array with the entries reversed along the specified axes.</p> </li> </ul> Notes <p>This operation does not copy the data; it returns a view with modified strides and offset. The result is compacted before being returned.</p> <p>Raises:</p> <ul> <li> <code>AxisError</code>             \u2013            <p>If the number of axes is greater than the number of dimensions, or if any axis is out of bounds.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; a = NDArray([[1, 2], [3, 4]])\n&gt;&gt;&gt; a.flip((0,))\nNDArray([[3, 4], [1, 2]], device=cpu_numpy())\n&gt;&gt;&gt; a.flip((1,))\nNDArray([[2, 1], [4, 3]], device=cpu_numpy())\n&gt;&gt;&gt; a.flip((0, 1))\nNDArray([[4, 3], [2, 1]], device=cpu_numpy())\n&gt;&gt;&gt; a.flip()  # or a.flip(None)\nNDArray([[4, 3], [2, 1]], device=cpu_numpy())\n</code></pre>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.is_compact","title":"<code>is_compact()</code>","text":"<p>Return true if array is compact in memory and internal size equals product of the shape dimensions.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.make","title":"<code>make(shape, strides=None, device=None, handle=None, offset=0)</code>  <code>staticmethod</code>","text":"<p>Create a new NDArray with the given properties. Memory will only be allocated if <code>handle</code> is None, otherwise it will use the same underlying memory.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.max","title":"<code>max(axis=None, keepdims=False)</code>","text":"<p>Max either across all axis (when axis=None) or one axis.</p> <p>Note: It doesn't support axis being multiple of axes.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.numpy","title":"<code>numpy()</code>","text":"<p>Convert the NDArray to a NumPy array.</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>NumPy array with the same data.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.pad","title":"<code>pad(axes)</code>","text":"<p>Pad the array with zeros along each axis according to the specified padding widths.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple[tuple[int, int], ...]</code>)           \u2013            <p>A tuple specifying the number of values padded to the edges of each axis. Each element should be a tuple of two integers (pad_before, pad_after), where pad_before is the number of values padded before the first element and pad_after is the number of values padded after the last element for that axis. The length of axes must match the number of dimensions of the array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>A new NDArray with the specified padding applied, filled with zeros in the padded regions.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AssertionError</code>             \u2013            <p>If the length of axes does not match the number of dimensions of the array.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; a = NDArray([[1, 2], [3, 4]])\n&gt;&gt;&gt; a.pad(((1, 1), (2, 2)))\nNDArray(\n    [[0, 0, 0, 0, 0, 0],\n     [0, 0, 1, 2, 0, 0],\n     [0, 0, 3, 4, 0, 0],\n     [0, 0, 0, 0, 0, 0]], device=cpu_numpy())\n</code></pre>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.permute","title":"<code>permute(new_axes)</code>","text":"<p>Permute order of the dimensions. <code>new_axes</code> describes a permutation of the existing axes, Example:</p> <ul> <li>If we have an array with dimension \"BHWC\" then     <code>.permute((0,3,1,2))</code>     would convert this to \"BCHW\" order.</li> <li>For a 2D array, <code>.permute((1,0))</code> would transpose the array.</li> </ul> <p>Like <code>reshape</code>, this operation should not copy memory, but achieves the permuting by just adjusting the shape/strides of the array.  That is, it returns a new array that has the dimensions permuted as desired, but which points to the same memory as the original array.</p> <p>Parameters:</p> <ul> <li> <code>new_axes</code>           \u2013            <p>Permutation order of the dimensions.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDarray</code>           \u2013            <p>New NDArray object with permuted dimensions, pointing to the same memory as the original NDArray (i.e., just shape and strides changed).</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.reduce_view_out","title":"<code>reduce_view_out(axis, keepdims=False)</code>","text":"<p>Return a view to the array set up for reduction functions and output array.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.reshape","title":"<code>reshape(new_shape)</code>","text":"<p>Reshape the array without copying memory.  This will return a new array (view) that corresponds to a reshaped array but points to the same memory as the original array. Therefore, we only change the shape and the strides to get the new n-dimensional logical view of the array.</p> <p>Parameters:</p> <ul> <li> <code>new_shape</code>           \u2013            <p>New shape of the array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Reshaped array; this will point to the same memory as the original NDArray.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If product of current shape is not equal to the product of the new shape, or if the matrix is not compact.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.sum","title":"<code>sum(axis=None, keepdims=False)</code>","text":"<p>Sum either across all axis (when axis=None) or one axis.</p> <p>Note: It doesn't support axis being multiple of axes.</p>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.NDArray.to","title":"<code>to(device)</code>","text":"<p>Move the array to a different device.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>BackendDevice</code>)           \u2013            <p>Target device.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Array on the target device.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.all_devices","title":"<code>all_devices()</code>","text":"<p>Get a list of all available devices.</p> <p>Returns:</p> <ul> <li> <code>list[BackendDevice]</code>           \u2013            <p>List of all available devices.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.array","title":"<code>array(a, dtype='float32', device=None)</code>","text":"<p>Create an NDArray from array-like data.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>array_like</code>)           \u2013            <p>Input data to create the array from.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the array. Default is \"float32\".</p> </li> <li> <code>device</code>               (<code>BackendDevice</code>, default:                   <code>None</code> )           \u2013            <p>Device to place the array on. If None, uses default device.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>New NDArray with the specified data.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.broadcast_to","title":"<code>broadcast_to(array, new_shape)</code>","text":"<p>Broadcast an array to a new shape.</p> <p>Parameters:</p> <ul> <li> <code>array</code>               (<code>NDArray</code>)           \u2013            <p>Array to broadcast.</p> </li> <li> <code>new_shape</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>Target shape for broadcasting.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Broadcasted array.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.cpu","title":"<code>cpu()</code>","text":"<p>Create a CPU device with native backend if available.</p> <p>Attempts to use the native CPU backend, falls back to NumPy if the C++ extension is not available.</p> <p>Returns:</p> <ul> <li> <code>BackendDevice</code>           \u2013            <p>CPU device with best available backend.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.cpu_numpy","title":"<code>cpu_numpy()</code>","text":"<p>Create a CPU device using NumPy backend.</p> <p>Returns:</p> <ul> <li> <code>BackendDevice</code>           \u2013            <p>CPU device with NumPy backend.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.cuda","title":"<code>cuda()</code>","text":"<p>Create a CUDA device if available.</p> <p>Returns:</p> <ul> <li> <code>BackendDevice</code>           \u2013            <p>CUDA device, or disabled device if CUDA is not available.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.default_device","title":"<code>default_device()</code>","text":"<p>Return the default device (CPU with NumPy backend).</p> <p>Returns:</p> <ul> <li> <code>BackendDevice</code>           \u2013            <p>Default CPU device.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.empty","title":"<code>empty(shape, dtype='float32', device=None)</code>","text":"<p>Create an empty NDArray.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>Shape of the array.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the array. Default is \"float32\".</p> </li> <li> <code>device</code>               (<code>BackendDevice</code>, default:                   <code>None</code> )           \u2013            <p>Device to place the array on. If None, uses default device.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Empty NDArray with the specified shape.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.exp","title":"<code>exp(a)</code>","text":"<p>Exponential, element-wise.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>NDArray</code>)           \u2013            <p>Input array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Exponential of a, element-wise.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.flip","title":"<code>flip(a, axes)</code>","text":"<p>Reverse (flip) the order of elements in an array along the specified axes.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>NDArray</code>)           \u2013            <p>Input array to be flipped.</p> </li> <li> <code>axes</code>               (<code>tuple[int, ...] or None</code>)           \u2013            <p>Axes along which to flip the array. Each axis index must be valid for the array's dimensions. If None, flip over all axes (reverse the array in every dimension).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>A view of the array with the entries reversed along the specified axes.</p> </li> </ul> Notes <p>This operation does not copy the data; it returns a view with modified strides and offset. The result is compacted before being returned.</p> <p>Raises:</p> <ul> <li> <code>AxisError</code>             \u2013            <p>If the number of axes is greater than the number of dimensions, or if any axis is out of bounds.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; a = NDArray([[1, 2], [3, 4]])\n&gt;&gt;&gt; flip(a, (0,))\nNDArray([[3, 4], [1, 2]], device=cpu_numpy())\n&gt;&gt;&gt; flip(a, (1,))\nNDArray([[2, 1], [4, 3]], device=cpu_numpy())\n&gt;&gt;&gt; flip(a, (0, 1))\nNDArray([[4, 3], [2, 1]], device=cpu_numpy())\n&gt;&gt;&gt; flip(a, None)\nNDArray([[4, 3], [2, 1]], device=cpu_numpy())\n</code></pre>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.full","title":"<code>full(shape, fill_value, dtype='float32', device=None)</code>","text":"<p>Create an NDArray filled with a constant value.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>Shape of the array.</p> </li> <li> <code>fill_value</code>               (<code>float</code>)           \u2013            <p>Value to fill the array with.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the array. Default is \"float32\".</p> </li> <li> <code>device</code>               (<code>BackendDevice</code>, default:                   <code>None</code> )           \u2013            <p>Device to place the array on. If None, uses default device.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>NDArray filled with the specified value.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.log","title":"<code>log(a)</code>","text":"<p>Natural logarithm, element-wise.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>NDArray</code>)           \u2013            <p>Input array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Natural logarithm of a, element-wise.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.maximum","title":"<code>maximum(a, b)</code>","text":"<p>Element-wise maximum of array elements.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>NDArray</code>)           \u2013            <p>First array.</p> </li> <li> <code>b</code>               (<code>NDArray or float</code>)           \u2013            <p>Second array or scalar value.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Array containing the element-wise maximum of a and b.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.negative","title":"<code>negative(a)</code>","text":"<p>Numerical negative, element-wise.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>NDArray</code>)           \u2013            <p>Input array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Returned array or scalar: y = -x.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; a = NDArray([1, -1, 2.5])\n&gt;&gt;&gt; negative(a)\nNDArray([-1.0, 1.0, -2.5], device=cpu_numpy())\n</code></pre> <pre><code>&gt;&gt;&gt; b = NDArray([[1, 2], [3, 4]])\n&gt;&gt;&gt; negative(b)\nNDArray([[-1.0, -2.0], [-3.0, -4.0]], device=cpu_numpy())\n</code></pre>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.reshape","title":"<code>reshape(array, new_shape)</code>","text":"<p>Reshape an array to a new shape.</p> <p>Parameters:</p> <ul> <li> <code>array</code>               (<code>NDArray</code>)           \u2013            <p>Array to reshape.</p> </li> <li> <code>new_shape</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>New shape of the array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Reshaped array.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the product of the new shape is not equal to the product of the original shape, or if the array is not compact.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.summation","title":"<code>summation(a, axis=None, keepdims=False)</code>","text":"<p>Sum of array elements over a given axis.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>NDArray</code>)           \u2013            <p>Input array.</p> </li> <li> <code>axis</code>               (<code>int or None</code>, default:                   <code>None</code> )           \u2013            <p>Axis along which a sum is performed. The default, axis=None, will sum all of the elements of the input array. If axis is negative it counts from the last to the first axis.</p> <p>Note: Only supports reduction over a single axis or all axes. Multiple axes reduction is not supported.</p> </li> <li> <code>keepdims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>An array with the same shape as a, with the specified axis removed. If a is a 0-d array, or if axis is None, a scalar is returned. If an output array is specified, a reference to out is returned.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an empty axis tuple is provided.</p> </li> </ul>"},{"location":"ndarray/#tiny_pytorch.backend_ndarray.ndarray.tanh","title":"<code>tanh(a)</code>","text":"<p>Hyperbolic tangent, element-wise.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>NDArray</code>)           \u2013            <p>Input array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Hyperbolic tangent of a, element-wise.</p> </li> </ul>"},{"location":"nlp-models/","title":"Models","text":"<p>Natural Language Processing models for tiny-pytorch implementation.</p> <p>This module provides pre-built neural network architectures for natural language processing tasks, specifically designed for sequence modeling and language understanding. The models are built using the core neural network components from the tiny-pytorch framework.</p> <p>The module includes implementations of popular language model architectures adapted for the tiny-pytorch ecosystem, focusing on efficiency and educational value while maintaining compatibility with the framework's tensor operations and automatic differentiation system.</p> Key Features <ul> <li>Pre-built language models for sequence prediction</li> <li>Support for both RNN and LSTM sequence models</li> <li>Configurable embedding and hidden layer dimensions</li> <li>Multi-layer sequence model architectures</li> <li>Efficient implementations optimized for the tiny-pytorch framework</li> <li>Educational models that demonstrate modern NLP design patterns</li> </ul> <p>Classes:</p> <ul> <li> <code>LanguageModel</code>           \u2013            <p>A complete language model architecture for sequence prediction tasks. Features an embedding layer, configurable sequence model (RNN/LSTM), and output projection layer. Designed for next-word prediction, text generation, and other sequence modeling applications.</p> </li> </ul> Notes <p>All models in this module are designed to work with the tiny-pytorch tensor system and support automatic differentiation. Input sequences should be provided as token indices, and models output logits for next-token prediction.</p> <p>The sequence models support both single and multi-layer architectures, with configurable hidden dimensions. The embedding layer maps from vocabulary size to a learned embedding space, while the output layer projects back to vocabulary size for next-token prediction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from tiny_pytorch.nlp.models import LanguageModel\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a language model for text generation\n&gt;&gt;&gt; model = LanguageModel(\n...     embedding_size=128,\n...     output_size=1000,  # vocabulary size\n...     hidden_size=256,\n...     num_layers=2,\n...     seq_model='lstm'\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Prepare input data (seq_len=10, batch_size=32)\n&gt;&gt;&gt; x = Tensor.randint(0, 1000, (10, 32))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Forward pass to get next-token predictions\n&gt;&gt;&gt; logits, hidden = model(x)\n&gt;&gt;&gt; print(logits.shape)  # (320, 1000) - (seq_len*batch_size, vocab_size)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # The model is ready for training with appropriate loss functions\n&gt;&gt;&gt; # and optimizers from the tiny-pytorch framework\n</code></pre>"},{"location":"nlp-models/#tiny_pytorch.nlp.models.LanguageModel","title":"<code>LanguageModel</code>","text":"<p>               Bases: <code>Module</code></p> <p>A language model for sequence prediction tasks.</p> <p>This module implements a complete language model architecture consisting of an embedding layer, a sequence model (RNN or LSTM), and a linear output layer. It is designed for tasks like next-word prediction, text generation, and other sequence modeling applications.</p> <p>The model architecture follows this pattern: 1. Embedding layer: Converts input token indices to dense vectors 2. Sequence model: Processes the embedded sequence (RNN or LSTM) 3. Linear layer: Projects the final hidden states to vocabulary logits</p> <p>Parameters:</p> <ul> <li> <code>num_embeddings</code>               (<code>int</code>)           \u2013            <p>The size of the vocabulary (number of unique tokens).</p> </li> <li> <code>embedding_dim</code>               (<code>int</code>)           \u2013            <p>The dimensionality of the embedding vectors.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state of the sequence model.</p> </li> <li> <code>num_layers</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of layers in the RNN or LSTM. Default is 1.</p> </li> <li> <code>seq_model</code>               (<code>str</code>, default:                   <code>'rnn'</code> )           \u2013            <p>Type of sequence model to use. Must be either 'rnn' or 'lstm'. Default is 'rnn'.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the model parameters. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the model parameters. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>output_size</code>               (<code>int</code>)           \u2013            <p>The size of the vocabulary.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state.</p> </li> <li> <code>embed</code>               (<code>Embedding</code>)           \u2013            <p>The embedding layer that converts token indices to vectors.</p> </li> <li> <code>seq_model</code>               (<code>RNN or LSTM</code>)           \u2013            <p>The sequence model (RNN or LSTM) for processing the embedded sequence.</p> </li> <li> <code>linear</code>               (<code>Linear</code>)           \u2013            <p>The output linear layer that projects to vocabulary logits.</p> </li> </ul> Notes <ul> <li>Input sequences should be provided as token indices in shape (seq_len, batch_size).</li> <li>The model outputs logits for next-token prediction at each position.</li> <li>Supports both RNN and LSTM sequence models with configurable layers.</li> <li>The embedding layer maps from vocabulary size to embedding dimension.</li> <li>The linear layer projects from hidden size back to vocabulary size.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; model = LanguageModel(\n...     embedding_size=128,\n...     output_size=1000,  # vocabulary size\n...     hidden_size=256,\n...     num_layers=2,\n...     seq_model='lstm'\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Input: (seq_len=10, batch_size=32)\n&gt;&gt;&gt; x = Tensor.randint(0, 1000, (10, 32))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Forward pass\n&gt;&gt;&gt; logits, hidden = model(x)\n&gt;&gt;&gt; print(logits.shape)  # (320, 1000) - (seq_len*batch_size, vocab_size)\n&gt;&gt;&gt; print(hidden[0].shape if isinstance(hidden, tuple) else hidden.shape)\n&gt;&gt;&gt; # (2, 32, 256) - (num_layers, batch_size, hidden_size)\n</code></pre>"},{"location":"nlp-models/#tiny_pytorch.nlp.models.LanguageModel.__init__","title":"<code>__init__(num_embeddings, embedding_dim, hidden_size, num_layers=1, seq_model='rnn', device=None, dtype='float32')</code>","text":"<p>Initialize the LanguageModel.</p> <p>Parameters:</p> <ul> <li> <code>num_embeddings</code>               (<code>int</code>)           \u2013            <p>The size of the vocabulary (number of unique tokens).</p> </li> <li> <code>embedding_dim</code>               (<code>int</code>)           \u2013            <p>The dimensionality of the embedding vectors.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state of the sequence model.</p> </li> <li> <code>num_layers</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of layers in the RNN or LSTM. Default is 1.</p> </li> <li> <code>seq_model</code>               (<code>str</code>, default:                   <code>'rnn'</code> )           \u2013            <p>Type of sequence model to use. Must be either 'rnn' or 'lstm'. Default is 'rnn'.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the model parameters. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the model parameters. Default is \"float32\".</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AssertionError</code>             \u2013            <p>If seq_model is not 'rnn' or 'lstm'.</p> </li> </ul>"},{"location":"nlp-models/#tiny_pytorch.nlp.models.LanguageModel.forward","title":"<code>forward(x, h=None)</code>","text":"<p>Forward pass of the language model.</p> <p>Given an input sequence of token indices, returns logits for next-token prediction along with the final hidden state from the sequence model.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (seq_len, batch_size) containing token indices. Each element should be an integer index in the range [0, output_size).</p> </li> <li> <code>h</code>               (<code>Tensor or tuple of (Tensor, Tensor) or None</code>, default:                   <code>None</code> )           \u2013            <p>Initial hidden state for the sequence model. - For RNN: Tensor of shape (num_layers, batch_size, hidden_size) - For LSTM: Tuple of (h0, c0), each of shape (num_layers, batch_size, hidden_size) - If None, defaults to zeros for RNN or (zeros, zeros) for LSTM.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>logits</code> (              <code>Tensor</code> )          \u2013            <p>Output tensor of shape (seq_len * batch_size, output_size) containing logits for next-token prediction at each position in the sequence.</p> </li> <li> <code>hidden</code> (              <code>Tensor or tuple of (Tensor, Tensor)</code> )          \u2013            <p>Final hidden state from the sequence model. - For RNN: Tensor of shape (num_layers, batch_size, hidden_size) - For LSTM: Tuple of (h_n, c_n), each of shape (num_layers, batch_size, hidden_size)</p> </li> </ul> Notes <p>The output logits are flattened across the sequence dimension, so each position in the sequence contributes batch_size predictions. This is useful for training with cross-entropy loss where each position is treated as a separate prediction task.</p>"},{"location":"nn/","title":"NN","text":"<p>Neural network module for tiny-pytorch implementation.</p> <p>This module provides a comprehensive set of classes and functions for building neural networks. It includes fundamental building blocks like layers, activation functions, normalization modules, and specialized components for various types of neural network architectures.</p> <p>The module is designed to work seamlessly with the automatic differentiation system, allowing for easy construction and training of complex neural networks. All modules inherit from the base <code>Module</code> class, providing consistent interfaces for parameter management, training mode control, and forward pass computation.</p> Key Features <ul> <li>Automatic parameter management and gradient tracking</li> <li>Training/evaluation mode switching</li> <li>Modular design for easy network construction</li> <li>Support for various neural network architectures</li> <li>Built-in activation functions and loss functions</li> <li>Normalization layers (BatchNorm, LayerNorm)</li> <li>Recurrent neural network components (RNN, LSTM)</li> <li>Convolutional neural network layers and composite blocks</li> <li>Embedding layers for sequence processing</li> </ul> <p>Classes:</p> <ul> <li> <code>Module</code>           \u2013            <p>Base class for all neural network modules. Provides common functionality for parameter management, training mode control, and forward pass computation.</p> </li> <li> <code>Parameter</code>           \u2013            <p>A special kind of tensor that represents learnable parameters. Acts as a marker so modules can identify trainable parameters. All Parameter tensors have require_grad set to True.</p> </li> <li> <code>ReLU</code>           \u2013            <p>Rectified Linear Unit activation function.</p> </li> <li> <code>Tanh</code>           \u2013            <p>Hyperbolic tangent activation function.</p> </li> <li> <code>Sigmoid</code>           \u2013            <p>Sigmoid activation function.</p> </li> <li> <code>Linear</code>           \u2013            <p>Linear transformation layer (fully connected layer).</p> </li> <li> <code>Flatten</code>           \u2013            <p>Flattens the input tensor into a 2D tensor.</p> </li> <li> <code>BatchNorm1d</code>           \u2013            <p>1D batch normalization layer for fully connected networks.</p> </li> <li> <code>BatchNorm2d</code>           \u2013            <p>2D batch normalization layer for convolutional networks.</p> </li> <li> <code>LayerNorm1d</code>           \u2013            <p>1D layer normalization layer.</p> </li> <li> <code>Dropout</code>           \u2013            <p>Dropout layer for regularization during training.</p> </li> <li> <code>Sequential</code>           \u2013            <p>Sequential container that applies modules in order.</p> </li> <li> <code>Residual</code>           \u2013            <p>Residual connection that adds input to the output of a module.</p> </li> <li> <code>SoftmaxLoss</code>           \u2013            <p>Softmax cross-entropy loss function.</p> </li> <li> <code>Conv</code>           \u2013            <p>2D convolutional layer with support for padding and stride.</p> </li> <li> <code>ConvBN</code>           \u2013            <p>Composite module combining convolution, batch normalization, and ReLU activation. Common building block in modern CNN architectures like ResNet.</p> </li> <li> <code>RNNCell</code>           \u2013            <p>Single RNN cell with tanh or ReLU nonlinearity.</p> </li> <li> <code>RNN</code>           \u2013            <p>Multi-layer RNN with tanh or ReLU nonlinearity.</p> </li> <li> <code>LSTMCell</code>           \u2013            <p>Single LSTM cell with forget, input, and output gates.</p> </li> <li> <code>LSTM</code>           \u2013            <p>Multi-layer LSTM network.</p> </li> <li> <code>Embedding</code>           \u2013            <p>Embedding layer for converting indices to dense vectors.</p> </li> </ul> Notes <p>All modules support automatic differentiation through the tensor system. Parameters are automatically tracked and gradients are computed during backward passes. The training mode affects the behavior of certain modules like Dropout and BatchNorm, which behave differently during training and evaluation.</p> <p>The module system is designed to be composable, allowing complex networks to be built from simple building blocks. The Sequential and Residual containers provide convenient ways to combine multiple modules.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tiny_pytorch as tp\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a simple feedforward network\n&gt;&gt;&gt; model = tp.nn.Sequential(\n...     tp.nn.Linear(784, 128),\n...     tp.nn.ReLU(),\n...     tp.nn.Dropout(0.5),\n...     tp.nn.Linear(128, 10)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a convolutional network\n&gt;&gt;&gt; conv_model = tp.nn.Sequential(\n...     tp.nn.Conv(3, 64, kernel_size=3),\n...     tp.nn.BatchNorm2d(64),\n...     tp.nn.ReLU(),\n...     tp.nn.Flatten(),\n...     tp.nn.Linear(64 * 28 * 28, 10)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create an RNN for sequence processing\n&gt;&gt;&gt; rnn = tp.nn.RNN(input_size=100, hidden_size=64, num_layers=2)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use the model\n&gt;&gt;&gt; x = tp.Tensor.randn(32, 784)  # batch_size=32, features=784\n&gt;&gt;&gt; output = model(x)  # Forward pass\n</code></pre>"},{"location":"nn/#tiny_pytorch.nn.BatchNorm1d","title":"<code>BatchNorm1d</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies batch normalization to the input tensor.</p> <p>Parameters:</p> <ul> <li> <code>dim</code>               (<code>int</code>)           \u2013            <p>Number of dimensions in the input tensor.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-05</code> )           \u2013            <p>Value added to the denominator for numerical stability. Default is 1e-5.</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>Momentum for the moving average. Default is 0.1.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>dim</code>               (<code>int</code>)           \u2013            <p>Number of dimensions in the input tensor.</p> </li> <li> <code>eps</code>               (<code>float</code>)           \u2013            <p>Value added to the denominator for numerical stability.</p> </li> <li> <code>momentum</code>               (<code>float</code>)           \u2013            <p>Momentum for the moving average.</p> </li> <li> <code>weight</code>               (<code>Parameter</code>)           \u2013            <p>Learnable weight parameter.</p> </li> <li> <code>bias</code>               (<code>Parameter</code>)           \u2013            <p>Learnable bias parameter.</p> </li> <li> <code>running_mean</code>               (<code>Tensor</code>)           \u2013            <p>Running mean of the input tensor.</p> </li> <li> <code>running_var</code>               (<code>Tensor</code>)           \u2013            <p>Running variance of the input tensor.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Applies batch normalization to the input tensor <code>x</code>.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.BatchNorm2d","title":"<code>BatchNorm2d</code>","text":"<p>               Bases: <code>BatchNorm1d</code></p> <p>Applies batch normalization to 2D input tensors.</p> <p>This module applies batch normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper \"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\".</p> <p>The input is expected to be in NCHW format (batch, channels, height, width). For each channel, this layer computes the mean and variance over the batch and spatial dimensions, then normalizes the input and applies learnable scale and shift parameters.</p> <p>Parameters:</p> <ul> <li> <code>num_features</code>               (<code>int</code>)           \u2013            <p>Number of features/channels in the input tensor.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-05</code> )           \u2013            <p>Value added to the denominator for numerical stability. Default is 1e-5.</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>Momentum for the moving average. Default is 0.1.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the parameters. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the parameters. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>num_features</code>               (<code>int</code>)           \u2013            <p>Number of features/channels in the input tensor.</p> </li> <li> <code>eps</code>               (<code>float</code>)           \u2013            <p>Value added to the denominator for numerical stability.</p> </li> <li> <code>momentum</code>               (<code>float</code>)           \u2013            <p>Momentum for the moving average.</p> </li> <li> <code>weight</code>               (<code>Parameter</code>)           \u2013            <p>Learnable weight parameter of shape (num_features,).</p> </li> <li> <code>bias</code>               (<code>Parameter</code>)           \u2013            <p>Learnable bias parameter of shape (num_features,).</p> </li> <li> <code>running_mean</code>               (<code>Tensor</code>)           \u2013            <p>Running mean of the input tensor of shape (num_features,).</p> </li> <li> <code>running_var</code>               (<code>Tensor</code>)           \u2013            <p>Running variance of the input tensor of shape (num_features,).</p> </li> </ul> Notes <ul> <li>Input is expected to be in NCHW format (batch, channels, height, width).</li> <li>During training, this layer keeps a running estimate of its computed mean   and variance, which is then used for normalization during evaluation.</li> <li>The running estimates are kept with a default momentum of 0.1.</li> <li>Internally converts to channel-last format for efficient computation,   similar to PyTorch's implementation.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bn = BatchNorm2d(64)\n&gt;&gt;&gt; x = Tensor.randn(32, 64, 28, 28)  # batch_size=32, channels=64, height=28, width=28\n&gt;&gt;&gt; output = bn(x)  # shape: (32, 64, 28, 28)\n</code></pre>"},{"location":"nn/#tiny_pytorch.nn.BatchNorm2d.__init__","title":"<code>__init__(num_features, eps=1e-05, momentum=0.1, device=None, dtype='float32')</code>","text":"<p>Initialize the BatchNorm2d module.</p> <p>Parameters:</p> <ul> <li> <code>num_features</code>               (<code>int</code>)           \u2013            <p>Number of features/channels in the input tensor.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-05</code> )           \u2013            <p>Value added to the denominator for numerical stability. Default is 1e-5.</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>Momentum for the moving average. Default is 0.1.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the parameters. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the parameters. Default is \"float32\".</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.BatchNorm2d.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the 2D batch normalization.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (batch_size, num_features, height, width) in NCHW format.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Normalized tensor of shape (batch_size, num_features, height, width) in NCHW format.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Conv","title":"<code>Conv</code>","text":"<p>               Bases: <code>Module</code></p> <p>Multi-channel 2D convolutional layer.</p> <p>This module applies a 2D convolution over an input signal composed of several input planes. The input is expected to be in NCHW format (batch, channels, height, width) and the output will also be in NCHW format.</p> <p>Parameters:</p> <ul> <li> <code>in_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels in the input image.</p> </li> <li> <code>out_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels produced by the convolution.</p> </li> <li> <code>kernel_size</code>               (<code>int or tuple of int</code>)           \u2013            <p>Size of the convolving kernel. If a single int is provided, it is used for both height and width dimensions. Only square kernels are supported.</p> </li> <li> <code>stride</code>               (<code>int or tuple of int</code>, default:                   <code>1</code> )           \u2013            <p>Stride of the convolution. If a single int is provided, it is used for both height and width dimensions. Default is 1.</p> </li> <li> <code>bias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, adds a learnable bias to the output. Default is True.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the weights. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the weights. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>in_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels in the input image.</p> </li> <li> <code>out_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels produced by the convolution.</p> </li> <li> <code>kernel_size</code>               (<code>int</code>)           \u2013            <p>Size of the convolving kernel (square kernel).</p> </li> <li> <code>stride</code>               (<code>int</code>)           \u2013            <p>Stride of the convolution.</p> </li> <li> <code>padding</code>               (<code>int</code>)           \u2013            <p>Padding added to both sides of the input. Automatically calculated as (kernel_size - 1) // 2 to maintain same output size.</p> </li> <li> <code>weight</code>               (<code>Parameter</code>)           \u2013            <p>The learnable weights of the module of shape (kernel_size, kernel_size, in_channels, out_channels).</p> </li> <li> <code>bias</code>               (<code>Parameter or None</code>)           \u2013            <p>The learnable bias of the module of shape (out_channels,). None if bias is False.</p> </li> </ul> Notes <ul> <li>Only supports padding='same' (automatic padding to maintain output size).</li> <li>No grouped convolution or dilation support.</li> <li>Only supports square kernels.</li> <li>Input and output are in NCHW format.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; conv = Conv(3, 64, kernel_size=3, stride=1)\n&gt;&gt;&gt; x = Tensor.randn(1, 3, 32, 32)  # batch_size=1, channels=3, height=32, width=32\n&gt;&gt;&gt; output = conv(x)  # shape: (1, 64, 32, 32)\n</code></pre>"},{"location":"nn/#tiny_pytorch.nn.Conv.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the 2D convolution.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (batch_size, in_channels, height, width) in NCHW format.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Output tensor of shape (batch_size, out_channels, height, width) in NCHW format.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.ConvBN","title":"<code>ConvBN</code>","text":"<p>               Bases: <code>Module</code></p> <p>A composite module that combines convolution, batch normalization, and ReLU activation.</p> <p>This module is a common building block in convolutional neural networks, particularly in architectures like ResNet. It applies a 2D convolution followed by batch normalization and ReLU activation in sequence. This combination helps with training stability and convergence speed.</p> <p>The module consists of three components applied in order: 1. Conv: 2D convolutional layer 2. BatchNorm2d: 2D batch normalization layer 3. ReLU: Rectified Linear Unit activation function</p> <p>Parameters:</p> <ul> <li> <code>in_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels in the input image.</p> </li> <li> <code>out_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels produced by the convolution.</p> </li> <li> <code>kernel_size</code>               (<code>int or tuple[int, int]</code>)           \u2013            <p>Size of the convolving kernel. If a single int is provided, it is used for both height and width dimensions. Only square kernels are supported.</p> </li> <li> <code>stride</code>               (<code>int or tuple[int, int]</code>, default:                   <code>1</code> )           \u2013            <p>Stride of the convolution. If a single int is provided, it is used for both height and width dimensions. Default is 1.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the parameters. Default is None (uses default device).</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>conv</code>               (<code>Conv</code>)           \u2013            <p>The 2D convolutional layer.</p> </li> <li> <code>bn</code>               (<code>BatchNorm2d</code>)           \u2013            <p>The 2D batch normalization layer.</p> </li> <li> <code>relu</code>               (<code>ReLU</code>)           \u2013            <p>The ReLU activation function.</p> </li> </ul> Notes <ul> <li>Input is expected to be in NCHW format (batch, channels, height, width).</li> <li>Output maintains the same format as input.</li> <li>The convolution uses padding='same' to maintain spatial dimensions.</li> <li>Batch normalization is applied per-channel across the batch and spatial dimensions.</li> <li>ReLU activation is applied element-wise after batch normalization.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; convbn = ConvBN(3, 64, kernel_size=3, stride=1)\n&gt;&gt;&gt; x = Tensor.randn(32, 3, 28, 28)  # batch_size=32, channels=3, height=28, width=28\n&gt;&gt;&gt; output = convbn(x)  # shape: (32, 64, 28, 28)\n</code></pre>"},{"location":"nn/#tiny_pytorch.nn.ConvBN.__init__","title":"<code>__init__(in_channels, out_channels, kernel_size, stride=1, device=None)</code>","text":"<p>Initialize the ConvBN module.</p> <p>Parameters:</p> <ul> <li> <code>in_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels in the input image.</p> </li> <li> <code>out_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels produced by the convolution.</p> </li> <li> <code>kernel_size</code>               (<code>int or tuple[int, int]</code>)           \u2013            <p>Size of the convolving kernel. If a single int is provided, it is used for both height and width dimensions.</p> </li> <li> <code>stride</code>               (<code>int or tuple[int, int]</code>, default:                   <code>1</code> )           \u2013            <p>Stride of the convolution. If a single int is provided, it is used for both height and width dimensions. Default is 1.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the parameters. Default is None (uses default device).</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.ConvBN.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the ConvBN module.</p> <p>Applies convolution, batch normalization, and ReLU activation in sequence.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (batch_size, in_channels, height, width) in NCHW format.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Output tensor of shape (batch_size, out_channels, height, width) in NCHW format. The output has been processed through convolution, batch normalization, and ReLU.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Dropout","title":"<code>Dropout</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies dropout to the input tensor.</p> <p>Parameters:</p> <ul> <li> <code>p</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>Probability of an element to be dropped. Default is 0.5.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>p</code>               (<code>float</code>)           \u2013            <p>Probability of an element to be dropped.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Applies dropout to the input tensor <code>x</code>.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Embedding","title":"<code>Embedding</code>","text":"<p>               Bases: <code>Module</code></p> <p>A lookup table that stores embeddings of a fixed dictionary and size.</p> <p>This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.</p> <p>Parameters:</p> <ul> <li> <code>vocab_sz</code>               (<code>int</code>)           \u2013            <p>Size of the dictionary of embeddings (number of unique tokens).</p> </li> <li> <code>embedding_dim</code>               (<code>int</code>)           \u2013            <p>The size of each embedding vector.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the embedding weights. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the embedding weights. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>vocab_sz</code>               (<code>int</code>)           \u2013            <p>Size of the dictionary of embeddings.</p> </li> <li> <code>embedding_dim</code>               (<code>int</code>)           \u2013            <p>The size of each embedding vector.</p> </li> <li> <code>weight</code>               (<code>Parameter</code>)           \u2013            <p>The learnable embedding weights of shape <code>(vocab_sz, embedding_dim)</code>. Initialized from N(0, 1) distribution.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Maps word indices to embedding vectors.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; embedding = Embedding(1000, 128)\n&gt;&gt;&gt; input_indices = Tensor([[1, 2, 3], [4, 5, 6]])  # shape: (seq_len, batch_size)\n&gt;&gt;&gt; output = embedding(input_indices)  # shape: (seq_len, batch_size, 128)\n</code></pre>"},{"location":"nn/#tiny_pytorch.nn.Embedding.forward","title":"<code>forward(x)</code>","text":"<p>Maps word indices to embedding vectors.</p> <p>This method converts input indices to one-hot vectors and then projects them to embedding vectors using the learned embedding weights.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor containing indices of shape <code>(seq_len, batch_size)</code>. Each element should be an integer index in the range [0, vocab_sz).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Output tensor of shape <code>(seq_len, batch_size, embedding_dim)</code> containing the corresponding embedding vectors for each input index.</p> </li> </ul> Notes <p>The input indices are converted to one-hot vectors internally, then multiplied with the embedding weight matrix to produce the final embeddings.</p>"},{"location":"nn/#tiny_pytorch.nn.Flatten","title":"<code>Flatten</code>","text":"<p>               Bases: <code>Module</code></p> <p>Flattens the input tensor into a 2D tensor.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor to be flattened.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Flattened tensor.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.LSTM","title":"<code>LSTM</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</p> <p>Parameters:</p> <ul> <li> <code>input_size</code>               (<code>int</code>)           \u2013            <p>The number of expected features in the input x.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>num_layers</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of recurrent layers. Default is 1.</p> </li> <li> <code>bias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If False, then the layer does not use bias weights. Default is True.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the weights. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the weights. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>lstm_cells</code>               (<code>list of LSTMCell</code>)           \u2013            <p>List of LSTMCell modules for each layer.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>num_layers</code>               (<code>int</code>)           \u2013            <p>Number of recurrent layers.</p> </li> <li> <code>device</code>               (<code>Device or None</code>)           \u2013            <p>Device on which the parameters are allocated.</p> </li> <li> <code>dtype</code>               (<code>str</code>)           \u2013            <p>Data type of the parameters.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Compute the output and final hidden and cell states for a batch of input sequences.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.LSTM.forward","title":"<code>forward(X, h=None)</code>","text":"<p>Compute the output and final hidden and cell states for a batch of input sequences.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (seq_len, batch_size, input_size) containing the features of the input sequence.</p> </li> <li> <code>h</code>               (<code>tuple of (Tensor, Tensor) or None</code>, default:                   <code>None</code> )           \u2013            <p>Tuple of (h0, c0), where each is a tensor of shape (num_layers, batch_size, hidden_size). If None, both default to zeros.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code> (              <code>Tensor</code> )          \u2013            <p>Output tensor of shape (seq_len, batch_size, hidden_size) containing the output features (h_t) from the last layer of the LSTM, for each t.</p> </li> <li> <code>(h_n, c_n) : tuple of Tensor</code>           \u2013            <p>Tuple of (h_n, c_n), each of shape (num_layers, batch_size, hidden_size) containing the final hidden and cell states for each element in the batch.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.LSTMCell","title":"<code>LSTMCell</code>","text":"<p>               Bases: <code>Module</code></p> <p>A long short-term memory (LSTM) cell.</p> <p>Parameters:</p> <ul> <li> <code>input_size</code>               (<code>int</code>)           \u2013            <p>The number of expected features in the input X.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>bias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If False, then the layer does not use bias weights. Default is True.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the weights. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the weights. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>W_ih</code>               (<code>Parameter</code>)           \u2013            <p>The learnable input-hidden weights, of shape (input_size, 4 * hidden_size).</p> </li> <li> <code>W_hh</code>               (<code>Parameter</code>)           \u2013            <p>The learnable hidden-hidden weights, of shape (hidden_size, 4 * hidden_size).</p> </li> <li> <code>bias_ih</code>               (<code>Parameter or None</code>)           \u2013            <p>The learnable input-hidden bias, of shape (4 * hidden_size,). None if bias is False.</p> </li> <li> <code>bias_hh</code>               (<code>Parameter or None</code>)           \u2013            <p>The learnable hidden-hidden bias, of shape (4 * hidden_size,). None if bias is False.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>device</code>               (<code>Device or None</code>)           \u2013            <p>Device on which the parameters are allocated.</p> </li> <li> <code>dtype</code>               (<code>str</code>)           \u2013            <p>Data type of the parameters.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Compute the next hidden and cell state given input X and previous states.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.LSTMCell.__init__","title":"<code>__init__(input_size, hidden_size, bias=True, device=None, dtype='float32')</code>","text":"<p>A long short-term memory (LSTM) cell.</p> <p>Parameters:</p> <ul> <li> <code>input_size</code>               (<code>int</code>)           \u2013            <p>The number of expected features in the input X.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>bias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If False, then the layer does not use bias weights. Default is True.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the weights. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the weights. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>W_ih</code>               (<code>Parameter</code>)           \u2013            <p>The learnable input-hidden weights, of shape (input_size, 4 * hidden_size).</p> </li> <li> <code>W_hh</code>               (<code>Parameter</code>)           \u2013            <p>The learnable hidden-hidden weights, of shape (hidden_size, 4 * hidden_size).</p> </li> <li> <code>bias_ih</code>               (<code>Parameter or None</code>)           \u2013            <p>The learnable input-hidden bias, of shape (4 * hidden_size,). None if bias is False.</p> </li> <li> <code>bias_hh</code>               (<code>Parameter or None</code>)           \u2013            <p>The learnable hidden-hidden bias, of shape (4 * hidden_size,). None if bias is False.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>device</code>               (<code>Device or None</code>)           \u2013            <p>Device on which the parameters are allocated.</p> </li> <li> <code>dtype</code>               (<code>str</code>)           \u2013            <p>Data type of the parameters.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>forward</code>             \u2013              <p>Compute the next hidden and cell state given input X and previous states.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.LSTMCell.forward","title":"<code>forward(X, h=None)</code>","text":"<p>Compute the next hidden and cell state for a batch of inputs.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (batch_size, input_size).</p> </li> <li> <code>h</code>               (<code>tuple of (Tensor, Tensor) or None</code>, default:                   <code>None</code> )           \u2013            <p>Tuple of (h0, c0), where each is a tensor of shape (batch_size, hidden_size). If None, both default to zeros.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>h_out</code> (              <code>Tensor</code> )          \u2013            <p>Next hidden state tensor of shape (batch_size, hidden_size).</p> </li> <li> <code>c_out</code> (              <code>Tensor</code> )          \u2013            <p>Next cell state tensor of shape (batch_size, hidden_size).</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.LayerNorm1d","title":"<code>LayerNorm1d</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies layer normalization to the input tensor.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor to apply layer normalization.</p> </li> <li> <code>dim</code>               (<code>int</code>)           \u2013            <p>Dimension to normalize.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-05</code> )           \u2013            <p>Epsilon for numerical stability. Default is 1e-5.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Normalized tensor.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Linear","title":"<code>Linear</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies a linear transformation to the input data.</p> <p>Attributes:</p> <ul> <li> <code>weight</code>               (<code>Tensor</code>)           \u2013            <p>The learnable weights of the module of shape <code>(in_features, out_features)</code>.</p> </li> <li> <code>bias</code>               (<code>(Tensor, optional)</code>)           \u2013            <p>The learnable bias of the module of shape <code>(1, out_features)</code>.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Linear.__init__","title":"<code>__init__(in_features, out_features, bias=True, device=None, dtype='float32')</code>","text":"<p>Parameters:</p> <ul> <li> <code>in_features</code>               (<code>int</code>)           \u2013            <p>Size of each input sample.</p> </li> <li> <code>out_features</code>               (<code>int</code>)           \u2013            <p>Size of each output sample.</p> </li> <li> <code>bias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If set to <code>False</code>, the layer will not learn an additive bias. Default is <code>True</code>.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the tensor. Default is CPU.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the tensor. Default is \"float32\".</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Module","title":"<code>Module</code>","text":"<p>Base class for all neural network modules. Your module should also subclass this.</p> <p>Attributes:</p> <ul> <li> <code>training</code>               (<code>bool</code>)           \u2013            <p>Whether the module is in training mode or not.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Module.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Forward pass of the module.</p> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>The output tensor of the forward pass.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Module.children","title":"<code>children()</code>","text":"<p>Return the list of child modules in the module.</p> <p>Returns:</p> <ul> <li> <code>list[Module]</code>           \u2013            <p>List of child modules in the module.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Module.eval","title":"<code>eval()</code>","text":"<p>Sets the module in evaluation mode.</p> <p>This method sets the <code>training</code> attribute to <code>False</code>, which affects the behavior of certain modules like dropout and batch normalization. It also recursively sets the <code>training</code> attribute of all child modules.</p> Notes <p>This method is a no-op if the module is already in evaluation mode.</p>"},{"location":"nn/#tiny_pytorch.nn.Module.parameters","title":"<code>parameters()</code>","text":"<p>Returns:</p> <ul> <li> <code>list[Tensor]</code>           \u2013            <p>A list of tensors representing the parameters of the module.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Module.train","title":"<code>train()</code>","text":"<p>Sets the module in training mode.</p> <p>This method sets the <code>training</code> attribute to <code>True</code>, which affects the behavior of certain modules like dropout and batch normalization. It also recursively sets the <code>training</code> attribute of all child modules.</p> Notes <p>This method is a no-op if the module is already in training mode.</p>"},{"location":"nn/#tiny_pytorch.nn.Parameter","title":"<code>Parameter</code>","text":"<p>               Bases: <code>Tensor</code></p> <p>A special kind of tensor that represents parameters. It acts as a marker so modules can be able to identify learnable parameters. All <code>Parameter</code> tensors have require_grad set to True.</p>"},{"location":"nn/#tiny_pytorch.nn.RNN","title":"<code>RNN</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies a multi-layer RNN with tanh or ReLU non-linearity to an input sequence.</p> <p>Parameters:</p> <ul> <li> <code>input_size</code>               (<code>int</code>)           \u2013            <p>The number of expected features in the input x.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>num_layers</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of recurrent layers. Default is 1.</p> </li> <li> <code>bias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If False, then the layer does not use bias weights. Default is True.</p> </li> <li> <code>nonlinearity</code>               (<code>str</code>, default:                   <code>'tanh'</code> )           \u2013            <p>The non-linearity to use. Can be either 'tanh' or 'relu'. Default is 'tanh'.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the weights. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the weights. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>rnn_cells</code>               (<code>list of RNNCell</code>)           \u2013            <p>List of RNNCell modules for each layer.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>num_layers</code>               (<code>int</code>)           \u2013            <p>Number of recurrent layers.</p> </li> <li> <code>device</code>               (<code>Device or None</code>)           \u2013            <p>Device on which the parameters are allocated.</p> </li> <li> <code>dtype</code>               (<code>str</code>)           \u2013            <p>Data type of the parameters.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Compute the output and final hidden state for a batch of input sequences.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.RNN.__init__","title":"<code>__init__(input_size, hidden_size, num_layers=1, bias=True, nonlinearity='tanh', device=None, dtype='float32')</code>","text":"<p>Applies an RNN cell with tanh or ReLU nonlinearity.</p> <p>Parameters: input_size: The number of expected features in the input X hidden_size: The number of features in the hidden state h bias: If False, then the layer does not use bias weights nonlinearity: The non-linearity to use. Can be either 'tanh' or 'relu'.</p> <p>Variables: W_ih: The learnable input-hidden weights of shape (input_size, hidden_size). W_hh: The learnable hidden-hidden weights of shape (hidden_size, hidden_size). bias_ih: The learnable input-hidden bias of shape (hidden_size,). bias_hh: The learnable hidden-hidden bias of shape (hidden_size,).</p> <p>Weights and biases are initialized from U(-sqrt(k), sqrt(k)) where k = 1/hidden_size</p>"},{"location":"nn/#tiny_pytorch.nn.RNN.forward","title":"<code>forward(X, h0=None)</code>","text":"<p>Compute the output and final hidden state for a batch of input sequences.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (seq_len, batch_size, input_size) containing the features of the input sequence.</p> </li> <li> <code>h0</code>               (<code>Tensor or None</code>, default:                   <code>None</code> )           \u2013            <p>Initial hidden state for each element in the batch, of shape (num_layers, batch_size, hidden_size). If None, defaults to zeros.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code> (              <code>Tensor</code> )          \u2013            <p>Output tensor of shape (seq_len, batch_size, hidden_size) containing the output features (h_t) from the last layer of the RNN, for each t.</p> </li> <li> <code>h_n</code> (              <code>Tensor</code> )          \u2013            <p>Tensor of shape (num_layers, batch_size, hidden_size) containing the final hidden state for each element in the batch.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.RNNCell","title":"<code>RNNCell</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies a single RNN cell with a specified nonlinearity (tanh or ReLU).</p> <p>Parameters:</p> <ul> <li> <code>input_size</code>               (<code>int</code>)           \u2013            <p>The number of expected features in the input X.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> <li> <code>bias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If False, then the layer does not use bias weights. Default is True.</p> </li> <li> <code>nonlinearity</code>               (<code>str</code>, default:                   <code>'tanh'</code> )           \u2013            <p>The non-linearity to use. Can be either 'tanh' or 'relu'. Default is 'tanh'.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the weights. Default is None (uses default device).</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>'float32'</code> )           \u2013            <p>Data type of the weights. Default is \"float32\".</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>W_ih</code>               (<code>Parameter</code>)           \u2013            <p>The learnable input-hidden weights of shape (input_size, hidden_size).</p> </li> <li> <code>W_hh</code>               (<code>Parameter</code>)           \u2013            <p>The learnable hidden-hidden weights of shape (hidden_size, hidden_size).</p> </li> <li> <code>bias_ih</code>               (<code>Parameter or None</code>)           \u2013            <p>The learnable input-hidden bias of shape (hidden_size,). None if bias is False.</p> </li> <li> <code>bias_hh</code>               (<code>Parameter or None</code>)           \u2013            <p>The learnable hidden-hidden bias of shape (hidden_size,). None if bias is False.</p> </li> <li> <code>nonlinearity</code>               (<code>Module</code>)           \u2013            <p>The nonlinearity module (Tanh or ReLU).</p> </li> <li> <code>device</code>               (<code>Device or None</code>)           \u2013            <p>Device on which the parameters are allocated.</p> </li> <li> <code>dtype</code>               (<code>str</code>)           \u2013            <p>Data type of the parameters.</p> </li> <li> <code>hidden_size</code>               (<code>int</code>)           \u2013            <p>The number of features in the hidden state h.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Compute the next hidden state given input X and previous hidden state h.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.RNNCell.__init__","title":"<code>__init__(input_size, hidden_size, bias=True, nonlinearity='tanh', device=None, dtype='float32')</code>","text":"<p>Applies an RNN cell with tanh or ReLU nonlinearity.</p> <p>Parameters: input_size: The number of expected features in the input X hidden_size: The number of features in the hidden state h bias: If False, then the layer does not use bias weights nonlinearity: The non-linearity to use. Can be either 'tanh' or 'relu'.</p> <p>Variables: W_ih: The learnable input-hidden weights of shape (input_size, hidden_size). W_hh: The learnable hidden-hidden weights of shape (hidden_size, hidden_size). bias_ih: The learnable input-hidden bias of shape (hidden_size,). bias_hh: The learnable hidden-hidden bias of shape (hidden_size,).</p> <p>Weights and biases are initialized from U(-sqrt(k), sqrt(k)) where k = 1/hidden_size</p>"},{"location":"nn/#tiny_pytorch.nn.RNNCell.forward","title":"<code>forward(X, h=None)</code>","text":"<p>Compute the next hidden state for a batch of inputs.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (batch_size, input_size).</p> </li> <li> <code>h</code>               (<code>Tensor or None</code>, default:                   <code>None</code> )           \u2013            <p>Initial hidden state for each element in the batch, of shape (batch_size, hidden_size). If None, defaults to zeros.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Next hidden state tensor of shape (batch_size, hidden_size).</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.ReLU","title":"<code>ReLU</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies the rectified linear unit (ReLU) activation function element-wise.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Output tensor with ReLU activation applied element-wise.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Residual","title":"<code>Residual</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies a residual connection to the input tensor.</p> <p>Parameters:</p> <ul> <li> <code>fn</code>               (<code>Module</code>)           \u2013            <p>The module to apply before adding the residual connection.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>fn</code>               (<code>Module</code>)           \u2013            <p>The module to apply before adding the residual connection.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Applies the residual connection to the input tensor <code>x</code>.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Sequential","title":"<code>Sequential</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies a sequence of modules to the input.</p> <p>Parameters:</p> <ul> <li> <code>*modules</code>               (<code>Module</code>, default:                   <code>()</code> )           \u2013            <p>A sequence of modules to apply to the input.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>The output tensor after applying all modules in sequence.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Sigmoid","title":"<code>Sigmoid</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies the sigmoid activation function element-wise.</p> <p>The sigmoid function maps any real-valued number to the range (0, 1). It is defined as: sigmoid(x) = 1 / (1 + e^(-x))</p> <p>The sigmoid function is commonly used in binary classification problems and as a gating mechanism in neural networks.</p> <p>Attributes:</p> <ul> <li> <code>None</code>           \u2013            <p>This module has no learnable parameters.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sigmoid = Sigmoid()\n&gt;&gt;&gt; x = Tensor([-2.0, -1.0, 0.0, 1.0, 2.0])\n&gt;&gt;&gt; output = sigmoid(x)\n&gt;&gt;&gt; print(output)\nTensor([0.1192, 0.2689, 0.5000, 0.7311, 0.8808], device=cpu_numpy())\n</code></pre>"},{"location":"nn/#tiny_pytorch.nn.Sigmoid.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the Sigmoid module.</p> <p>This module has no learnable parameters and requires no initialization.</p>"},{"location":"nn/#tiny_pytorch.nn.Sigmoid.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the sigmoid activation function.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of any shape.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Output tensor with the same shape as input, with sigmoid activation applied element-wise. Values are in the range (0, 1).</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.SoftmaxLoss","title":"<code>SoftmaxLoss</code>","text":"<p>               Bases: <code>Module</code></p> <p>Computes the softmax loss between logits and labels.</p> <p>Parameters:</p> <ul> <li> <code>logits</code>               (<code>Tensor</code>)           \u2013            <p>Input logits tensor.</p> </li> <li> <code>y</code>               (<code>Tensor</code>)           \u2013            <p>Ground truth labels tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>The softmax loss between logits and labels.</p> </li> </ul>"},{"location":"nn/#tiny_pytorch.nn.Tanh","title":"<code>Tanh</code>","text":"<p>               Bases: <code>Module</code></p> <p>Applies the hyperbolic tangent (tanh) activation function element-wise.</p> <p>The tanh function maps any real-valued number to the range (-1, 1). It is defined as: tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))</p> <p>Attributes:</p> <ul> <li> <code>None</code>           \u2013            <p>This module has no learnable parameters.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tanh = Tanh()\n&gt;&gt;&gt; x = Tensor([-2.0, -1.0, 0.0, 1.0, 2.0])\n&gt;&gt;&gt; output = tanh(x)\n&gt;&gt;&gt; print(output)\nTensor([-0.9640, -0.7616, 0.0000, 0.7616, 0.9640], device=cpu_numpy())\n</code></pre>"},{"location":"nn/#tiny_pytorch.nn.Tanh.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the tanh activation function.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of any shape.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Output tensor with the same shape as input, with tanh activation applied element-wise. Values are in the range (-1, 1).</p> </li> </ul>"},{"location":"ops/","title":"Operators","text":"<p>Tensor operations module for tiny-pytorch implementation.</p> <p>This module provides a comprehensive collection of fundamental tensor operations that form the building blocks of the computational graph in tiny-pytorch. Each operation is implemented as a class that inherits from the TensorOp base class, with corresponding helper functions for easier usage.</p> <p>The module includes element-wise operations, matrix operations, reduction operations, activation functions, and various mathematical functions commonly used in deep learning and neural network computations.</p> Key Features <ul> <li>Automatic differentiation support through gradient methods</li> <li>Element-wise and scalar operations</li> <li>Matrix operations (multiplication, transpose)</li> <li>Reduction operations (summation, log-sum-exp)</li> <li>Activation functions (ReLU, tanh)</li> <li>Shape manipulation (reshape, broadcast, stack, split)</li> <li>Convolutional operations</li> <li>Memory-efficient operations with strided arrays</li> </ul> <p>Classes:</p> <ul> <li> <code>TensorOp</code>           \u2013            <p>Base class for all tensor operations.</p> </li> <li> <code>TensorTupleOp</code>           \u2013            <p>Base class for operations that return tensor tuples.</p> </li> <li> <code>ScalarAdd</code>           \u2013            <p>Addition of a scalar to a tensor.</p> </li> <li> <code>EWiseAdd</code>           \u2013            <p>Element-wise addition of two tensors.</p> </li> <li> <code>ScalarMul</code>           \u2013            <p>Multiplication of a tensor by a scalar.</p> </li> <li> <code>EWiseMul</code>           \u2013            <p>Element-wise multiplication of two tensors.</p> </li> <li> <code>Negate</code>           \u2013            <p>Negation of a tensor.</p> </li> <li> <code>ScalarPower</code>           \u2013            <p>Raising tensor elements to a scalar power.</p> </li> <li> <code>EWisePower</code>           \u2013            <p>Element-wise power operation between two tensors.</p> </li> <li> <code>ScalarDivide</code>           \u2013            <p>Division of a tensor by a scalar.</p> </li> <li> <code>EWiseDivide</code>           \u2013            <p>Element-wise division of two tensors.</p> </li> <li> <code>Reshape</code>           \u2013            <p>Reshaping a tensor to a new shape.</p> </li> <li> <code>Summation</code>           \u2013            <p>Summing tensor elements along specified axes.</p> </li> <li> <code>BroadcastTo</code>           \u2013            <p>Broadcasting a tensor to a larger shape.</p> </li> <li> <code>Transpose</code>           \u2013            <p>Transposing a tensor along specified axes.</p> </li> <li> <code>MatMul</code>           \u2013            <p>Matrix multiplication between two tensors.</p> </li> <li> <code>Log</code>           \u2013            <p>Natural logarithm of tensor elements.</p> </li> <li> <code>Exp</code>           \u2013            <p>Exponential of tensor elements.</p> </li> <li> <code>ReLU</code>           \u2013            <p>Rectified Linear Unit activation function.</p> </li> <li> <code>LogSumExp</code>           \u2013            <p>Log-sum-exp operation, commonly used in softmax computation.</p> </li> <li> <code>Tanh</code>           \u2013            <p>Hyperbolic tangent activation function.</p> </li> <li> <code>Stack</code>           \u2013            <p>Stack a sequence of arrays along a new axis.</p> </li> <li> <code>Split</code>           \u2013            <p>Split a tensor along a specified axis.</p> </li> <li> <code>Flip</code>           \u2013            <p>Reverse the order of elements along specified axes.</p> </li> <li> <code>Dilate</code>           \u2013            <p>Insert zeros between elements along specified axes.</p> </li> <li> <code>UnDilate</code>           \u2013            <p>Remove zeros inserted by dilation along specified axes.</p> </li> <li> <code>Conv</code>           \u2013            <p>2D convolution operation.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>add_scalar</code>             \u2013              <p>Add a scalar to a tensor.</p> </li> <li> <code>add</code>             \u2013              <p>Add two tensors element-wise.</p> </li> <li> <code>mul_scalar</code>             \u2013              <p>Multiply a tensor by a scalar.</p> </li> <li> <code>multiply</code>             \u2013              <p>Multiply two tensors element-wise.</p> </li> <li> <code>negate</code>             \u2013              <p>Negate a tensor.</p> </li> <li> <code>power_scalar</code>             \u2013              <p>Raise tensor elements to a scalar power.</p> </li> <li> <code>power</code>             \u2013              <p>Element-wise power operation.</p> </li> <li> <code>divide_scalar</code>             \u2013              <p>Divide a tensor by a scalar.</p> </li> <li> <code>divide</code>             \u2013              <p>Element-wise division of tensors.</p> </li> <li> <code>reshape</code>             \u2013              <p>Reshape a tensor.</p> </li> <li> <code>summation</code>             \u2013              <p>Sum tensor elements along specified axes.</p> </li> <li> <code>broadcast_to</code>             \u2013              <p>Broadcast tensor to a larger shape.</p> </li> <li> <code>transpose</code>             \u2013              <p>Transpose tensor axes.</p> </li> <li> <code>matmul</code>             \u2013              <p>Matrix multiplication.</p> </li> <li> <code>log</code>             \u2013              <p>Natural logarithm.</p> </li> <li> <code>exp</code>             \u2013              <p>Exponential function.</p> </li> <li> <code>relu</code>             \u2013              <p>ReLU activation function.</p> </li> <li> <code>logsumexp</code>             \u2013              <p>Log-sum-exp operation.</p> </li> <li> <code>tanh</code>             \u2013              <p>Hyperbolic tangent function.</p> </li> <li> <code>stack</code>             \u2013              <p>Stack a sequence of arrays along a new axis.</p> </li> <li> <code>split</code>             \u2013              <p>Split a tensor along a specified axis.</p> </li> <li> <code>flip</code>             \u2013              <p>Reverse the order of elements along specified axes.</p> </li> <li> <code>dilate</code>             \u2013              <p>Insert zeros between elements along specified axes.</p> </li> <li> <code>undilate</code>             \u2013              <p>Remove zeros inserted by dilation along specified axes.</p> </li> <li> <code>conv</code>             \u2013              <p>2D convolution operation.</p> </li> </ul> Notes <p>All operations support automatic differentiation through their gradient methods, making them suitable for building and training neural networks. The operations are designed to work efficiently with the NDArray backend system and support multiple devices (CPU, CUDA, NumPy).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tiny_pytorch as tp\n&gt;&gt;&gt; x = tp.Tensor([1, 2, 3])\n&gt;&gt;&gt; y = tp.Tensor([4, 5, 6])\n&gt;&gt;&gt; z = tp.ops.add(x, y)  # Element-wise addition\n&gt;&gt;&gt; w = tp.ops.matmul(x, y)  # Matrix multiplication\n</code></pre>"},{"location":"ops/#tiny_pytorch.ops.BroadcastTo","title":"<code>BroadcastTo</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Broadcast a tensor to a larger shape.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>tuple</code>)           \u2013            <p>Target shape to broadcast to.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the broadcast operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Conv","title":"<code>Conv</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>2D convolution operation between input tensor and kernel.</p> <p>This operation performs 2D convolution between an input tensor and a kernel tensor. The input is expected to be in NHWC format (batch, height, width, channels) and the kernel in KKCC format (kernel_height, kernel_width, input_channels, output_channels).</p> <p>Parameters:</p> <ul> <li> <code>stride</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The stride of the convolution. Default is 1.</p> </li> <li> <code>padding</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The amount of padding to apply to the input. Default is 0.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the 2D convolution operation using im2col and matrix multiplication.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient with respect to both input and kernel tensors.</p> </li> </ul> Notes <ul> <li>Input tensor A should have shape (N, H, W, C_in)</li> <li>Kernel tensor B should have shape (K, K, C_in, C_out) where K is the kernel size</li> <li>Output tensor will have shape (N, out_H, out_W, C_out)</li> <li>Uses im2col transformation for efficient computation</li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Dilate","title":"<code>Dilate</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Dilate a tensor by inserting zeros between elements along specified axes.</p> <p>This operation inserts zeros between elements along the specified axes, effectively increasing the size of the tensor in those dimensions. This is commonly used in convolutional neural networks for dilated convolutions.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>The axes along which to apply dilation. Each axis index must be valid for the tensor's dimensions.</p> </li> <li> <code>dilation</code>               (<code>int</code>)           \u2013            <p>The dilation factor. For each element in the original tensor, <code>dilation</code> zeros will be inserted after it along the specified axes.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the dilation operation on the input NDArray.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the dilation operation (returns undilated gradient).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; Dilate((0,), 1)(x)\nTensor([[1, 2], [0, 0], [3, 4]])\n&gt;&gt;&gt; Dilate((1,), 1)(x)\nTensor([[1, 0, 2], [3, 0, 4]])\n&gt;&gt;&gt; Dilate((0, 1), 1)(x)\nTensor([[1, 0, 2], [0, 0, 0], [3, 0, 4]])\n</code></pre>"},{"location":"ops/#tiny_pytorch.ops.EWiseAdd","title":"<code>EWiseAdd</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Element-wise addition of two tensors.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute element-wise addition.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient with respect to both inputs.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.EWiseDivide","title":"<code>EWiseDivide</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Element-wise division of two tensors.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute element-wise division.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient with respect to both inputs.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.EWiseMul","title":"<code>EWiseMul</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Element-wise multiplication of two tensors.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute element-wise multiplication.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient with respect to both inputs.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.EWisePower","title":"<code>EWisePower</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Element-wise power operation between two tensors.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute element-wise power operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient with respect to both inputs.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Exp","title":"<code>Exp</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Exponential of tensor elements.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute exponential.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Flip","title":"<code>Flip</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Reverse (flip) the order of elements in a tensor along the specified axes.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple[int, ...] or None</code>, default:                   <code>None</code> )           \u2013            <p>Axes along which to flip the tensor. Each axis index must be valid for the tensor's dimensions. If None, flip over all axes (reverse the tensor in every dimension).</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the flip operation on the input NDArray.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the flip operation (flip the gradient along the same axes).</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AxisError</code>             \u2013            <p>If the number of axes is greater than the number of dimensions, or if any axis is out of bounds.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; Flip((0,))(x)\nTensor([[3, 4], [1, 2]])\n&gt;&gt;&gt; Flip((1,))(x)\nTensor([[2, 1], [4, 3]])\n&gt;&gt;&gt; Flip((0, 1))(x)\nTensor([[4, 3], [2, 1]])\n&gt;&gt;&gt; Flip()(x)\nTensor([[4, 3], [2, 1]])\n</code></pre>"},{"location":"ops/#tiny_pytorch.ops.Log","title":"<code>Log</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Natural logarithm of tensor elements.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute natural logarithm.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.LogSumExp","title":"<code>LogSumExp</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Log-sum-exp operation, commonly used in softmax computation.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple or None</code>, default:                   <code>None</code> )           \u2013            <p>Axes along which to perform the operation. If None, use all axes.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute log-sum-exp operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.MatMul","title":"<code>MatMul</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Matrix multiplication between two tensors.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute matrix multiplication.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient with respect to both inputs.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Negate","title":"<code>Negate</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Negate a tensor element-wise.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the negation operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.ReLU","title":"<code>ReLU</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Rectified Linear Unit activation function.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute ReLU activation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Reshape","title":"<code>Reshape</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Reshape a tensor to a new shape.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>tuple</code>)           \u2013            <p>The target shape for the tensor.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the reshape operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.ScalarAdd","title":"<code>ScalarAdd</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Add a scalar to a tensor.</p> <p>Parameters:</p> <ul> <li> <code>scalar</code>               (<code>float</code>)           \u2013            <p>The scalar value to add to the tensor.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the scalar addition operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.ScalarDivide","title":"<code>ScalarDivide</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Divide a tensor by a scalar.</p> <p>Parameters:</p> <ul> <li> <code>scalar</code>               (<code>float</code>)           \u2013            <p>The scalar value to divide by.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the scalar division.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.ScalarMul","title":"<code>ScalarMul</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Multiply a tensor by a scalar.</p> <p>Parameters:</p> <ul> <li> <code>scalar</code>               (<code>float</code>)           \u2013            <p>The scalar value to multiply with the tensor.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the scalar multiplication.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.ScalarPower","title":"<code>ScalarPower</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Raise tensor elements to a scalar power.</p> <p>Parameters:</p> <ul> <li> <code>scalar</code>               (<code>float</code>)           \u2013            <p>The power to raise tensor elements to.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the power operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Split","title":"<code>Split</code>","text":"<p>               Bases: <code>TensorTupleOp</code></p> <p>Split a tensor along an axis into a tuple of tensors.</p> <p>This operation is the inverse of Stack. It splits a tensor along a specified axis into multiple tensors, each with one less dimension than the input tensor.</p> <p>Parameters:</p> <ul> <li> <code>axis</code>               (<code>int</code>)           \u2013            <p>The axis along which to split the tensor. The axis dimension will be removed from each resulting tensor.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Split the input array along the specified axis.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the split operation (returns stack of out_grad tensors).</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Stack","title":"<code>Stack</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Stack a sequence of arrays along a new axis.</p> <p>Parameters:</p> <ul> <li> <code>axis</code>               (<code>int</code>)           \u2013            <p>The axis along which to stack. The new axis will be inserted at this position in the result array shape.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Stack the input arrays along the specified axis.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the stack operation (returns split of out_grad along axis).</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Summation","title":"<code>Summation</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Sum tensor elements along specified axes.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple or None</code>, default:                   <code>None</code> )           \u2013            <p>Axes along which to perform summation. If None, sum over all axes.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the summation operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Tanh","title":"<code>Tanh</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Hyperbolic tangent activation function.</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute hyperbolic tangent.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.Transpose","title":"<code>Transpose</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Transpose a tensor along specified axes.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple or None</code>, default:                   <code>None</code> )           \u2013            <p>Permutation of the dimensions. If None, reverse the last two dimensions.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the transpose operation.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.UnDilate","title":"<code>UnDilate</code>","text":"<p>               Bases: <code>TensorOp</code></p> <p>Undilate a tensor by removing zeros inserted by dilation along specified axes.</p> <p>This operation is the inverse of Dilate. It removes the zeros that were inserted during dilation, effectively reducing the size of the tensor in those dimensions. This is commonly used in convolutional neural networks for dilated convolutions.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>The axes along which to apply undilation. Each axis index must be valid for the tensor's dimensions.</p> </li> <li> <code>dilation</code>               (<code>int</code>)           \u2013            <p>The dilation factor that was used in the original Dilate operation.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute the undilation operation on the input NDArray.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the undilation operation (returns dilated gradient).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 0, 2], [0, 0, 0], [3, 0, 4]])\n&gt;&gt;&gt; UnDilate((0,), 1)(x)\nTensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; UnDilate((1,), 1)(x)\nTensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; UnDilate((0, 1), 1)(x)\nTensor([[1, 2], [3, 4]])\n</code></pre>"},{"location":"ops/#tiny_pytorch.ops.add","title":"<code>add(a, b)</code>","text":"<p>Add two tensors element-wise.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>First input tensor.</p> </li> <li> <code>b</code>               (<code>Tensor</code>)           \u2013            <p>Second input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Element-wise sum of the input tensors.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.add_scalar","title":"<code>add_scalar(a, scalar)</code>","text":"<p>Add a scalar value to a tensor.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>scalar</code>               (<code>float</code>)           \u2013            <p>Scalar value to add.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with the scalar added to each element.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.broadcast_to","title":"<code>broadcast_to(a, shape)</code>","text":"<p>Broadcast a tensor to a larger shape.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>shape</code>               (<code>tuple</code>)           \u2013            <p>Target shape to broadcast to.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Broadcasted tensor with the specified shape.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.conv","title":"<code>conv(a, b, stride=1, padding=1)</code>","text":"<p>Perform 2D convolution between input tensor and kernel.</p> <p>This function performs 2D convolution between an input tensor and a kernel tensor. The input is expected to be in NHWC format (batch, height, width, channels) and the kernel in KKCC format (kernel_height, kernel_width, input_channels, output_channels).</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor with shape (N, H, W, C_in) in NHWC format.</p> </li> <li> <code>b</code>               (<code>Tensor</code>)           \u2013            <p>Kernel tensor with shape (K, K, C_in, C_out) where K is the kernel size.</p> </li> <li> <code>stride</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The stride of the convolution. Default is 1.</p> </li> <li> <code>padding</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The amount of padding to apply to the input. Default is 1.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Convolved tensor with shape (N, out_H, out_W, C_out) where: - out_H = (H + 2padding - K) // stride + 1 - out_W = (W + 2padding - K) // stride + 1</p> </li> </ul> Notes <ul> <li>Uses im2col transformation for efficient computation</li> <li>Supports automatic differentiation through gradient computation</li> <li>Kernel must be square (K x K)</li> <li>Input and kernel channel dimensions must match</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor.randn(1, 32, 32, 3)  # 1 batch, 32x32 image, 3 channels\n&gt;&gt;&gt; kernel = Tensor.randn(3, 3, 3, 16)  # 3x3 kernel, 3 input channels, 16 output channels\n&gt;&gt;&gt; result = conv(x, kernel, stride=1, padding=1)\n&gt;&gt;&gt; result.shape  # (1, 32, 32, 16)\n(1, 32, 32, 16)\n</code></pre>"},{"location":"ops/#tiny_pytorch.ops.dilate","title":"<code>dilate(a, axes, dilation)</code>","text":"<p>Dilate a tensor by inserting zeros between elements along specified axes.</p> <p>This function inserts zeros between elements along the specified axes, effectively increasing the size of the tensor in those dimensions. This is commonly used in convolutional neural networks for dilated convolutions.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor to be dilated.</p> </li> <li> <code>axes</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>The axes along which to apply dilation. Each axis index must be valid for the tensor's dimensions.</p> </li> <li> <code>dilation</code>               (<code>int</code>)           \u2013            <p>The dilation factor. For each element in the original tensor, <code>dilation</code> zeros will be inserted after it along the specified axes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A dilated tensor with zeros inserted along the specified axes.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; dilate(x, (0,), 1)\nTensor([[1, 2], [0, 0], [3, 4]])\n&gt;&gt;&gt; dilate(x, (1,), 1)\nTensor([[1, 0, 2], [3, 0, 4]])\n&gt;&gt;&gt; dilate(x, (0, 1), 1)\nTensor([[1, 0, 2], [0, 0, 0], [3, 0, 4]])\n</code></pre>"},{"location":"ops/#tiny_pytorch.ops.divide","title":"<code>divide(a, b)</code>","text":"<p>Divide two tensors element-wise.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Numerator tensor.</p> </li> <li> <code>b</code>               (<code>Tensor</code>)           \u2013            <p>Denominator tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Element-wise division of the input tensors.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.divide_scalar","title":"<code>divide_scalar(a, scalar)</code>","text":"<p>Divide a tensor by a scalar value.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>scalar</code>               (<code>float</code>)           \u2013            <p>Scalar value to divide by.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with each element divided by the scalar.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.exp","title":"<code>exp(a)</code>","text":"<p>Compute the exponential of tensor elements.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Exponential of input tensor elements.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.flip","title":"<code>flip(a, axes=None)</code>","text":"<p>Reverse (flip) the order of elements in a tensor along the specified axes.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor to be flipped.</p> </li> <li> <code>axes</code>               (<code>tuple[int, ...] or None</code>, default:                   <code>None</code> )           \u2013            <p>Axes along which to flip the tensor. Each axis index must be valid for the tensor's dimensions. If None, flip over all axes (reverse the tensor in every dimension).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A tensor with the entries reversed along the specified axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AxisError</code>             \u2013            <p>If the number of axes is greater than the number of dimensions, or if any axis is out of bounds.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; flip(x, (0,))\nTensor([[3, 4], [1, 2]])\n&gt;&gt;&gt; flip(x, (1,))\nTensor([[2, 1], [4, 3]])\n&gt;&gt;&gt; flip(x, (0, 1))\nTensor([[4, 3], [2, 1]])\n&gt;&gt;&gt; flip(x)\nTensor([[4, 3], [2, 1]])\n</code></pre>"},{"location":"ops/#tiny_pytorch.ops.log","title":"<code>log(a)</code>","text":"<p>Compute the natural logarithm of tensor elements.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Natural logarithm of input tensor elements.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.logsumexp","title":"<code>logsumexp(a, axes=None)</code>","text":"<p>Compute log-sum-exp along specified axes.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>axes</code>               (<code>tuple or None</code>, default:                   <code>None</code> )           \u2013            <p>Axes along which to perform the operation. If None, use all axes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of log-sum-exp operation.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.matmul","title":"<code>matmul(a, b)</code>","text":"<p>Perform matrix multiplication between two tensors.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>First input tensor.</p> </li> <li> <code>b</code>               (<code>Tensor</code>)           \u2013            <p>Second input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of matrix multiplication.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.mul_scalar","title":"<code>mul_scalar(a, scalar)</code>","text":"<p>Multiply a tensor by a scalar value.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>scalar</code>               (<code>float</code>)           \u2013            <p>Scalar value to multiply with.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with each element multiplied by the scalar.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.multiply","title":"<code>multiply(a, b)</code>","text":"<p>Multiply two tensors element-wise.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>First input tensor.</p> </li> <li> <code>b</code>               (<code>Tensor</code>)           \u2013            <p>Second input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Element-wise product of the input tensors.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.negate","title":"<code>negate(a)</code>","text":"<p>Negate a tensor element-wise.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with each element negated.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.power","title":"<code>power(a, b)</code>","text":"<p>Raise elements of one tensor to powers specified by another tensor.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Base tensor.</p> </li> <li> <code>b</code>               (<code>Tensor</code>)           \u2013            <p>Exponent tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Element-wise power operation result.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.power_scalar","title":"<code>power_scalar(a, scalar)</code>","text":"<p>Raise tensor elements to a scalar power.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>scalar</code>               (<code>float</code>)           \u2013            <p>Power to raise elements to.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with each element raised to the given power.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.relu","title":"<code>relu(a)</code>","text":"<p>Apply Rectified Linear Unit (ReLU) activation function.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Tensor with ReLU activation applied.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.reshape","title":"<code>reshape(a, shape)</code>","text":"<p>Reshape a tensor to a new shape.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>shape</code>               (<code>tuple</code>)           \u2013            <p>Target shape for the tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with the specified shape.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.split","title":"<code>split(a, axis)</code>","text":"<p>Split a tensor along an axis into a tuple of tensors.</p> <p>This function splits a tensor along a specified axis into multiple tensors. Each resulting tensor has one less dimension than the input tensor.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor to split.</p> </li> <li> <code>axis</code>               (<code>int</code>)           \u2013            <p>The axis along which to split the tensor. The axis dimension will be removed from each resulting tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TensorTuple</code>           \u2013            <p>A tuple of tensors, each with the specified axis dimension removed. The number of tensors in the tuple equals the size of the input tensor along the specified axis.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; result = split(x, axis=0)\n&gt;&gt;&gt; len(result)  # Returns 2 tensors\n2\n&gt;&gt;&gt; result[0].shape  # Each tensor has shape (3,)\n(3,)\n</code></pre>"},{"location":"ops/#tiny_pytorch.ops.stack","title":"<code>stack(arrays, axis)</code>","text":"<p>Stack a sequence of tensors along a new axis.</p> <p>Parameters:</p> <ul> <li> <code>arrays</code>               (<code>list of Tensor</code>)           \u2013            <p>Sequence of tensors to stack. All tensors must have the same shape.</p> </li> <li> <code>axis</code>               (<code>int</code>)           \u2013            <p>The axis along which to stack. The new axis will be inserted at this position in the result tensor shape.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>The stacked tensor with one more dimension than the input tensors.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.summation","title":"<code>summation(a, axes=None)</code>","text":"<p>Sum tensor elements along specified axes.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>axes</code>               (<code>tuple or None</code>, default:                   <code>None</code> )           \u2013            <p>Axes along which to perform summation. If None, sum over all axes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Sum of elements along specified axes.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.tanh","title":"<code>tanh(a)</code>","text":"<p>Compute the hyperbolic tangent of tensor elements.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Hyperbolic tangent of input tensor elements.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.transpose","title":"<code>transpose(a, axes=None)</code>","text":"<p>Transpose a tensor along specified axes.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>axes</code>               (<code>tuple or None</code>, default:                   <code>None</code> )           \u2013            <p>Permutation of the dimensions. If None, reverse the dimensions.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Transposed tensor.</p> </li> </ul>"},{"location":"ops/#tiny_pytorch.ops.undilate","title":"<code>undilate(a, axes, dilation)</code>","text":"<p>Undilate a tensor by removing zeros inserted by dilation along specified axes.</p> <p>This function is the inverse of dilate. It removes the zeros that were inserted during dilation, effectively reducing the size of the tensor in those dimensions. This is commonly used in convolutional neural networks for dilated convolutions.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor to be undilated.</p> </li> <li> <code>axes</code>               (<code>tuple[int, ...]</code>)           \u2013            <p>The axes along which to apply undilation. Each axis index must be valid for the tensor's dimensions.</p> </li> <li> <code>dilation</code>               (<code>int</code>)           \u2013            <p>The dilation factor that was used in the original dilate operation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>An undilated tensor with zeros removed along the specified axes.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = Tensor([[1, 0, 2], [0, 0, 0], [3, 0, 4]])\n&gt;&gt;&gt; undilate(x, (0,), 1)\nTensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; undilate(x, (1,), 1)\nTensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; undilate(x, (0, 1), 1)\nTensor([[1, 2], [3, 4]])\n</code></pre>"},{"location":"optim/","title":"Optimizer","text":"<p>Optimization algorithms for neural networks.</p> <p>This module implements various optimization algorithms commonly used in deep learning, including Stochastic Gradient Descent (SGD) and Adam. These optimizers are used to update model parameters during training to minimize the loss function through gradient-based optimization.</p> <p>The module provides a base Optimizer class that defines the common interface for all optimizers, as well as concrete implementations of specific optimization algorithms. All optimizers work seamlessly with the Tensor system and automatic differentiation capabilities.</p> Key Features <ul> <li>Gradient-based optimization algorithms</li> <li>Support for momentum and weight decay</li> <li>Adaptive learning rate methods</li> <li>Automatic parameter updates</li> <li>Integration with Tensor gradients</li> <li>Memory-efficient optimization</li> </ul> <p>Classes:</p> <ul> <li> <code>Optimizer</code>           \u2013            <p>Base class that provides common optimizer functionality. Defines the interface for parameter updates and gradient management.</p> </li> <li> <code>SGD : Optimizer</code>           \u2013            <p>Stochastic Gradient Descent optimizer with optional momentum. Implements the classic gradient descent algorithm with support for momentum and weight decay regularization.</p> </li> <li> <code>Adam : Optimizer</code>           \u2013            <p>Adaptive Moment Estimation optimizer. Implements the Adam algorithm with adaptive learning rates for each parameter, combining the benefits of AdaGrad and RMSprop.</p> </li> </ul> Notes <p>All optimizers in this module work with the Tensor system and automatically handle gradient computation and parameter updates. The optimizers expect parameters to be Tensor objects with gradients computed through the automatic differentiation system.</p> <p>The optimization algorithms implement various techniques to improve training stability and convergence speed: - Momentum helps accelerate convergence in relevant directions - Weight decay provides regularization to prevent overfitting - Adaptive learning rates (in Adam) help handle sparse gradients</p> <p>Optimizers automatically handle gradient accumulation and parameter updates, making them easy to use in training loops.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tiny_pytorch as tp\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a simple model\n&gt;&gt;&gt; model = tp.nn.Sequential(\n...     tp.nn.Linear(784, 128),\n...     tp.nn.ReLU(),\n...     tp.nn.Linear(128, 10)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create an optimizer\n&gt;&gt;&gt; optimizer = tp.optim.SGD(\n...     model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Training loop\n&gt;&gt;&gt; for epoch in range(num_epochs):\n...     for batch_x, batch_y in dataloader:\n...         # Forward pass\n...         output = model(batch_x)\n...         loss = tp.nn.SoftmaxLoss()(output, batch_y)\n...\n...         # Backward pass\n...         loss.backward()\n...\n...         # Update parameters\n...         optimizer.step()\n...         optimizer.reset_grad()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Using Adam optimizer\n&gt;&gt;&gt; adam_optimizer = tp.optim.Adam(\n...     model.parameters(), lr=0.001, beta1=0.9, beta2=0.999\n... )\n</code></pre> See Also <p>tensor.Tensor : The Tensor class used for parameter optimization. nn : Neural network modules whose parameters are optimized.</p>"},{"location":"optim/#tiny_pytorch.optim.Adam","title":"<code>Adam</code>","text":"<p>               Bases: <code>Optimizer</code></p> <p>Adaptive Moment Estimation optimizer.</p> <p>Adam is an optimization algorithm that combines the benefits of two other extensions of stochastic gradient descent: - Adaptive Gradient Algorithm (AdaGrad) - Root Mean Square Propagation (RMSProp)</p> <p>It computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients.</p> <p>The update rule for parameter p is:</p> <pre><code>m = \u03b2\u2081 * m + (1 - \u03b2\u2081) * g         # First moment estimate\n\nv = \u03b2\u2082 * v + (1 - \u03b2\u2082) * g\u00b2        # Second moment estimate\n\nm\u0302 = m / (1 - \u03b2\u2081\u1d57)                 # Bias correction\n\nv\u0302 = v / (1 - \u03b2\u2082\u1d57)                 # Bias correction\n\np = p - lr * m\u0302 / (\u221av\u0302 + \u03b5)        # Update\n</code></pre> Notes <p>The optimizer implements the Adam algorithm as described in \"Adam: A Method for Stochastic Optimization\" by Kingma and Ba (2014).</p> See Also <p>SGD : Stochastic Gradient Descent optimizer</p>"},{"location":"optim/#tiny_pytorch.optim.Adam.__init__","title":"<code>__init__(params, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-08, weight_decay=0.0)</code>","text":"<p>Parameters:</p> <ul> <li> <code>params</code>               (<code>list</code>)           \u2013            <p>List of parameters to optimize.</p> </li> <li> <code>lr</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>Learning rate, by default 0.01</p> </li> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>Exponential decay rate for first moment estimates, by default 0.9</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>Exponential decay rate for second moment estimates, by default 0.999</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>Small constant for numerical stability, by default 1e-8</p> </li> <li> <code>weight_decay</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Weight decay (L2 penalty), by default 0.0</p> </li> </ul>"},{"location":"optim/#tiny_pytorch.optim.Optimizer","title":"<code>Optimizer</code>","text":"<p>Base class for all optimizers.</p> <p>This class defines the basic interface and functionality that all optimizer implementations should follow. It provides common methods like step() for parameter updates and reset_grad() for gradient reset.</p> Notes <p>All optimizers should inherit from this base class and implement the step() method according to their specific optimization algorithm.</p> See Also <p>SGD : Stochastic Gradient Descent optimizer</p> <p>Adam : Adaptive Moment Estimation optimizer</p>"},{"location":"optim/#tiny_pytorch.optim.Optimizer.__init__","title":"<code>__init__(params)</code>","text":"<p>Parameters:</p> <ul> <li> <code>params</code>               (<code>list</code>)           \u2013            <p>List of parameters to optimize. Each parameter should be an instance of Tensor with requires_grad=True.</p> </li> </ul>"},{"location":"optim/#tiny_pytorch.optim.SGD","title":"<code>SGD</code>","text":"<p>               Bases: <code>Optimizer</code></p> <p>Stochastic Gradient Descent optimizer.</p> <p>Implements stochastic gradient descent (optionally with momentum).</p> Notes <p>The update rule for parameter <code>p</code> with gradient <code>g</code> is:</p> <p>With momentum:</p> <pre><code>u = momentum * u + (1 - momentum) * g\n\np = p * (1 - lr * weight_decay) - lr * u\n</code></pre> <p>Without momentum:     p = p * (1 - lr * weight_decay) - lr * g</p> See Also <p>Adam : Adaptive Moment Estimation optimizer</p>"},{"location":"optim/#tiny_pytorch.optim.SGD.__init__","title":"<code>__init__(params, lr=0.01, momentum=0.0, weight_decay=0.0)</code>","text":"<p>Parameters:</p> <ul> <li> <code>params</code>               (<code>list</code>)           \u2013            <p>List of parameters to optimize. Each parameter should be an instance of Tensor with requires_grad=True.</p> </li> <li> <code>lr</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>Learning rate. Default: 0.01</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Momentum factor. Default: 0.0</p> </li> <li> <code>weight_decay</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Weight decay (L2 penalty). Default: 0.0</p> </li> </ul> Notes <p>When momentum is 0, this is equivalent to standard stochastic gradient descent. When momentum &gt; 0, this implements momentum-based gradient descent which helps accelerate gradients vectors in the right directions.</p>"},{"location":"tensor/","title":"Tensor","text":"<p>Core data structures for multi-dimensional tensors.</p> <p>This module provides the fundamental Tensor class and related components that form the backbone of the tiny-pytorch framework. It implements automatic differentiation, computation graph management, and tensor operations with support for multiple backends and devices.</p> <p>The module includes the core Tensor class, operation abstractions, and gradient computation utilities that enable building and training neural networks with automatic differentiation capabilities.</p> Key Features <ul> <li>Automatic differentiation with gradient tracking</li> <li>Computation graph construction and management</li> <li>Support for multiple backends (NumPy, CPU, CUDA)</li> <li>Lazy evaluation mode for memory efficiency</li> <li>Tensor operations with automatic broadcasting</li> <li>Gradient computation and backpropagation</li> <li>Device and dtype management</li> </ul> <p>Classes:</p> <ul> <li> <code>Op</code>           \u2013            <p>Base class for all tensor operations. Defines the interface for operations that can be applied to tensors to create new tensors in the computation graph.</p> </li> <li> <code>TensorOp : Op</code>           \u2013            <p>Base class for operations that produce single tensors.</p> </li> <li> <code>TensorTupleOp : Op</code>           \u2013            <p>Base class for operations that produce tuples of tensors.</p> </li> <li> <code>Tensor</code>           \u2013            <p>Multi-dimensional tensor with automatic differentiation support. The core data structure for representing inputs, outputs, and intermediate results in neural network computations.</p> </li> <li> <code>TensorTuple : Tensor</code>           \u2013            <p>Specialized tensor class for representing tuples of tensors.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>compute_gradients</code>             \u2013              <p>Compute gradients for all tensors in the computation graph.</p> </li> <li> <code>find_topo_sort</code>             \u2013              <p>Find topological sort of tensors in the computation graph.</p> </li> <li> <code>_topo_sort_dfs</code>             \u2013              <p>Depth-first search for topological sorting.</p> </li> </ul> Notes <p>The Tensor system implements automatic differentiation through a computation graph where each tensor operation creates a new tensor node that tracks its inputs and the operation that produced it. When backward() is called on a tensor, gradients are computed and propagated through the graph using the chain rule.</p> <p>The system supports both eager and lazy evaluation modes. In eager mode (default), tensor values are computed immediately. In lazy mode, computation is deferred until the tensor value is actually needed.</p> <p>All tensor operations are designed to work seamlessly with the automatic differentiation system, automatically tracking gradients when requires_grad=True.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tiny_pytorch as tp\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create tensors\n&gt;&gt;&gt; x = tp.Tensor([1, 2, 3], requires_grad=True)\n&gt;&gt;&gt; y = tp.Tensor([4, 5, 6], requires_grad=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Perform operations\n&gt;&gt;&gt; z = x * y + 2  # Automatic gradient tracking\n&gt;&gt;&gt; loss = z.sum()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compute gradients\n&gt;&gt;&gt; loss.backward()\n&gt;&gt;&gt; print(x.grad)  # Gradient with respect to x\n&gt;&gt;&gt; print(y.grad)  # Gradient with respect to y\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use different devices\n&gt;&gt;&gt; x_cpu = tp.Tensor([1, 2, 3], device=tp.cpu())\n&gt;&gt;&gt; x_cuda = tp.Tensor([1, 2, 3], device=tp.cuda())\n</code></pre>"},{"location":"tensor/#tiny_pytorch.tensor.Op","title":"<code>Op</code>","text":"<p>Base class for all tensor operations.</p> <p>This class defines the interface that all tensor operations must implement. Operations are callable objects that can be applied to tensors to create new tensors in the computation graph.</p> <p>Methods:</p> <ul> <li> <code>__call__</code>             \u2013              <p>Apply the operation to the given arguments.</p> </li> <li> <code>compute</code>             \u2013              <p>Compute the actual operation on the underlying arrays.</p> </li> <li> <code>gradient</code>             \u2013              <p>Compute the gradient of the operation.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Op.__call__","title":"<code>__call__(*args)</code>","text":"<p>Apply the operation to the given arguments.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Tensor</code>, default:                   <code>()</code> )           \u2013            <p>Input tensors to the operation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of applying the operation to the inputs.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Op.compute","title":"<code>compute(*args)</code>","text":"<p>Compute the actual operation on the underlying arrays.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>tuple[NDArray]</code>, default:                   <code>()</code> )           \u2013            <p>Input arrays to the operation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>Result of the operation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NotImplementedError</code>             \u2013            <p>This method must be implemented by subclasses.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Op.gradient","title":"<code>gradient(out_grad, out_node)</code>","text":"<p>Compute the gradient of the operation.</p> <p>Parameters:</p> <ul> <li> <code>out_grad</code>               (<code>Tensor</code>)           \u2013            <p>Gradient of the output with respect to the final result.</p> </li> <li> <code>out_node</code>               (<code>Tensor</code>)           \u2013            <p>The output tensor of this operation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor or tuple[Tensor]</code>           \u2013            <p>Gradient(s) with respect to the input(s) of this operation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NotImplementedError</code>             \u2013            <p>This method must be implemented by subclasses.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Op.gradient_as_tuple","title":"<code>gradient_as_tuple(out_grad, node)</code>","text":"<p>Convenience method to always return a tuple from gradient call</p>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor","title":"<code>Tensor</code>","text":"<p>Tensor is the fundamental data structure in tiny_pytorch. It is a multi-dimensional array of numerical values used to represent inputs, outputs, and intermediate results in a computation graph.</p> <p>Attributes:</p> <ul> <li> <code>cached_data</code>               (<code>list[object]</code>)           \u2013            <p>The cached data of the tensor.</p> </li> <li> <code>inputs</code>               (<code>list[Tensor]</code>)           \u2013            <p>The input tensors to the operation that produced this tensor.</p> </li> <li> <code>op</code>               (<code>Op</code>)           \u2013            <p>The operation that produced this tensor.</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>)           \u2013            <p>If True, the tensor will track gradients.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.data","title":"<code>data</code>  <code>property</code> <code>writable</code>","text":"<p>Returns a detached Tensor with the original data.</p>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.device","title":"<code>device</code>  <code>property</code>","text":"<p>Returns the device on which the tensor is stored.</p> <p>Returns:</p> <ul> <li> <code>device</code> (              <code>Device</code> )          \u2013            <p>The device on which the tensor is stored.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.dtype","title":"<code>dtype</code>  <code>property</code>","text":"<p>Returns the data type of the tensor.</p> <p>Returns:</p> <ul> <li> <code>dtype</code> (              <code>dtype</code> )          \u2013            <p>The data type of the tensor.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>Returns the number of dimensions of the tensor.</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Number of dimensions of the tensor.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Returns the shape of the tensor as a tuple.</p> <p>Returns:</p> <ul> <li> <code>tuple</code>           \u2013            <p>Shape of the tensor.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__add__","title":"<code>__add__(other)</code>","text":"<p>Add another tensor or scalar to this tensor.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>Tensor or scalar</code>)           \u2013            <p>The tensor or scalar to add.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of the addition operation.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__init__","title":"<code>__init__(array, *, device=None, dtype=None, requires_grad=True)</code>","text":"<p>Construct a Tensor by copying <code>array</code>.</p> <p>Parameters:</p> <ul> <li> <code>array</code>               (<code>object</code>)           \u2013            <p>The array to be copied.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>The device on which to place the tensor. Default is None.</p> </li> <li> <code>dtype</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The data type of the tensor. Default is None.</p> </li> <li> <code>requires_grad</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, the tensor will track gradients. Default is True.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Matrix multiplication with another tensor.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>Tensor</code>)           \u2013            <p>The tensor to multiply with.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of the matrix multiplication.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiply this tensor by another tensor or scalar.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>Tensor or scalar</code>)           \u2013            <p>The tensor or scalar to multiply by.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of the multiplication operation.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__neg__","title":"<code>__neg__()</code>","text":"<p>Negate this tensor.</p> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Negated tensor.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__pow__","title":"<code>__pow__(other)</code>","text":"<p>Raise this tensor to the power of another tensor or scalar.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>Tensor or scalar</code>)           \u2013            <p>The exponent.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of the power operation.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of the tensor.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>String representation showing the tensor data.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the tensor.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>String representation of the tensor data.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtract another tensor or scalar from this tensor.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>Tensor or scalar</code>)           \u2013            <p>The tensor or scalar to subtract.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of the subtraction operation.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.__truediv__","title":"<code>__truediv__(other)</code>","text":"<p>Divide this tensor by another tensor or scalar.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>Tensor or scalar</code>)           \u2013            <p>The tensor or scalar to divide by.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Result of the division operation.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.backward","title":"<code>backward(out_grad=None)</code>","text":"<p>Computes the gradients of the tensor with respect to the output gradient.</p> <p>Parameters:</p> <ul> <li> <code>out_grad</code>               (<code>Tensor</code>, default:                   <code>None</code> )           \u2013            <p>The gradient of the output with respect to which the gradients are computed. If None, a tensor of ones is used.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This method updates the <code>grad</code> attribute of the tensor and its dependencies with the computed gradients.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.broadcast_to","title":"<code>broadcast_to(shape)</code>","text":"<p>Broadcasts the tensor to the specified shape.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>tuple of ints</code>)           \u2013            <p>The new shape of the tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with the specified shape.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.detach","title":"<code>detach()</code>","text":"<p>Returns a new Tensor with no history (detached from the computation graph). The returned Tensor will share the same data with the original one.</p>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.from_constant","title":"<code>from_constant(data, requires_grad=False)</code>  <code>classmethod</code>","text":"<p>Creates a leaf node Tensor from the given <code>data</code>.</p>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.from_operation","title":"<code>from_operation(op, inputs)</code>  <code>classmethod</code>","text":"<p>Creates a node Tensor by applying the <code>op</code> operation on the <code>inputs</code> Tensors.</p>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.is_leaf","title":"<code>is_leaf()</code>","text":"<p>All Tensors that have <code>requires_grad</code> set to <code>False</code> OR they were created by the user and were not the result of an operation are considered leaf Tensors.</p>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.numpy","title":"<code>numpy()</code>","text":"<p>Returns <code>Tensor</code> as Numpy ndarray. The underlying data will be shared between Tensor and the Numpy ndarray.</p>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.realize_cached_data","title":"<code>realize_cached_data()</code>","text":"<p>Run computation to get the output if the LAZY MODE is on, else return cached data.</p>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.reshape","title":"<code>reshape(shape)</code>","text":"<p>Reshapes the tensor to the specified shape.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>               (<code>tuple of ints</code>)           \u2013            <p>The new shape of the tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with the specified shape.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.sum","title":"<code>sum(axes=None)</code>","text":"<p>Returns the sum of elements over specified axes.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>None or int or tuple of ints</code>, default:                   <code>None</code> )           \u2013            <p>Axis or axes along which a sum is performed. The default is to sum all of the elements of the input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with the sum of elements over specified axes.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.Tensor.transpose","title":"<code>transpose(axes=None)</code>","text":"<p>Transposes the tensor according to the specified axes.</p> <p>Parameters:</p> <ul> <li> <code>axes</code>               (<code>tuple of ints</code>, default:                   <code>None</code> )           \u2013            <p>By default, reverse the dimensions, otherwise permute the axes according to the values given.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>A new tensor with the specified axes transposed.</p> </li> </ul>"},{"location":"tensor/#tiny_pytorch.tensor.TensorOp","title":"<code>TensorOp</code>","text":"<p>               Bases: <code>Op</code></p> <p>Op class specialized to output tensors, will be alterate subclasses for other structures</p>"},{"location":"tensor/#tiny_pytorch.tensor.TensorTuple","title":"<code>TensorTuple</code>","text":"<p>               Bases: <code>Tensor</code></p> <p>Represent a tuple of tensors.</p> <p>To keep things simple, we do not support nested tuples.</p>"},{"location":"tensor/#tiny_pytorch.tensor.TensorTuple.detach","title":"<code>detach()</code>","text":"<p>Create a new tensor that shares the data but detaches from the graph.</p>"},{"location":"tensor/#tiny_pytorch.tensor.TensorTupleOp","title":"<code>TensorTupleOp</code>","text":"<p>               Bases: <code>Op</code></p> <p>Op class specialized to output TensorTuple</p>"},{"location":"tensor/#tiny_pytorch.tensor.compute_gradients","title":"<code>compute_gradients(out_tensor, out_grad)</code>","text":"<p>Compute gradients for all nodes in the computation graph.</p> <p>This function implements reverse-mode automatic differentiation by traversing the computation graph in reverse topological order and computing gradients for each node.</p> <p>Parameters:</p> <ul> <li> <code>out_tensor</code>               (<code>Tensor</code>)           \u2013            <p>The output tensor for which gradients are computed.</p> </li> <li> <code>out_grad</code>               (<code>Tensor</code>)           \u2013            <p>The gradient of the output with respect to the final result.</p> </li> </ul> Notes <p>This function modifies the <code>grad</code> attribute of tensors in the computation graph. It stores the computed result in the grad field of each tensor.</p>"},{"location":"tensor/#tiny_pytorch.tensor.find_topo_sort","title":"<code>find_topo_sort(node_list)</code>","text":"<p>Find topological sort of nodes in the computation graph.</p> <p>Given a list of nodes, return a topological sort list of nodes ending in them. A simple algorithm is to do a post-order DFS traversal on the given nodes, going backwards based on input edges. Since a node is added to the ordering after all its predecessors are traversed due to post-order DFS, we get a topological sort.</p> <p>Parameters:</p> <ul> <li> <code>node_list</code>               (<code>list[Tensor]</code>)           \u2013            <p>List of tensors to sort topologically.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Tensor]</code>           \u2013            <p>Topologically sorted list of tensors.</p> </li> </ul>"},{"location":"utils/","title":"Utils","text":"<p>Utility functions for tiny-pytorch.</p> <p>This module provides various utility functions used throughout the tiny-pytorch framework. It includes helper functions for data type conversion, object manipulation, and other common operations needed by the framework's components.</p> <p>Functions:</p> <ul> <li> <code>listify</code>             \u2013              <p>Convert any object into a list.</p> </li> <li> <code>tuplify</code>             \u2013              <p>Convert any object into a tuple.</p> </li> <li> <code>setify</code>             \u2013              <p>Convert any object into a set.</p> </li> </ul> Notes <p>The utility functions in this module are designed to be simple, reusable helpers that support the core functionality of the framework. They handle common operations like type conversion and data manipulation that are needed across multiple modules.</p>"},{"location":"utils/#tiny_pytorch.utils.listify","title":"<code>listify(obj)</code>","text":"<p>Convert any object into a list.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>               (<code>object</code>)           \u2013            <p>Object to convert to list.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>List representation of input object.</p> </li> </ul> Notes <p>The function handles the following cases:</p> <ul> <li>None -&gt; empty list</li> <li>list -&gt; returned as-is</li> <li>string -&gt; single-item list containing the string</li> <li>iterable -&gt; converted to list</li> <li>any other object -&gt; single-item list containing the object</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; listify(None)\n[]\n&gt;&gt;&gt; listify([1,2,3])\n[1,2,3]\n&gt;&gt;&gt; listify(\"abc\")\n[\"abc\"]\n&gt;&gt;&gt; listify(range(3))\n[0,1,2]\n&gt;&gt;&gt; listify(5)\n[5]\n</code></pre>"},{"location":"utils/#tiny_pytorch.utils.setify","title":"<code>setify(obj)</code>","text":"<p>Convert any object into a set.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>               (<code>object</code>)           \u2013            <p>Object to convert to set.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set</code>           \u2013            <p>Set representation of input object.</p> </li> </ul> Notes <p>The function handles the following cases:</p> <ul> <li>None -&gt; empty set</li> <li>set -&gt; returned as-is</li> <li>list/tuple -&gt; converted to set</li> <li>string -&gt; single-item set containing the string</li> <li>iterable -&gt; converted to set</li> <li>any other object -&gt; single-item set containing the object</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; setify(None)\nset()\n&gt;&gt;&gt; setify([1,2,2,3])\n{1,2,3}\n&gt;&gt;&gt; setify(\"abc\")\n{\"abc\"}\n&gt;&gt;&gt; setify(range(3))\n{0,1,2}\n&gt;&gt;&gt; setify(5)\n{5}\n</code></pre>"},{"location":"utils/#tiny_pytorch.utils.tuplify","title":"<code>tuplify(obj)</code>","text":"<p>Convert any object into a tuple.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>               (<code>object</code>)           \u2013            <p>Object to convert to tuple.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>           \u2013            <p>Tuple representation of input object.</p> </li> </ul> Notes <p>The function handles the following cases:</p> <ul> <li>None -&gt; empty tuple</li> <li>tuple -&gt; returned as-is</li> <li>list -&gt; converted to tuple</li> <li>string -&gt; single-item tuple containing the string</li> <li>iterable -&gt; converted to tuple</li> <li>any other object -&gt; single-item tuple containing the object</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tuplify(None)\n()\n&gt;&gt;&gt; tuplify([1,2,3])\n(1,2,3)\n&gt;&gt;&gt; tuplify(\"abc\")\n(\"abc\",)\n&gt;&gt;&gt; tuplify(range(3))\n(0,1,2)\n&gt;&gt;&gt; tuplify(5)\n(5,)\n</code></pre>"},{"location":"vision-models/","title":"Models","text":"<p>Vision models for tiny-pytorch implementation.</p> <p>This module provides pre-built neural network architectures for computer vision tasks, specifically designed for image classification. The models are built using the core neural network components from the tiny-pytorch framework.</p> <p>The module includes implementations of popular architectures adapted for the tiny-pytorch ecosystem, focusing on efficiency and educational value while maintaining compatibility with the framework's tensor operations and automatic differentiation system.</p> Key Features <ul> <li>Pre-built vision models for image classification</li> <li>Residual network architectures with skip connections</li> <li>Efficient implementations optimized for the tiny-pytorch framework</li> <li>Educational models that demonstrate modern CNN design patterns</li> </ul> <p>Classes:</p> <ul> <li> <code>ResNet9</code>           \u2013            <p>A lightweight ResNet architecture designed for efficient training and inference on smaller datasets. Features residual connections and progressive channel expansion for 10-class classification tasks.</p> </li> <li> <code>ResidualBlock</code>           \u2013            <p>A utility function that creates residual blocks with two ConvBN layers and skip connections, essential for building deep residual networks.</p> </li> </ul> Notes <p>All models in this module are designed to work with the tiny-pytorch tensor system and support automatic differentiation. Input tensors should be in NCHW format (batch, channels, height, width) and models output classification logits.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from tiny_pytorch.vision.models import ResNet9\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a ResNet-9 model for image classification\n&gt;&gt;&gt; model = ResNet9()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Prepare input data (batch_size=32, channels=3, height=32, width=32)\n&gt;&gt;&gt; x = Tensor.randn(32, 3, 32, 32)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Forward pass to get classification logits\n&gt;&gt;&gt; output = model(x)  # shape: (32, 10)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # The model is ready for training with appropriate loss functions\n&gt;&gt;&gt; # and optimizers from the tiny-pytorch framework\n</code></pre>"},{"location":"vision-models/#tiny_pytorch.vision.models.ResNet9","title":"<code>ResNet9</code>","text":"<p>               Bases: <code>Module</code></p> <p>ResNet-9: A lightweight ResNet architecture for image classification.</p> <p>ResNet-9 is a simplified version of the ResNet architecture designed for efficient training and inference on smaller datasets. It consists of convolutional layers with residual connections, followed by fully connected layers for classification.</p> <p>The architecture follows this pattern: 1. Initial convolution (7x7, stride 4) to reduce spatial dimensions 2. Multiple convolutional blocks with residual connections 3. Global average pooling (via Flatten) 4. Fully connected layers for classification</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the model parameters. Default is None (uses default device).</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>model</code>               (<code>Sequential</code>)           \u2013            <p>The complete ResNet-9 model as a sequential container.</p> </li> </ul> Notes <ul> <li>Input is expected to be in NCHW format (batch, channels, height, width).</li> <li>The model is designed for 10-class classification (e.g., CIFAR-10).</li> <li>Uses residual connections to help with gradient flow in deeper layers.</li> <li>The architecture progressively reduces spatial dimensions while increasing   the number of channels.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; model = ResNet9()\n&gt;&gt;&gt; x = Tensor.randn(32, 3, 32, 32)  # batch_size=32, channels=3, height=32, width=32\n&gt;&gt;&gt; output = model(x)  # shape: (32, 10) - 10 class probabilities\n</code></pre>"},{"location":"vision-models/#tiny_pytorch.vision.models.ResNet9.__init__","title":"<code>__init__(device=None)</code>","text":"<p>Initialize the ResNet-9 model.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the model parameters. Default is None (uses default device).</p> </li> </ul>"},{"location":"vision-models/#tiny_pytorch.vision.models.ResNet9.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the ResNet-9 model.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor of shape (batch_size, 3, height, width) in NCHW format. Typically used with 32x32 or 64x64 images.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Output tensor of shape (batch_size, 10) containing class logits for 10-class classification.</p> </li> </ul>"},{"location":"vision-models/#tiny_pytorch.vision.models.ResidualBlock","title":"<code>ResidualBlock(in_channels, out_channels, kernel_size, stride, device=None)</code>","text":"<p>Create a residual block with two ConvBN layers and a skip connection.</p> <p>This function creates a residual block that consists of two ConvBN layers followed by a residual connection that adds the input to the output. The residual connection helps with gradient flow and enables training of deeper networks.</p> <p>Parameters:</p> <ul> <li> <code>in_channels</code>               (<code>int</code>)           \u2013            <p>Number of input channels.</p> </li> <li> <code>out_channels</code>               (<code>int</code>)           \u2013            <p>Number of output channels.</p> </li> <li> <code>kernel_size</code>               (<code>int</code>)           \u2013            <p>Size of the convolutional kernel.</p> </li> <li> <code>stride</code>               (<code>int</code>)           \u2013            <p>Stride of the convolution.</p> </li> <li> <code>device</code>               (<code>Device</code>, default:                   <code>None</code> )           \u2013            <p>Device on which to place the parameters. Default is None (uses default device).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Residual</code>           \u2013            <p>A residual block module that applies two ConvBN layers with a skip connection.</p> </li> </ul> Notes <p>The residual block applies two ConvBN operations in sequence, then adds the original input to the result. This helps with gradient flow in deep networks.</p>"}]}