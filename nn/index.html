
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../optim/">
      
      
        <link rel="next" href="../init/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>NN - tiny_pytorch</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tiny_pytorch.nn" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="tiny_pytorch" class="md-header__button md-logo" aria-label="tiny_pytorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            tiny_pytorch
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              NN
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="amber"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="amber"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ImadDabbura/tiny-pytorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    ImadDabbura/tiny-pytorch
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="tiny_pytorch" class="md-nav__button md-logo" aria-label="tiny_pytorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    tiny_pytorch
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ImadDabbura/tiny-pytorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    ImadDabbura/tiny-pytorch
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../ndarray/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NDArray
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensor
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../optim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizer
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    NN
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    NN
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn" class="md-nav__link">
    <span class="md-ellipsis">
      nn
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.BatchNorm1d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm1d
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.BatchNorm2d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm2d
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchNorm2d">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.BatchNorm2d.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.BatchNorm2d.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Conv" class="md-nav__link">
    <span class="md-ellipsis">
      Conv
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conv">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Conv.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.ConvBN" class="md-nav__link">
    <span class="md-ellipsis">
      ConvBN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ConvBN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.ConvBN.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.ConvBN.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Embedding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Embedding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Embedding.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Flatten" class="md-nav__link">
    <span class="md-ellipsis">
      Flatten
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTM" class="md-nav__link">
    <span class="md-ellipsis">
      LSTM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LSTM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTM.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTMCell" class="md-nav__link">
    <span class="md-ellipsis">
      LSTMCell
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LSTMCell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTMCell.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTMCell.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LayerNorm1d" class="md-nav__link">
    <span class="md-ellipsis">
      LayerNorm1d
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Linear" class="md-nav__link">
    <span class="md-ellipsis">
      Linear
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linear">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Linear.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module" class="md-nav__link">
    <span class="md-ellipsis">
      Module
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Module">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.children" class="md-nav__link">
    <span class="md-ellipsis">
      children
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.eval" class="md-nav__link">
    <span class="md-ellipsis">
      eval
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.parameters" class="md-nav__link">
    <span class="md-ellipsis">
      parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Parameter" class="md-nav__link">
    <span class="md-ellipsis">
      Parameter
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNN" class="md-nav__link">
    <span class="md-ellipsis">
      RNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNN.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNN.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNNCell" class="md-nav__link">
    <span class="md-ellipsis">
      RNNCell
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RNNCell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNNCell.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNNCell.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.ReLU" class="md-nav__link">
    <span class="md-ellipsis">
      ReLU
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Residual" class="md-nav__link">
    <span class="md-ellipsis">
      Residual
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Sequential" class="md-nav__link">
    <span class="md-ellipsis">
      Sequential
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sigmoid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Sigmoid.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Sigmoid.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.SoftmaxLoss" class="md-nav__link">
    <span class="md-ellipsis">
      SoftmaxLoss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Tanh" class="md-nav__link">
    <span class="md-ellipsis">
      Tanh
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tanh">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Tanh.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../init/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Initialization
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Operators
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../backend_numpy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Backend Numpy
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    NLP
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            NLP
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Vision
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            Vision
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vision-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn" class="md-nav__link">
    <span class="md-ellipsis">
      nn
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.BatchNorm1d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm1d
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.BatchNorm2d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm2d
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchNorm2d">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.BatchNorm2d.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.BatchNorm2d.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Conv" class="md-nav__link">
    <span class="md-ellipsis">
      Conv
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conv">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Conv.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.ConvBN" class="md-nav__link">
    <span class="md-ellipsis">
      ConvBN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ConvBN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.ConvBN.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.ConvBN.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Embedding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Embedding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Embedding.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Flatten" class="md-nav__link">
    <span class="md-ellipsis">
      Flatten
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTM" class="md-nav__link">
    <span class="md-ellipsis">
      LSTM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LSTM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTM.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTMCell" class="md-nav__link">
    <span class="md-ellipsis">
      LSTMCell
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LSTMCell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTMCell.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LSTMCell.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.LayerNorm1d" class="md-nav__link">
    <span class="md-ellipsis">
      LayerNorm1d
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Linear" class="md-nav__link">
    <span class="md-ellipsis">
      Linear
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linear">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Linear.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module" class="md-nav__link">
    <span class="md-ellipsis">
      Module
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Module">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.children" class="md-nav__link">
    <span class="md-ellipsis">
      children
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.eval" class="md-nav__link">
    <span class="md-ellipsis">
      eval
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.parameters" class="md-nav__link">
    <span class="md-ellipsis">
      parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Module.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Parameter" class="md-nav__link">
    <span class="md-ellipsis">
      Parameter
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNN" class="md-nav__link">
    <span class="md-ellipsis">
      RNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNN.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNN.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNNCell" class="md-nav__link">
    <span class="md-ellipsis">
      RNNCell
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RNNCell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNNCell.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.RNNCell.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.ReLU" class="md-nav__link">
    <span class="md-ellipsis">
      ReLU
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Residual" class="md-nav__link">
    <span class="md-ellipsis">
      Residual
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Sequential" class="md-nav__link">
    <span class="md-ellipsis">
      Sequential
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sigmoid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Sigmoid.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Sigmoid.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.SoftmaxLoss" class="md-nav__link">
    <span class="md-ellipsis">
      SoftmaxLoss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Tanh" class="md-nav__link">
    <span class="md-ellipsis">
      Tanh
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tanh">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tiny_pytorch.nn.Tanh.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>NN</h1>

<div class="doc doc-object doc-module">



<a id="tiny_pytorch.nn"></a>
    <div class="doc doc-contents first">

        <p>Neural network module for tiny-pytorch implementation.</p>
<p>This module provides a comprehensive set of classes and functions for building
neural networks. It includes fundamental building blocks like layers, activation
functions, normalization modules, and specialized components for various types
of neural network architectures.</p>
<p>The module is designed to work seamlessly with the automatic differentiation
system, allowing for easy construction and training of complex neural networks.
All modules inherit from the base <code>Module</code> class, providing consistent interfaces
for parameter management, training mode control, and forward pass computation.</p>


<details class="key-features" open>
  <summary>Key Features</summary>
  <ul>
<li>Automatic parameter management and gradient tracking</li>
<li>Training/evaluation mode switching</li>
<li>Modular design for easy network construction</li>
<li>Support for various neural network architectures</li>
<li>Built-in activation functions and loss functions</li>
<li>Normalization layers (BatchNorm, LayerNorm)</li>
<li>Recurrent neural network components (RNN, LSTM)</li>
<li>Convolutional neural network layers and composite blocks</li>
<li>Embedding layers for sequence processing</li>
</ul>
</details>

<p><span class="doc-section-title">Classes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></b>
          –
          <div class="doc-md-description">
            <p>Base class for all neural network modules. Provides common functionality
for parameter management, training mode control, and forward pass computation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code></b>
          –
          <div class="doc-md-description">
            <p>A special kind of tensor that represents learnable parameters. Acts as a marker
so modules can identify trainable parameters. All Parameter tensors have
require_grad set to True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="ReLU (tiny_pytorch.nn.ReLU)" href="#tiny_pytorch.nn.ReLU">ReLU</a></code></b>
          –
          <div class="doc-md-description">
            <p>Rectified Linear Unit activation function.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Tanh (tiny_pytorch.nn.Tanh)" href="#tiny_pytorch.nn.Tanh">Tanh</a></code></b>
          –
          <div class="doc-md-description">
            <p>Hyperbolic tangent activation function.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Sigmoid (tiny_pytorch.nn.Sigmoid)" href="#tiny_pytorch.nn.Sigmoid">Sigmoid</a></code></b>
          –
          <div class="doc-md-description">
            <p>Sigmoid activation function.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Linear (tiny_pytorch.nn.Linear)" href="#tiny_pytorch.nn.Linear">Linear</a></code></b>
          –
          <div class="doc-md-description">
            <p>Linear transformation layer (fully connected layer).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Flatten (tiny_pytorch.nn.Flatten)" href="#tiny_pytorch.nn.Flatten">Flatten</a></code></b>
          –
          <div class="doc-md-description">
            <p>Flattens the input tensor into a 2D tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="BatchNorm1d (tiny_pytorch.nn.BatchNorm1d)" href="#tiny_pytorch.nn.BatchNorm1d">BatchNorm1d</a></code></b>
          –
          <div class="doc-md-description">
            <p>1D batch normalization layer for fully connected networks.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="BatchNorm2d (tiny_pytorch.nn.BatchNorm2d)" href="#tiny_pytorch.nn.BatchNorm2d">BatchNorm2d</a></code></b>
          –
          <div class="doc-md-description">
            <p>2D batch normalization layer for convolutional networks.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="LayerNorm1d (tiny_pytorch.nn.LayerNorm1d)" href="#tiny_pytorch.nn.LayerNorm1d">LayerNorm1d</a></code></b>
          –
          <div class="doc-md-description">
            <p>1D layer normalization layer.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Dropout (tiny_pytorch.nn.Dropout)" href="#tiny_pytorch.nn.Dropout">Dropout</a></code></b>
          –
          <div class="doc-md-description">
            <p>Dropout layer for regularization during training.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Sequential (tiny_pytorch.nn.Sequential)" href="#tiny_pytorch.nn.Sequential">Sequential</a></code></b>
          –
          <div class="doc-md-description">
            <p>Sequential container that applies modules in order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Residual (tiny_pytorch.nn.Residual)" href="#tiny_pytorch.nn.Residual">Residual</a></code></b>
          –
          <div class="doc-md-description">
            <p>Residual connection that adds input to the output of a module.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="SoftmaxLoss (tiny_pytorch.nn.SoftmaxLoss)" href="#tiny_pytorch.nn.SoftmaxLoss">SoftmaxLoss</a></code></b>
          –
          <div class="doc-md-description">
            <p>Softmax cross-entropy loss function.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Conv (tiny_pytorch.nn.Conv)" href="#tiny_pytorch.nn.Conv">Conv</a></code></b>
          –
          <div class="doc-md-description">
            <p>2D convolutional layer with support for padding and stride.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="ConvBN (tiny_pytorch.nn.ConvBN)" href="#tiny_pytorch.nn.ConvBN">ConvBN</a></code></b>
          –
          <div class="doc-md-description">
            <p>Composite module combining convolution, batch normalization, and ReLU activation.
Common building block in modern CNN architectures like ResNet.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="RNNCell (tiny_pytorch.nn.RNNCell)" href="#tiny_pytorch.nn.RNNCell">RNNCell</a></code></b>
          –
          <div class="doc-md-description">
            <p>Single RNN cell with tanh or ReLU nonlinearity.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="RNN (tiny_pytorch.nn.RNN)" href="#tiny_pytorch.nn.RNN">RNN</a></code></b>
          –
          <div class="doc-md-description">
            <p>Multi-layer RNN with tanh or ReLU nonlinearity.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="LSTMCell (tiny_pytorch.nn.LSTMCell)" href="#tiny_pytorch.nn.LSTMCell">LSTMCell</a></code></b>
          –
          <div class="doc-md-description">
            <p>Single LSTM cell with forget, input, and output gates.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="LSTM (tiny_pytorch.nn.LSTM)" href="#tiny_pytorch.nn.LSTM">LSTM</a></code></b>
          –
          <div class="doc-md-description">
            <p>Multi-layer LSTM network.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="Embedding (tiny_pytorch.nn.Embedding)" href="#tiny_pytorch.nn.Embedding">Embedding</a></code></b>
          –
          <div class="doc-md-description">
            <p>Embedding layer for converting indices to dense vectors.</p>
          </div>
        </li>
    </ul>


<details class="note" open>
  <summary>Notes</summary>
  <p>All modules support automatic differentiation through the tensor system.
Parameters are automatically tracked and gradients are computed during
backward passes. The training mode affects the behavior of certain modules
like Dropout and BatchNorm, which behave differently during training and
evaluation.</p>
<p>The module system is designed to be composable, allowing complex networks
to be built from simple building blocks. The Sequential and Residual
containers provide convenient ways to combine multiple modules.</p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">tiny_pytorch</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tp</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a simple feedforward network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a convolutional network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv_model</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
<span class="gp">... </span>    <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create an RNN for sequence processing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rnn</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use the model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>  <span class="c1"># batch_size=32, features=784</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Forward pass</span>
</code></pre></div>









  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.BatchNorm1d" class="doc doc-heading">
            <code>BatchNorm1d</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies batch normalization to the input tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>dim</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of dimensions in the input tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>eps</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>1e-05</code>
)
          –
          <div class="doc-md-description">
            <p>Value added to the denominator for numerical stability. Default is 1e-5.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>momentum</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>0.1</code>
)
          –
          <div class="doc-md-description">
            <p>Momentum for the moving average. Default is 0.1.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the tensor. Default is CPU.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the tensor. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm1d.dim">dim</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of dimensions in the input tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm1d.eps">eps</span></code></b>
              (<code><span title="float">float</span></code>)
          –
          <div class="doc-md-description">
            <p>Value added to the denominator for numerical stability.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm1d.momentum">momentum</span></code></b>
              (<code><span title="float">float</span></code>)
          –
          <div class="doc-md-description">
            <p>Momentum for the moving average.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm1d.weight">weight</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>Learnable weight parameter.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm1d.bias">bias</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>Learnable bias parameter.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm1d.running_mean">running_mean</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Running mean of the input tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm1d.running_var">running_var</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Running variance of the input tensor.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><span title="tiny_pytorch.nn.BatchNorm1d.forward">forward</span></code></b>
            –
            <div class="doc-md-description">
              <p>Applies batch normalization to the input tensor <code>x</code>.</p>
            </div>
          </li>
    </ul>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.BatchNorm2d" class="doc doc-heading">
            <code>BatchNorm2d</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="BatchNorm1d (tiny_pytorch.nn.BatchNorm1d)" href="#tiny_pytorch.nn.BatchNorm1d">BatchNorm1d</a></code></p>


        <p>Applies batch normalization to 2D input tensors.</p>
<p>This module applies batch normalization over a 4D input (a mini-batch of 2D inputs
with additional channel dimension) as described in the paper
"Batch Normalization: Accelerating Deep Network Training by Reducing Internal
Covariate Shift".</p>
<p>The input is expected to be in NCHW format (batch, channels, height, width).
For each channel, this layer computes the mean and variance over the batch
and spatial dimensions, then normalizes the input and applies learnable
scale and shift parameters.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>num_features</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of features/channels in the input tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>eps</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>1e-05</code>
)
          –
          <div class="doc-md-description">
            <p>Value added to the denominator for numerical stability. Default is 1e-5.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>momentum</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>0.1</code>
)
          –
          <div class="doc-md-description">
            <p>Momentum for the moving average. Default is 0.1.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the parameters. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the parameters. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm2d.num_features">num_features</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of features/channels in the input tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm2d.eps">eps</span></code></b>
              (<code><span title="float">float</span></code>)
          –
          <div class="doc-md-description">
            <p>Value added to the denominator for numerical stability.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm2d.momentum">momentum</span></code></b>
              (<code><span title="float">float</span></code>)
          –
          <div class="doc-md-description">
            <p>Momentum for the moving average.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm2d.weight">weight</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>Learnable weight parameter of shape (num_features,).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm2d.bias">bias</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>Learnable bias parameter of shape (num_features,).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm2d.running_mean">running_mean</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Running mean of the input tensor of shape (num_features,).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.BatchNorm2d.running_var">running_var</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Running variance of the input tensor of shape (num_features,).</p>
          </div>
        </li>
    </ul>


<details class="note" open>
  <summary>Notes</summary>
  <ul>
<li>Input is expected to be in NCHW format (batch, channels, height, width).</li>
<li>During training, this layer keeps a running estimate of its computed mean
  and variance, which is then used for normalization during evaluation.</li>
<li>The running estimates are kept with a default momentum of 0.1.</li>
<li>Internally converts to channel-last format for efficient computation,
  similar to PyTorch's implementation.</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">bn</span> <span class="o">=</span> <span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>  <span class="c1"># batch_size=32, channels=64, height=28, width=28</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># shape: (32, 64, 28, 28)</span>
</code></pre></div>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.BatchNorm2d.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Initialize the BatchNorm2d module.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>num_features</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of features/channels in the input tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>eps</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>1e-05</code>
)
          –
          <div class="doc-md-description">
            <p>Value added to the denominator for numerical stability. Default is 1e-5.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>momentum</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>0.1</code>
)
          –
          <div class="doc-md-description">
            <p>Momentum for the moving average. Default is 0.1.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the parameters. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the parameters. Default is "float32".</p>
          </div>
        </li>
    </ul>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.BatchNorm2d.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Forward pass of the 2D batch normalization.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>x</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of shape (batch_size, num_features, height, width) in NCHW format.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Normalized tensor of shape (batch_size, num_features, height, width) in NCHW format.</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Conv" class="doc doc-heading">
            <code>Conv</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Multi-channel 2D convolutional layer.</p>
<p>This module applies a 2D convolution over an input signal composed of several
input planes. The input is expected to be in NCHW format (batch, channels, height, width)
and the output will also be in NCHW format.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>in_channels</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of channels in the input image.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>out_channels</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of channels produced by the convolution.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>kernel_size</code></b>
              (<code>int or tuple of int</code>)
          –
          <div class="doc-md-description">
            <p>Size of the convolving kernel. If a single int is provided, it is used
for both height and width dimensions. Only square kernels are supported.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>stride</code></b>
              (<code>int or tuple of int</code>, default:
                  <code>1</code>
)
          –
          <div class="doc-md-description">
            <p>Stride of the convolution. If a single int is provided, it is used for
both height and width dimensions. Default is 1.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>bias</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>If True, adds a learnable bias to the output. Default is True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the weights. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the weights. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Conv.in_channels">in_channels</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of channels in the input image.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Conv.out_channels">out_channels</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of channels produced by the convolution.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Conv.kernel_size">kernel_size</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Size of the convolving kernel (square kernel).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Conv.stride">stride</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Stride of the convolution.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Conv.padding">padding</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Padding added to both sides of the input. Automatically calculated as
(kernel_size - 1) // 2 to maintain same output size.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Conv.weight">weight</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable weights of the module of shape
(kernel_size, kernel_size, in_channels, out_channels).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Conv.bias">bias</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>The learnable bias of the module of shape (out_channels,). None if bias is False.</p>
          </div>
        </li>
    </ul>


<details class="note" open>
  <summary>Notes</summary>
  <ul>
<li>Only supports padding='same' (automatic padding to maintain output size).</li>
<li>No grouped convolution or dilation support.</li>
<li>Only supports square kernels.</li>
<li>Input and output are in NCHW format.</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">conv</span> <span class="o">=</span> <span class="n">Conv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>  <span class="c1"># batch_size=1, channels=3, height=32, width=32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># shape: (1, 64, 32, 32)</span>
</code></pre></div>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Conv.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Forward pass of the 2D convolution.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>x</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of shape (batch_size, in_channels, height, width) in NCHW format.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Output tensor of shape (batch_size, out_channels, height, width) in NCHW format.</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.ConvBN" class="doc doc-heading">
            <code>ConvBN</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>A composite module that combines convolution, batch normalization, and ReLU activation.</p>
<p>This module is a common building block in convolutional neural networks, particularly
in architectures like ResNet. It applies a 2D convolution followed by batch normalization
and ReLU activation in sequence. This combination helps with training stability and
convergence speed.</p>
<p>The module consists of three components applied in order:
1. Conv: 2D convolutional layer
2. BatchNorm2d: 2D batch normalization layer
3. ReLU: Rectified Linear Unit activation function</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>in_channels</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of channels in the input image.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>out_channels</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of channels produced by the convolution.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>kernel_size</code></b>
              (<code><span title="int">int</span> or <span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>)
          –
          <div class="doc-md-description">
            <p>Size of the convolving kernel. If a single int is provided, it is used
for both height and width dimensions. Only square kernels are supported.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>stride</code></b>
              (<code><span title="int">int</span> or <span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>, default:
                  <code>1</code>
)
          –
          <div class="doc-md-description">
            <p>Stride of the convolution. If a single int is provided, it is used for
both height and width dimensions. Default is 1.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the parameters. Default is None (uses default device).</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.ConvBN.conv">conv</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Conv (tiny_pytorch.nn.Conv)" href="#tiny_pytorch.nn.Conv">Conv</a></code>)
          –
          <div class="doc-md-description">
            <p>The 2D convolutional layer.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.ConvBN.bn">bn</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="BatchNorm2d (tiny_pytorch.nn.BatchNorm2d)" href="#tiny_pytorch.nn.BatchNorm2d">BatchNorm2d</a></code>)
          –
          <div class="doc-md-description">
            <p>The 2D batch normalization layer.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.ConvBN.relu">relu</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="ReLU (tiny_pytorch.nn.ReLU)" href="#tiny_pytorch.nn.ReLU">ReLU</a></code>)
          –
          <div class="doc-md-description">
            <p>The ReLU activation function.</p>
          </div>
        </li>
    </ul>


<details class="note" open>
  <summary>Notes</summary>
  <ul>
<li>Input is expected to be in NCHW format (batch, channels, height, width).</li>
<li>Output maintains the same format as input.</li>
<li>The convolution uses padding='same' to maintain spatial dimensions.</li>
<li>Batch normalization is applied per-channel across the batch and spatial dimensions.</li>
<li>ReLU activation is applied element-wise after batch normalization.</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">convbn</span> <span class="o">=</span> <span class="n">ConvBN</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>  <span class="c1"># batch_size=32, channels=3, height=28, width=28</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">convbn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># shape: (32, 64, 28, 28)</span>
</code></pre></div>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.ConvBN.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Initialize the ConvBN module.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>in_channels</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of channels in the input image.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>out_channels</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of channels produced by the convolution.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>kernel_size</code></b>
              (<code><span title="int">int</span> or <span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>)
          –
          <div class="doc-md-description">
            <p>Size of the convolving kernel. If a single int is provided, it is used
for both height and width dimensions.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>stride</code></b>
              (<code><span title="int">int</span> or <span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>, default:
                  <code>1</code>
)
          –
          <div class="doc-md-description">
            <p>Stride of the convolution. If a single int is provided, it is used for
both height and width dimensions. Default is 1.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the parameters. Default is None (uses default device).</p>
          </div>
        </li>
    </ul>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.ConvBN.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Forward pass of the ConvBN module.</p>
<p>Applies convolution, batch normalization, and ReLU activation in sequence.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>x</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of shape (batch_size, in_channels, height, width) in NCHW format.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Output tensor of shape (batch_size, out_channels, height, width) in NCHW format.
The output has been processed through convolution, batch normalization, and ReLU.</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Dropout" class="doc doc-heading">
            <code>Dropout</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies dropout to the input tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>p</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>0.5</code>
)
          –
          <div class="doc-md-description">
            <p>Probability of an element to be dropped. Default is 0.5.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Dropout.p">p</span></code></b>
              (<code><span title="float">float</span></code>)
          –
          <div class="doc-md-description">
            <p>Probability of an element to be dropped.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><span title="tiny_pytorch.nn.Dropout.forward">forward</span></code></b>
            –
            <div class="doc-md-description">
              <p>Applies dropout to the input tensor <code>x</code>.</p>
            </div>
          </li>
    </ul>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Embedding" class="doc doc-heading">
            <code>Embedding</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>A lookup table that stores embeddings of a fixed dictionary and size.</p>
<p>This module is often used to store word embeddings and retrieve them using indices.
The input to the module is a list of indices, and the output is the corresponding
word embeddings.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>vocab_sz</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Size of the dictionary of embeddings (number of unique tokens).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>embedding_dim</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The size of each embedding vector.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the embedding weights. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the embedding weights. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Embedding.vocab_sz">vocab_sz</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Size of the dictionary of embeddings.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Embedding.embedding_dim">embedding_dim</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The size of each embedding vector.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Embedding.weight">weight</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable embedding weights of shape <code>(vocab_sz, embedding_dim)</code>.
Initialized from N(0, 1) distribution.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="forward(x) (tiny_pytorch.nn.Embedding.forward)" href="#tiny_pytorch.nn.Embedding.forward">forward</a></code></b>
            –
            <div class="doc-md-description">
              <p>Maps word indices to embedding vectors.</p>
            </div>
          </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>  <span class="c1"># shape: (seq_len, batch_size)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">(</span><span class="n">input_indices</span><span class="p">)</span>  <span class="c1"># shape: (seq_len, batch_size, 128)</span>
</code></pre></div>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Embedding.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Maps word indices to embedding vectors.</p>
<p>This method converts input indices to one-hot vectors and then projects
them to embedding vectors using the learned embedding weights.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>x</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor containing indices of shape <code>(seq_len, batch_size)</code>.
Each element should be an integer index in the range [0, vocab_sz).</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Output tensor of shape <code>(seq_len, batch_size, embedding_dim)</code> containing
the corresponding embedding vectors for each input index.</p>
          </div>
        </li>
    </ul>


<details class="note" open>
  <summary>Notes</summary>
  <p>The input indices are converted to one-hot vectors internally, then
multiplied with the embedding weight matrix to produce the final embeddings.</p>
</details>

    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Flatten" class="doc doc-heading">
            <code>Flatten</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Flattens the input tensor into a 2D tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>X</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor to be flattened.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Flattened tensor.</p>
          </div>
        </li>
    </ul>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.LSTM" class="doc doc-heading">
            <code>LSTM</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>input_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of expected features in the input x.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>hidden_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>num_layers</code></b>
              (<code><span title="int">int</span></code>, default:
                  <code>1</code>
)
          –
          <div class="doc-md-description">
            <p>Number of recurrent layers. Default is 1.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>bias</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>If False, then the layer does not use bias weights. Default is True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the weights. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the weights. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTM.lstm_cells">lstm_cells</span></code></b>
              (<code>list of LSTMCell</code>)
          –
          <div class="doc-md-description">
            <p>List of LSTMCell modules for each layer.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTM.hidden_size">hidden_size</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTM.num_layers">num_layers</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of recurrent layers.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTM.device">device</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>Device on which the parameters are allocated.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTM.dtype">dtype</span></code></b>
              (<code><span title="str">str</span></code>)
          –
          <div class="doc-md-description">
            <p>Data type of the parameters.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="forward(X, h=None) (tiny_pytorch.nn.LSTM.forward)" href="#tiny_pytorch.nn.LSTM.forward">forward</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the output and final hidden and cell states for a batch of input sequences.</p>
            </div>
          </li>
    </ul>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.LSTM.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute the output and final hidden and cell states for a batch of input sequences.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>X</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of shape (seq_len, batch_size, input_size) containing the features of the input sequence.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>h</code></b>
              (<code>tuple of (Tensor, Tensor) or None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Tuple of (h0, c0), where each is a tensor of shape (num_layers, batch_size, hidden_size). If None, both default to zeros.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>output</code></b> (              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
)          –
          <div class="doc-md-description">
            <p>Output tensor of shape (seq_len, batch_size, hidden_size) containing the output features (h_t) from the last layer of the LSTM, for each t.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
              <code>(h_n, c_n) : tuple of Tensor</code>
          –
          <div class="doc-md-description">
            <p>Tuple of (h_n, c_n), each of shape (num_layers, batch_size, hidden_size) containing the final hidden and cell states for each element in the batch.</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.LSTMCell" class="doc doc-heading">
            <code>LSTMCell</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>A long short-term memory (LSTM) cell.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>input_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of expected features in the input X.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>hidden_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>bias</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>If False, then the layer does not use bias weights. Default is True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the weights. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the weights. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.W_ih">W_ih</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable input-hidden weights, of shape (input_size, 4 * hidden_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.W_hh">W_hh</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable hidden-hidden weights, of shape (hidden_size, 4 * hidden_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.bias_ih">bias_ih</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>The learnable input-hidden bias, of shape (4 * hidden_size,). None if bias is False.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.bias_hh">bias_hh</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>The learnable hidden-hidden bias, of shape (4 * hidden_size,). None if bias is False.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.hidden_size">hidden_size</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.device">device</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>Device on which the parameters are allocated.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.dtype">dtype</span></code></b>
              (<code><span title="str">str</span></code>)
          –
          <div class="doc-md-description">
            <p>Data type of the parameters.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="forward(X, h=None) (tiny_pytorch.nn.LSTMCell.forward)" href="#tiny_pytorch.nn.LSTMCell.forward">forward</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the next hidden and cell state given input X and previous states.</p>
            </div>
          </li>
    </ul>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.LSTMCell.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>A long short-term memory (LSTM) cell.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>input_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of expected features in the input X.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>hidden_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>bias</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>If False, then the layer does not use bias weights. Default is True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the weights. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the weights. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.__init__.W_ih">W_ih</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable input-hidden weights, of shape (input_size, 4 * hidden_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.__init__.W_hh">W_hh</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable hidden-hidden weights, of shape (hidden_size, 4 * hidden_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.__init__.bias_ih">bias_ih</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>The learnable input-hidden bias, of shape (4 * hidden_size,). None if bias is False.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.__init__.bias_hh">bias_hh</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>The learnable hidden-hidden bias, of shape (4 * hidden_size,). None if bias is False.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.__init__.hidden_size">hidden_size</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.__init__.device">device</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>Device on which the parameters are allocated.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.LSTMCell.__init__.dtype">dtype</span></code></b>
              (<code><span title="str">str</span></code>)
          –
          <div class="doc-md-description">
            <p>Data type of the parameters.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Functions:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><span title="tiny_pytorch.nn.LSTMCell.__init__.forward">forward</span></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the next hidden and cell state given input X and previous states.</p>
            </div>
          </li>
    </ul>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.LSTMCell.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute the next hidden and cell state for a batch of inputs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>X</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of shape (batch_size, input_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>h</code></b>
              (<code>tuple of (Tensor, Tensor) or None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Tuple of (h0, c0), where each is a tensor of shape (batch_size, hidden_size). If None, both default to zeros.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>h_out</code></b> (              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
)          –
          <div class="doc-md-description">
            <p>Next hidden state tensor of shape (batch_size, hidden_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<b><code>c_out</code></b> (              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
)          –
          <div class="doc-md-description">
            <p>Next cell state tensor of shape (batch_size, hidden_size).</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.LayerNorm1d" class="doc doc-heading">
            <code>LayerNorm1d</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies layer normalization to the input tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>x</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor to apply layer normalization.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dim</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Dimension to normalize.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>eps</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>1e-05</code>
)
          –
          <div class="doc-md-description">
            <p>Epsilon for numerical stability. Default is 1e-5.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the tensor. Default is CPU.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the tensor. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Normalized tensor.</p>
          </div>
        </li>
    </ul>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Linear" class="doc doc-heading">
            <code>Linear</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies a linear transformation to the input data.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Linear.weight">weight</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable weights of the module of shape <code>(in_features, out_features)</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Linear.bias">bias</span></code></b>
              (<code>(<a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a>, <span title="optional">optional</span>)</code>)
          –
          <div class="doc-md-description">
            <p>The learnable bias of the module of shape <code>(1, out_features)</code>.</p>
          </div>
        </li>
    </ul>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Linear.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>in_features</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Size of each input sample.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>out_features</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Size of each output sample.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>bias</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>If set to <code>False</code>, the layer will not learn an additive bias. Default is <code>True</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the tensor. Default is CPU.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the tensor. Default is "float32".</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Module" class="doc doc-heading">
            <code>Module</code>


</h2>


    <div class="doc doc-contents ">


        <p>Base class for all neural network modules. Your module should also subclass this.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Module.training">training</span></code></b>
              (<code><span title="bool">bool</span></code>)
          –
          <div class="doc-md-description">
            <p>Whether the module is in training mode or not.</p>
          </div>
        </li>
    </ul>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Module.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Forward pass of the module.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>The output tensor of the forward pass.</p>
          </div>
        </li>
    </ul>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Module.children" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">children</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Return the list of child modules in the module.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><span title="list">list</span>[<a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a>]</code>
          –
          <div class="doc-md-description">
            <p>List of child modules in the module.</p>
          </div>
        </li>
    </ul>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Module.eval" class="doc doc-heading">
            <code class="highlight language-python"><span class="nb">eval</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Sets the module in evaluation mode.</p>
<p>This method sets the <code>training</code> attribute to <code>False</code>, which affects the behavior of certain modules like dropout and batch normalization. It also recursively sets the <code>training</code> attribute of all child modules.</p>


<details class="note" open>
  <summary>Notes</summary>
  <p>This method is a no-op if the module is already in evaluation mode.</p>
</details>

    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Module.parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">parameters</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><span title="list">list</span>[<a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a>]</code>
          –
          <div class="doc-md-description">
            <p>A list of tensors representing the parameters of the module.</p>
          </div>
        </li>
    </ul>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Module.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Sets the module in training mode.</p>
<p>This method sets the <code>training</code> attribute to <code>True</code>, which affects the behavior of certain modules like dropout and batch normalization. It also recursively sets the <code>training</code> attribute of all child modules.</p>


<details class="note" open>
  <summary>Notes</summary>
  <p>This method is a no-op if the module is already in training mode.</p>
</details>

    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Parameter" class="doc doc-heading">
            <code>Parameter</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code></p>


        <p>A special kind of tensor that represents parameters. It acts as a marker
so modules can be able to identify learnable parameters. All <code>Parameter</code>
tensors have require_grad set to True.</p>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.RNN" class="doc doc-heading">
            <code>RNN</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies a multi-layer RNN with tanh or ReLU non-linearity to an input sequence.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>input_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of expected features in the input x.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>hidden_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>num_layers</code></b>
              (<code><span title="int">int</span></code>, default:
                  <code>1</code>
)
          –
          <div class="doc-md-description">
            <p>Number of recurrent layers. Default is 1.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>bias</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>If False, then the layer does not use bias weights. Default is True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>nonlinearity</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;tanh&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>The non-linearity to use. Can be either 'tanh' or 'relu'. Default is 'tanh'.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the weights. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the weights. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNN.rnn_cells">rnn_cells</span></code></b>
              (<code>list of RNNCell</code>)
          –
          <div class="doc-md-description">
            <p>List of RNNCell modules for each layer.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNN.hidden_size">hidden_size</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNN.num_layers">num_layers</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>Number of recurrent layers.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNN.device">device</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>Device on which the parameters are allocated.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNN.dtype">dtype</span></code></b>
              (<code><span title="str">str</span></code>)
          –
          <div class="doc-md-description">
            <p>Data type of the parameters.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="forward(X, h0=None) (tiny_pytorch.nn.RNN.forward)" href="#tiny_pytorch.nn.RNN.forward">forward</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the output and final hidden state for a batch of input sequences.</p>
            </div>
          </li>
    </ul>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.RNN.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Applies an RNN cell with tanh or ReLU nonlinearity.</p>
<p>Parameters:
input_size: The number of expected features in the input X
hidden_size: The number of features in the hidden state h
bias: If False, then the layer does not use bias weights
nonlinearity: The non-linearity to use. Can be either 'tanh' or 'relu'.</p>
<p>Variables:
W_ih: The learnable input-hidden weights of shape (input_size, hidden_size).
W_hh: The learnable hidden-hidden weights of shape (hidden_size, hidden_size).
bias_ih: The learnable input-hidden bias of shape (hidden_size,).
bias_hh: The learnable hidden-hidden bias of shape (hidden_size,).</p>
<p>Weights and biases are initialized from U(-sqrt(k), sqrt(k)) where k = 1/hidden_size</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.RNN.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">h0</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute the output and final hidden state for a batch of input sequences.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>X</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of shape (seq_len, batch_size, input_size) containing the features of the input sequence.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>h0</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a> or None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Initial hidden state for each element in the batch, of shape (num_layers, batch_size, hidden_size). If None, defaults to zeros.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>output</code></b> (              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
)          –
          <div class="doc-md-description">
            <p>Output tensor of shape (seq_len, batch_size, hidden_size) containing the output features (h_t) from the last layer of the RNN, for each t.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<b><code>h_n</code></b> (              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
)          –
          <div class="doc-md-description">
            <p>Tensor of shape (num_layers, batch_size, hidden_size) containing the final hidden state for each element in the batch.</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.RNNCell" class="doc doc-heading">
            <code>RNNCell</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies a single RNN cell with a specified nonlinearity (tanh or ReLU).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>input_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of expected features in the input X.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>hidden_size</code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>bias</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>If False, then the layer does not use bias weights. Default is True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>nonlinearity</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;tanh&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>The non-linearity to use. Can be either 'tanh' or 'relu'. Default is 'tanh'.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>device</code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Device on which to place the weights. Default is None (uses default device).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>dtype</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;float32&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>Data type of the weights. Default is "float32".</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNNCell.W_ih">W_ih</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable input-hidden weights of shape (input_size, hidden_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNNCell.W_hh">W_hh</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a></code>)
          –
          <div class="doc-md-description">
            <p>The learnable hidden-hidden weights of shape (hidden_size, hidden_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNNCell.bias_ih">bias_ih</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>The learnable input-hidden bias of shape (hidden_size,). None if bias is False.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNNCell.bias_hh">bias_hh</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Parameter (tiny_pytorch.nn.Parameter)" href="#tiny_pytorch.nn.Parameter">Parameter</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>The learnable hidden-hidden bias of shape (hidden_size,). None if bias is False.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNNCell.nonlinearity">nonlinearity</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code>)
          –
          <div class="doc-md-description">
            <p>The nonlinearity module (Tanh or ReLU).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNNCell.device">device</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Device (tiny_pytorch.backend_selection.Device)" href="../backend_numpy/#tiny_pytorch.backend_numpy.Device">Device</a> or None</code>)
          –
          <div class="doc-md-description">
            <p>Device on which the parameters are allocated.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNNCell.dtype">dtype</span></code></b>
              (<code><span title="str">str</span></code>)
          –
          <div class="doc-md-description">
            <p>Data type of the parameters.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.RNNCell.hidden_size">hidden_size</span></code></b>
              (<code><span title="int">int</span></code>)
          –
          <div class="doc-md-description">
            <p>The number of features in the hidden state h.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="forward(X, h=None) (tiny_pytorch.nn.RNNCell.forward)" href="#tiny_pytorch.nn.RNNCell.forward">forward</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the next hidden state given input X and previous hidden state h.</p>
            </div>
          </li>
    </ul>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.RNNCell.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Applies an RNN cell with tanh or ReLU nonlinearity.</p>
<p>Parameters:
input_size: The number of expected features in the input X
hidden_size: The number of features in the hidden state h
bias: If False, then the layer does not use bias weights
nonlinearity: The non-linearity to use. Can be either 'tanh' or 'relu'.</p>
<p>Variables:
W_ih: The learnable input-hidden weights of shape (input_size, hidden_size).
W_hh: The learnable hidden-hidden weights of shape (hidden_size, hidden_size).
bias_ih: The learnable input-hidden bias of shape (hidden_size,).
bias_hh: The learnable hidden-hidden bias of shape (hidden_size,).</p>
<p>Weights and biases are initialized from U(-sqrt(k), sqrt(k)) where k = 1/hidden_size</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.RNNCell.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute the next hidden state for a batch of inputs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>X</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of shape (batch_size, input_size).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>h</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a> or None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Initial hidden state for each element in the batch, of shape (batch_size, hidden_size). If None, defaults to zeros.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Next hidden state tensor of shape (batch_size, hidden_size).</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.ReLU" class="doc doc-heading">
            <code>ReLU</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies the rectified linear unit (ReLU) activation function element-wise.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>x</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Output tensor with ReLU activation applied element-wise.</p>
          </div>
        </li>
    </ul>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Residual" class="doc doc-heading">
            <code>Residual</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies a residual connection to the input tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>fn</code></b>
              (<code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code>)
          –
          <div class="doc-md-description">
            <p>The module to apply before adding the residual connection.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Residual.fn">fn</span></code></b>
              (<code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code>)
          –
          <div class="doc-md-description">
            <p>The module to apply before adding the residual connection.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><span title="tiny_pytorch.nn.Residual.forward">forward</span></code></b>
            –
            <div class="doc-md-description">
              <p>Applies the residual connection to the input tensor <code>x</code>.</p>
            </div>
          </li>
    </ul>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Sequential" class="doc doc-heading">
            <code>Sequential</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies a sequence of modules to the input.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>*modules</code></b>
              (<code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code>, default:
                  <code>()</code>
)
          –
          <div class="doc-md-description">
            <p>A sequence of modules to apply to the input.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>The output tensor after applying all modules in sequence.</p>
          </div>
        </li>
    </ul>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Sigmoid" class="doc doc-heading">
            <code>Sigmoid</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies the sigmoid activation function element-wise.</p>
<p>The sigmoid function maps any real-valued number to the range (0, 1).
It is defined as: sigmoid(x) = 1 / (1 + e^(-x))</p>
<p>The sigmoid function is commonly used in binary classification problems
and as a gating mechanism in neural networks.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Sigmoid.None">None</span></code></b>
          –
          <div class="doc-md-description">
            <p>This module has no learnable parameters.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">Tensor([0.1192, 0.2689, 0.5000, 0.7311, 0.8808], device=cpu_numpy())</span>
</code></pre></div>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Sigmoid.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Initialize the Sigmoid module.</p>
<p>This module has no learnable parameters and requires no initialization.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Sigmoid.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Forward pass of the sigmoid activation function.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>x</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of any shape.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Output tensor with the same shape as input, with sigmoid activation
applied element-wise. Values are in the range (0, 1).</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.SoftmaxLoss" class="doc doc-heading">
            <code>SoftmaxLoss</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Computes the softmax loss between logits and labels.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>logits</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input logits tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Ground truth labels tensor.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>The softmax loss between logits and labels.</p>
          </div>
        </li>
    </ul>










  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tiny_pytorch.nn.Tanh" class="doc doc-heading">
            <code>Tanh</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Module (tiny_pytorch.nn.Module)" href="#tiny_pytorch.nn.Module">Module</a></code></p>


        <p>Applies the hyperbolic tangent (tanh) activation function element-wise.</p>
<p>The tanh function maps any real-valued number to the range (-1, 1).
It is defined as: tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="tiny_pytorch.nn.Tanh.None">None</span></code></b>
          –
          <div class="doc-md-description">
            <p>This module has no learnable parameters.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">tanh</span> <span class="o">=</span> <span class="n">Tanh</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">Tensor([-0.9640, -0.7616, 0.0000, 0.7616, 0.9640], device=cpu_numpy())</span>
</code></pre></div>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tiny_pytorch.nn.Tanh.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Forward pass of the tanh activation function.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>x</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Input tensor of any shape.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="Tensor (tiny_pytorch.tensor.Tensor)" href="../tensor/#tiny_pytorch.tensor.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>Output tensor with the same shape as input, with tanh activation
applied element-wise. Values are in the range (-1, 1).</p>
          </div>
        </li>
    </ul>


    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/ImadDabbura/tiny-pytorch" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/ImadPhd" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/imaddabbura/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://medium.com/@ImadPhd" target="_blank" rel="noopener" title="medium.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M180.5 74.262C80.813 74.262 0 155.633 0 256s80.819 181.738 180.5 181.738S361 356.373 361 256 280.191 74.262 180.5 74.262m288.25 10.646c-49.845 0-90.245 76.619-90.245 171.095s40.406 171.1 90.251 171.1 90.251-76.619 90.251-171.1H559c0-94.503-40.4-171.095-90.248-171.095Zm139.506 17.821c-17.526 0-31.735 68.628-31.735 153.274s14.2 153.274 31.735 153.274S640 340.631 640 256c0-84.649-14.215-153.271-31.742-153.271Z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://imaddabbura.github.io/" target="_blank" rel="noopener" title="imaddabbura.github.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M352 256c0 22.2-1.2 43.6-3.3 64H163.4c-2.2-20.4-3.3-41.8-3.3-64s1.2-43.6 3.3-64h185.3c2.2 20.4 3.3 41.8 3.3 64m28.8-64h123.1c5.3 20.5 8.1 41.9 8.1 64s-2.8 43.5-8.1 64H380.8c2.1-20.6 3.2-42 3.2-64s-1.1-43.4-3.2-64m112.6-32H376.7c-10-63.9-29.8-117.4-55.3-151.6 78.3 20.7 142 77.5 171.9 151.6zm-149.1 0H167.7c6.1-36.4 15.5-68.6 27-94.7 10.5-23.6 22.2-40.7 33.5-51.5C239.4 3.2 248.7 0 256 0s16.6 3.2 27.8 13.8c11.3 10.8 23 27.9 33.5 51.5 11.6 26 20.9 58.2 27 94.7m-209 0H18.6c30-74.1 93.6-130.9 172-151.6-25.5 34.2-45.3 87.7-55.3 151.6M8.1 192h123.1c-2.1 20.6-3.2 42-3.2 64s1.1 43.4 3.2 64H8.1C2.8 299.5 0 278.1 0 256s2.8-43.5 8.1-64m186.6 254.6c-11.6-26-20.9-58.2-27-94.6h176.6c-6.1 36.4-15.5 68.6-27 94.6-10.5 23.6-22.2 40.7-33.5 51.5-11.2 10.7-20.5 13.9-27.8 13.9s-16.6-3.2-27.8-13.8c-11.3-10.8-23-27.9-33.5-51.5zM135.3 352c10 63.9 29.8 117.4 55.3 151.6-78.4-20.7-142-77.5-172-151.6zm358.1 0c-30 74.1-93.6 130.9-171.9 151.6 25.5-34.2 45.2-87.7 55.3-151.6h116.7z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["search.suggest", "search.highlight", "content.tabs.link"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>